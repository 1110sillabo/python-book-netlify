[
["prologue.html", "Programming Digital Humanities. Python (and More) for Academia 1 Prologue 1.1 The Journey: Welcome to HumanDemia 1.2 A Difficult Trade-Off (including Book Summary) 1.3 Who’s this Book for 1.4 Getting the Most Out of this Book 1.5 Summary", " Programming Digital Humanities. Python (and More) for Academia Guglielmo Feis v. 0.1 2021-03-11 1 Prologue A Few Words on this Web-Based Edition I wrote the book quite sometime ago, when I was still in uni. You can buy and download it in fancier formats on LeanPub. As time passed, I realized it is good to have also the book as a browserable website. Al does that, so does Harry. 1.1 The Journey: Welcome to HumanDemia You just joined HumanDemia, a new hi-tech campus focused on Humanities. It is actually nothing futuristic. Do not imagine the Los Angeles of the Tyrrel Corps nor Esthar city. It’s a small campus (by US standards) with libraries containing physical copies of books you can touch and borrow. The notable things are that HumanDemia members know the difference between reply, forward and answer all; they can also sort the candidate sheet by student id, alphabetically or by registration date. The strangest thing is that nobody complains about wasting time at the meeting. &gt;Probably they lie. As you meet the Dean over coffee, she tells you that personal projects are welcomed and that the Uni Council is thinking about integrating a little bit of extra technical competencies into both the staff’s competencies and the curricula. You review your classes, talks and academic obligations and you agree on a weekly plan. (In your heart you already know that you’ll carry out some of the work while travelling or between meetings students during office hours, but maybe this new place will surprise you. Be it as it may, no way you are going to overwork this tech-stuff during the weekends.) Your first weeks will be about getting used to the way they work at HumanDemia. HumanDemia claims to care about research, (open) access to research products and about the time of their researchers. So they stop spending a lot on locked-in solutions and licensing software with big corporations. (This increased the production of the critical studies by 30% and, most importantly, it doubled their happiness: knowing you can criticize capital and corporations without running corporate techs’ software you don’t know how to fully use is a real banger.) The Dean tells you that, in the training, you have to spend a week getting familiar with Markdown and RStudio. You also have two weeks to refresh a little bit of command-line interface (CLI in techy-jargon) - as she looks at you she rephrases the ‘refresh’ with ‘learning’, as she notices you don’t look like you were there stroking keys in front of a PC in the late ’80s and early ’90s. Then there are and Git and GitHub. She tells not to worry about Git: “you’ll appreciate its potential for cooperation and teamwork,” she says. As you find out GitHub is “a version control system”, you think that these tech-persons seem to know how to preserve the products of their intellectual work. You shrug away some memories of crushed HDs or stories about “I wrote a paper on an old machine, but it crashed” or your favourite “I may send you the file, but I have no means to open it.” (and the joy you caused providing a converted and accessible version of the file.) Then, she says, you’ll have a month or more to pick up some programming. HumanDemia faculties work mainly with Python because it is easy to use, but they’ll throw you some further hints about other languages as well as a few curved balls. This sounds a little intimidating. Then you remind yourself you are a researcher. After all, you think, you should be able to find your way out. Plus, you’ve read around that tech-persons like challenges. “Of course,” she tells you, “we know that as a research you would like to learn something and put into practice into your work. Based on your application we find out you like building things and getting data. That ‘LEGO’ item in your interests was highly appreciated… Hence we are presenting you some Python not only for the sake of it but with design goals and implementation in mind.” This sounds promising, but you are still confused. She says not to worry, that you’ll find out what to do. That’s the reason they hired you. “If you feel you are working as a researcher and wasting your time for some reason, that’s where Python may help”. Your mind immediately thinks emails, splitting and merging pdfs to produce a reader for your course or the struggle of getting the data for your always-in-the-making grant application on “Hate Speech on Social Networks in the Post-Trump Era” (you know it has a 200+ characters long subtitle, but you are trying to forget it). After the Python month(s), you can take some time off your regular job. Then you’ll spend two weeks on a variety of projects. Some will be suggested but, they say, in a couple of months you’ll start working on your own projects. Their job will be to prevent you from starting too many things all at once and to ensure you finish your projects. You say ‘yes’, doubtful and go away. Training starts next week. 1.2 A Difficult Trade-Off (including Book Summary) Let’s make the Dean’s deal more explicit. I want to write a book that gets you started and allows you to write the best programs you have in your mind to fit your (academic and intellectual) needs. Ideally you should be more productive, but what matters is that you feel fine and rewarded with what you are doing. If you are into research, you are likely to appreciate exploring different paths, building things and trying out options, solve problems, inspire others and help others with the products of your intellectual efforts. If not, you are probably in the game for the wrong reasons (feel free to email me to start talking about it or if I’ve forgotten good instances of academia stuff). It’s fairly easy to provide some hints on technical literacy or to provide you with some ready-made code for you to copy. But that’s neither a good teaching method nor what a researcher deserves. In fact, the programs you write are something that you have to able to customize. The goal of the book is to get you started by having something that works and that you understand. Something you can extend to better fit your goals and needs. There’s no one-fits-all-solution. Especially when you are dealing with coding for humanities (humanities are vast). The best way to sum this up is probably with this longish quote by Eric Steven Raymond (discussing hacking): \"Learning to compose music has three stages. First, you have to learn the basic mechanical technique of an instrument — fingering and how to play scales. Then you have to train your ear to understand musical patterns. Finally, you must learn how to recombine musical patterns into original creations. Hacking is similar. [..] The equivalent of playing scales is writing small programs, alone. Unfortunately, playing scales (a) doesn’t teach you anything about music, and (b) is boring as hell. Similarly, writing toy programs doesn’t tend to teach you much about hacking, and (b) will tend to de-motivate you unless the program immediately solves a problem you care about. Most formal programming instruction gets to playing scales and stops. Thus, it tends to produce coders who are poor at collaborating with each other and have the equivalent of no ear for music — a poor feel for software design and architecture.\"1 Long story short, there are two conflicting needs in this book: the first is to offer something that works and pays off as researchers. Time is limited and precious (unless you don’t write your “international papers” in something that’s not English and you are tenured) and you do not want a super comprehensive book of everything that’s available on Python or other programming languages; the second is to allow you to understand what you are doing (something you need to do as a researcher, you want to understand what goes on). I’m not there to provide “copy-paste this and get the result” recipes. Given that everybody will be different, with different backgrounds, stories and with different things that will be either hard or easy to learn, it’s difficult to strike a balance that is balanced for everybody. Luckily, a solution (well, a mitigation of the problem) comes from the fact that we got trained in the academia and research is our passion. This allows me to skip on some of the hyper basic step by step tutorial with images on installing the tools or the whole basic syntax.2 I trust you can use a search engine to find this stuff on your own. I’ll explain the concepts and the interesting stuff, and offer opportunities for you to give them your own spin. Still, given the talks and the experience of “talking tech in Humanities”, I’ll indulge on some basic steps if I’ve found out they can be tricky. Sometimes that’s going to be easy, others it will be more difficult (there are git commands you have to learn, data structures cannot be super-duper fun all the time, etc.). I mean, after all, you the HumanDemia training to undergo.3 It is still training. And, despite being “human”, it also has some academic reminiscence - so expect your fair share of nonsense… Also, the shared research background allows us to work on the “start with something kinda known and move into the unknown” approach. The first weeks (part I) include something a little bit more technical than using reply to all in emails that still is not programming. There we’ll set our working environment. After setting clearly the ground here and why we should care about coding in the humanities, the book gets practical in chapter 2. With RStudio and Markdown we build an environment with automated bibliography, control over the table of contents and spell-check.4 Further, GitHub integration is just around the corner, which means: cooperation with the world. That’s what we cover next (chapter 3), and that gives us a chance to (re)discover command-line interfaces (is there anybody from MS-DOS world? or Linux? or text adventures?). Markdown is also a cool tool to develop a nice logging system5 and an easy starter for HTML if you are interested into it, and it fosters a “learn, write, master” approach to the kind of perpetual learning you know well as a researcher. The final step (chapter 4) will be to install Python through the Anaconda distribution. This makes our life easier and allows us to get started with Python programming. We are ready for Part II, the hardest trade-off for the book. There’s a crash course in Python and tools to allow you to transition from Python basics to gaining confidence. Chapter 5 is where Python kicks in. Here we stop a little bit on some of the definitions, programming mechanics and data structures. It is generally quite easy to break down the pieces of a problem, like: connect to a search engine; search the term you need for your research; open all the link; read them searching for some specific keywords and see if they meet the requirements to be part of your research. (This is often called ‘pseudocode’).6 Still, creating a program that does this might not be so easy. We need to learn a language that instructs our dumb machine friend to do that. Again, the research-based background will help to keep the crash course contained in this chapter short(ish). Chapter 6 has instructions, warnings and things I wish I had known. I present some of the areas that are mysterious for Python beginners. They vary from jargon and vocabulary issues (something easy to figure out) to more complex things such as understanding Python’s internal mechanics and coding for others. (Code has idioms, as well as real languages.) Given the wide avaiability of tutorials as well as ready-made code we can paste and - if we are lucky - use to get things done, we discuss a bit how to approach tutorials as learning tools. The last part is about the fine art of reading the docs. This is vital to get confidence with software and programming. This chapter ends part II, but you are likely to re-read it again once you are done with part III. In fact, in part III we are going through some programs. We are going to deal mainly with automation tools and search engine processing in chapter 7. Chapter 8 is all on extracting references and visualizing citation graphs. 1.3 Who’s this Book for The book is intended to serve every curious reader. Basically every human being with sparse access to an internet connection and some time to focus qualifies as that, I guess. The narration focuses on people with some academic background or doing research. As for the academic background, the book targets people from humanities as they are most likely to be the ones that have had no exposure to code in their curricula. (Of course, there are exceptions, e.g. (computational) linguistics; media studies, etc.) I hope the book may help the stereotyped oldish tenured track professors who can’t upload the syllabus on the university’s website not to bother their Ph.Ds “because you are digital natives” and it will make those making research expand their ambitions (and their dataset) relying on a bigger and broader toolbox. Maybe as MAs or Ph.Ds you’ll start considering parallel careers or who knows. Also, I wish this book can be a resource to self-thought developers (with or without a background in academia) as well. 1.3.1 How Coding Helps in the Humanities There are many ways coding helps in the humanities. Some are obvious and should not require a coding book. Suppose you say that “5 tech companies are screwing the world”. It’s probably a good idea to know who are these 5 (bad) guys and what they are doing. If one of them is into tech and may be operating on sensible data, chances are there’s some dirty work to be done. The same probably applies if you are into ‘Data Ethics’, ‘cryptocurrencies’ and other hype worlds ‘AI’ related (machine learning, deep learning, etc.). Code can help settling legal disputes. (By the way, GDPR and blockchain are pushing lawyers to be aware as developers and some universities have code for lawyers course. Kudos to them.) Suppose we pay taxes online and that there’s a norm that allows us to obtain a tax deduction up to X items. An academic dispute arises on “whether X is included or not”. That should be coded into the protocol that allows you to pay the taxes. If you can read the protocol -assuming code is available - you can set the dispute. (If the debate is whether the code correctly implemented the proposal’s intent then you still have legit papers to be written, code alone doesn’t always help.) Ok, so much for polemics and things we know already. Real-life and politics reminds us how our habit change and we (sometimes) can be more effective when a bit of technology kicks in. (Still, beware of what you do with your data. As researchers you should probably know that already.) Think about paying taxes online (if the site works), online banking, streaming videos vs. going to the Blockbuster, Coursera education and related stuff (Udemy, freecode.org). The Italian reader may even remember Berlusconi’s “Tre I” or more recent Movimento 5 Stelle “everything blockchain to achieve transparency”.7 Here’s a little list of the benefits of learning enough tech-stuff to be dangerous: better workflow: you’ll get control of your data and research output(s). Your students will be free to access your course material without compatibility issues, you are going to store your material to minimize data loss, you’ll be able to produce open data, you are not going to be locked in into specific technologies or software (unless you chose it); cooperation: you know how to exchange pieces of information properly and how to load them. You are going to pass source codes rather than .pdf if you want people to read them on their ebook reader. You’ll edit the stuff on GitHub and publish on ArXiv and stop having things behind a log wall of academia-inspired social networks. (Maybe you have all you pre-prints or papers floating around there, but in this way you save on signing agreements you are not going to respect); practicalities and technical literacy: you will know the difference between reply and reply all, you are able to sort exams lists, automate multiple-choice test corrections (enough Ph.D mocking!), upload your course materials to your website or even start one (r blogdown is your friend); writing (coauthored) papers and editing: save time performing various checks, managing bibliography, building to different formats. Learn version control to control your data; getting the data: depending on your field you’ll need to access data. Maybe it’s just papers and books. Even there you can stop guessing “the first time word X appeared” and do corpus-based analysis. Or citations graphs. If you need data and evidence to track hate speech online you may download all Trump’s tweets and refresh your analysis every hour. Enough of this. If programming is the opportunity to build our own (small-scale) panopticon, it’s all up to us to find ways to produce better research with these tools (gamification of statistics? an analysis of gender biases in Netflix top series?). A lot of the above characterizations are a parody. (It seems at HumanDemia someone told them the onboarding material is better to be fun. Still, as you know, research is based on experience - and in the case above personal experience is part of that.) 1.3.2 What Coding Can’t Do for You “It is important to be aware of what coding can’t do for us”. You nod while clicking over the next HumanDemia slide. You already had a similar belief. Coding is an enhancement to your research, it saves you time and allows you to gain access to data that could take ages to be checked by hand. Still, coding is no replacement for thought or having ideas.8 (Coding may be helpful thought-wise: it can be another engine or way to approach a problem). Although machines can generate text or summarize articles or categories pieces of information, it is still up to you to choose the topic, formulate the hypothesis, etc. You can write a program that checks every article of a legal code (say the GDPR) and prints a map of all the various references between the single articles. That’s super nice and helpful (it appears they have such a project in the HumanDemia ‘nerdy things’ list). It is still up to you to figure out what does it mean that a certain article is referred the most or whether such a reference is doing any work or rather is it some sort of honorable mention. This latter may be true more in papers than in legal codes: sometimes to add a reference does not amount to discuss a paper. (Feel free to enter your case.) You can download all of Trump’s tweets and rank the people he mentions the most. But then again it is up to you to figure out and verify if there’s any strategy or guidelines in what he is doing. If there’s sexism or if he is encouraging to bash some of the people that criticises him. You can measure some other things connected with that. In fact, you may find out that an average unknown professor that happens to be on Twitter is then flooded with insults after some Trump’s tweet. A bit of coding allows you to show that a certain bunch of users were created all together on a social network, that they started to follow some political actor, retweeting specific contents and then aggressively engaging with dissenting voices. That’s the way to go about these issues rather than “Enter a Scandalistic post-Cambridge Analytica Title”. If we want to do research (the first draft had ‘serious’ before research, but that was pleonastic) we need to show something more than what might be perceived as “yet another big narration”. Especially if the analysis gets political or engages in highly polarized issues. If we really talk about critical discourse, analytic thinking, or being interdisciplinary (not only in the attempt to get some grant) that’s the only way to do it. Embrace programming. As researchers, we need to offer a way into what we are doing to everybody, dissenting voices included. And everybody will be given a chance to go into the details and check herself. Aspiration-based and wishful-thinking research belongs all to the same bucket, whether they are Fox News-based, Freud-based or Bertrand Russell-based. That’s the bucket of pseudoscience (at best). 1.4 Getting the Most Out of this Book Let’s provide some guidelines for the HumanDemia training. (Chapter 6 will iterate some of them and offer more coding-related discussion.) The training has three parts: we set the working environment. We install RStudio, refresh the command line and install Git and mingw (a port of a Unix shell) and install the Anaconda distribution (which contains Python). In the meantime we get into a more programming-like framework. We start to control our documents and paper. We choose the setting and realize a design. Further, we learn Git cooperative workflow; we learn some Python essentials; we use Python to build something relevant academia-wise. We build our automation tools, scrape bibliography and collect search results. Start thinking how much time you invest in opening the same programs all over again… a text editor, a few websites, etc. Now, assume you boot your pc twice a day and that it takes one and a half minutes to set up and open all your tabs. If you did that, think about how many emails you can evade in 15 minutes. As far as Python programming is concerned (part. II), we already know most of the contents of this section as they deal with learning hard-skills. The best way to learn something is to put this into practice, sooner or later. How do you (learn to) write a paper? You talk with people, read, but in the end you will have to write your paper yourself. More than once actually. How do you learn how peer review works? By trials and errors (especially if you are not a native speaker) or if you are raised somehow outside the US/UK environment. I suggest you to try most of the code and methods yourself in a way that it helps you assimilate it. Personally, I like to read books on kindle to get the general picture of what I am doing. That’s happens at night or while travelling (people at HumanDemia seems to know that, I’d better check what I’m sharing on socials). When coding is concerned the more exercises I can make, the better. When you code for the first time you may do way more typos and syntax errors than you would by writing a paper in an “ordinary” language. All in all, there is a reason for them to say “talk is cheap, show me the code”. Try to start coding as soon as possible. Once the necessity is there, you’ll start diggin’ it more. I’ll try my best to propose something that can be useful, academic wise, or fun and interesting. But you should start expanding and flexing all the tools out there as soon as possible. So let’s try to have a list of some advice, but first set the ground with some (hopefully) shared assumptions. 1.4.1 Assumptions You are either on Windows or on Mac (instructions here will be Windows-based). You’ve mainly used MS Word or other branded software to write your papers and do your research. You may have explored some tools to automate toc creation or managing references. Maybe you move further enough to write in Latex. And you even tried yourself some HTML. You use a search engine when there’s something you don’t know before scream I can’t do that and also specific databases for your work, use WhatsApp or other social media (remembering myspace is no pre-requisite). You have a daily pile of emails waiting for you. You use your uni-based website to display your research or interact with students. Bonus points if you can print the list of the students both alphabetically and by their registration number (no jokes here, it is not an obvious skill to have; trust me). Still, for one of many reasons, you never took a deep breath (because you thought you need one) and dive into programming. Or maybe you even tried once, but it did not work, there was no catch. I’ve been there. More than once (I’ve actually tried to learn programming 3 times before really starting). We start from the passion for research and intellectual curiosity. We will build things (mostly) step by step. Thankfully we have a journey into HumanDemia to go through. 1.4.2 Type these Commands In (and Use IPython) There’s a saying about theory and practice according to which theory in theory, should not be something different from practice. Nonetheless, in practice, that’s not the case. Again, talk is cheap, we have to show ’em the code. It is better to show the code you wrote and understand. There is some time needed to get around the commands and have them at your fingertips.9 The setup we are going to use offers us many ways to explore a problem or a feature by way of writing code. Here’s a little spoiler for you of IPython from chapter 4. IPython and its shell are great because they prompt you to try things out. Type and explore is a great method to learn and figure out what a command does. Programming languages are languages, and languages need to be practiced. This means that not only you have to understand a concept but also to use it quite a lot. Music is another language that comes in as a good comparison. It is pretty easy to learn what C major scale is: C, D, E, F, G, A, B. It is harder to play in sixteens notes at a tempo of 160bpm. You will need to play (i.e. type it, out of analogy) these notes quite a lot (and, if you play guitar or similar, you’ll have different fingerings and positions to learn). It is fairly simple to grasp the structure of a major scale (the intervallic structure is: tone, tone, semitone, tone, tone, tone, semitone). It takes some extra efforts to realize that G major is G, A, B, C, D, E, F#. It takes practice and experience to be able to find out on your instrument the major scale you need to best serve your needs on the different chords of a song. Sorry for the long digression. IPython offers you a lot of opportunities to start typing out. It further helps you because it offers you a tool to ask for help and know what a command is or what your object is going (just add a ? - question mark - after the command). I spent a lot of time in the Python interpreter compiling programs that were too long just to test and learn something new. IPython allows you to move from a type-(compile)-save-run approach to a type and see one. As soon as you find out what you need that works, you can copy your snippet into the main code. (I know this sounds too good to be true but IPython is free. And in the Anaconda-based setup we are going to use you got it bundled in your main tool for writing code: Spyder.) 1.4.3 Make it Your Own (and Grow it) A useful tip I discovered too late - thanks to Let’s Build Instagram from Scratch with Ruby on Rails10 - is that, while following a tutorial, it is a good idea to change the names of the program you are building and the variable and make it your own. You are not a monkey copying stuff. Ok, retyping is probably necessary to grasp the syntax of something, still, you need to put some of your input. So, if the code is for you only, name the parts in your own language if that’s not English. Write more comments. And, most important of all, once the code runs fine try to work on upgrades. Can you add a little embellishment? Can you export your analysis of Trump’s tweet to a website that updates with every Trump’s tweet? Can you make the visualization of the GDPR interactive? Ok, these are all big topics. Start small. Are you able to identify all the small steps that are there in a tutorial? Can you add a little bit, like “do something super similar to step 5, but different?”. Suppose you are programming a tic-tac-toe game (people at HumanDemia has strange practices for choosing who is going to give a keynote talk). Can you make the board larger? Can you save the current board game? (Suppose tic-tac-toe spreads to different departiments and you have to discuss each move at a faculty meeting. Ok, enough of this PerverseDemia. Still, this picture sounds way better than the standard faculty meeting, doesn’t it?) Again, let me provide an analogy with music and foreign languages. If you are into music and are starting out on improvisation, you know what I am talking about. Also, learning a foreign language is a similar example. (After all music, languages and programming languages are all languages). No matter how many licks or cliches “in the style of [your favourite player]” or how many pre-build phrases (“where is the toilet?”, “what’s your name?”) you’ve learnt, talking or improvising won’t just be repeating this. Knowing chords and notes will help you as it helps to know the grammar. But then performing a solo or chat with others is different. How do you deal with phrasing or your accent? Etc. Coding is not different. There are programming styles and lots of things that, when put in practice, go in a different way than expected. (This book is the result of my learning experience. It is my first big RStudio project using the bookdown package and Markdown. Most of the projects were the things I needed for my academic journey.) 1.4.4 Make (Deliberate) Mistakes Controlled mistakes are good. Well, we can even call them “experiments”. HumanDemia kindly invites you to get used to the way a programming language works and what are the reactions you get from the machine when you got things wrong. You don’t want to be Trapattoni during that famous Bayern press conference. There’s a better way to learn German auxiliary verbs. How does that translate into programming? We experiment, we modify things. As you learn that to print something on the screen you need to write ‘print’ (how clever!) followed by a round parenthesis ‘(’ and then you need some quotation mark inside the commas. There’s a lot you can do to experiment here. What happens if you forget a quotation mark? What if you just insert the text between brackets? And what if you add more brackets? That’s the way to go. 1.4.5 Read the Docs (Note: there is another section in chapter 6 on the art and skill of reading the docs. But we all like appetizers.) Here is some good news on learning to program: there are a lot of sources and resources out there (some are listed at the end of each chapter under the ‘More Resources’ heading). Further, each package, language or command is documented by its creator (or, at least, it should be). This documentation is a form of text we need to get used to read and interact with. We know how to read papers in our professional areas. Further, chances are that, as academics, we had to assemble a bookshelf. After all, these papers and books (and desktop pcs) have to go somewhere in the real physical space. The nerdier out there may have assembled a pc. And, when we were young, I hope we all were exposed to LEGO. Be it as it may, chances are we got exposed to both papers and instruction sets. Now we need to learn how to deal with software documentation. Papers often have more ideas (if they have it), than data or instructions. Some papers have lots of references and information (e.g. literature reviews) still it is hard to know exactly what “the majority view” or the “most recent consensus view” is. (Programming can help us track down this, as we are going to see later). On the other hand, the instructions tell us what to do step by step. When you read the documentation of software packages the situation is quite strange. Documentation is meant to be read by humans, but actually presents you with the commands and instructions that your machine will execute. It is like you are reading instructions about how to make someone else stick the yellow lego over the red one. So when reading documentation you are reading instructions for the computer and you have to understand why these instructions are valuable for you. Further, these instructions are related to some concepts or tools, but these concepts are kind of presupposed. To abuse the LEGO analogy, sometimes reading a documentation feels like buying the latest “build the Death Star!” pack, opening the pack and finding only a hundred thousands of small pieces. And nothing else. Of course you know what you want to achieve and how your program looks like (it is the Death Star, after all) and of course you have some general idea of the building blocks that you are likely to use and the main blocks that a respected Death Star should have. Still, you thought the package had an instruction book showing you step by step what happens and how to do it. Documentation most of the time documents what’s in the box, but it is up to you to create a Death Star or Tower Bridge. After all, packages and modules are tools you can use as you prefer. They are not packages like “Build the Death Star” they are closer to “All nice permutations and tricks with 3 different colours 4 by 2 blocks”. Your read this, then it’s your turn to (try to) make something. Major packages will have a tutorial or a quick start (or both). These parts of a documentation will help you getting started and correctly installing your tools. A tutorial will also show you a rudimental implementation of the package’s potential. So if you go through the tutorial of Flask (a module that allows you to build web-based applications), you are going to set up a server.11 There are also third party tutorials and demos (i.e. Coursera or Udemy), but that’s another story. In general, the tutorial in the documentation will show you something you can do with the library. Also, GitHub can be searched for documentation, tutorials or code inspiration: it’s the world bank of code, after all. Also, the blogging platform Medium has some good articles and software dedicated publications. 1.4.6 Learn From the Computer Feedback A program gives you a way different feedback from that of a Q&amp;A session after your first explorative talks. A computer program executes your code and it has a terminal (i.e. a window) in which it “communicates” with you. If you are lucky you are going to get the result you wanted. If something goes wrong, you receive error messages. The kind of messages you receive and the information they give you vary a lot across different programming languages and settings, still, it is useful to learn from that. During the HumanDemia training you’ll face some nice errors from Git, where the interface will provide you with tips or suggestions like ‘X is not a git command. Did you mean git X?’. IPython has some nice traceback errors. When compiling documents with a big RStudio project the log of the errors can be a bit terse. A major difference from conferences concerns obvious mistakes. When the shell gives you a precise error message there is no “yeah, I’ll have to think about it” or “you know, as they say, my modus ponens is your modus tollens” or even “let’s agree to disagree” (did you really ever say that?). You have to go there and fix this mistake. Also, conferences can be nice and encouraging to first timers or, if your intentions are good, nobody is going to correct you if you say “X criticizes Y” when everybody knows it goes the other way around (and you are actually reporting Y’s arguments against X). If you call your function that computes Trump’s followers ‘compute_Trump_followers()’ but you’ve called the function ‘compute_trump_followers()’ the machine won’t work. No matter how clear your intentions were. (Yes, Python is CaSe sEnSItiVe). 1.4.7 Ask for Help You are not alone programming. There are many resources and tutorials out there. And there are search engines to find them (enter: Stack Overflow). Besides your favourite seaching activities, be sure to add Stack Overflow to your searches. That’s the place to go for programming questions. If you want to post there, be aware that sometimes answers can be quite direct. Also, try to look for tutorials and resources on GitHub as well. GitHub hosts mostly code, but it features entire cooperative books out there (they can be updated better than printed version - check out the Programming Bitcoin Book, for example), repositories full of resources from programming languages or books in general (look for the EbookFoundation). Further, if you are stuck while coding you may look for similar programming and see if that brings any Eureka! moment to you. 1.4.8 The Importance of (Keyboard) Shortcuts You are going to type quite a lot in different environments. If you look at the hand of proficient people, they know how to type. You can invest some quality time to be more efficient at typing. Also, you should know your shortcuts. You are likely to know ctrl+c and ctrl+v. But do you know how to access the navigation bar of a browser? Or how to split screens or go into fullscreen mode into Acrobat Reader?12 (These will help you if you are in a country with a language intimidating enough to make you realize that you can’t go to full-screen presentation mode without IT assistance.) The best way to practice this is to do without the mouse for a while. Also, feel free to time your performances. It’s not that bad to stick to the keyboard only. 1.4.9 Book Organization and Extra Resources By now you know almost everything about your HumanDemia training. Their instructional department seems pretty good: every chapter has a summary at the end. There are also additional resources and links for the topics covered with book recommendations and tutorials. The further work section has exercises and other things you may consider doing. If there are (keyboard) shortcuts worth knowing, they will be listed as a recap. 1.5 Summary You’ve finished the brochure of the HumanDemia training. You now know what to expect and are happy you have some tools to go through all the material. Some of these tips are not as easy as they seem to be applied practically. (Experimenting, making mistakes, reading the docs, looking for shortcuts.) You know why the kinds here are important for the academia and are welcome to start thinking about your applications. A final piece advice: start small. You’d like to have a machine spotting the 20 best papers out of the 200 last published and presented. But ‘AI’ and ‘machine learning’ are both hard to be programmed and computationally intense to be performed (hours or days, depending on the task and the software). 1.5.1 More Resources Here’s a perspective on how to learn to code https://medium.com/@christianalexanderbonilla/learning-how-to-learn-how-to-program -d3f8b9d37222 (Medium, on the whole, has quite many articles on the topic) In case you missed the search for free programming books on GitHub here’s a lot of stuff: https://github.com/EbookFoundation/free-programming-books/blob/master/free-programming-books.md. There’s quite a lot going on on how to choose a programming language for teaching. Here are some interesting articles: https://blog.janestreet.com/how-to-choose-a-teaching-language/ and https://www.freecodecamp.org/news/what-programming-language-should-i-learn-first-19a33b0a467d/ and also https://www.drdobbs.com/architecture-and-design/software-engineering- computer-science/217701907. Eric Steven Raymond has another great piece about developing an hackinng mentality by way of using the Incremental-Hacking Cycle: here it is http://www.catb.org/~esr/faqs/hacking-howto.html. 1.5.2 Further Work Research the various stuff that’s in the HumanDemia curricula. Try to imagine what the things are about if you don’t know already. Estimate how complex things are going to be. Make a list of the actions you perform most often in front of the screen and learn the shortcuts. Try some: “look, mum, no mouse!” working sessions. See Eric Steven Raymond, How to Learn Hacking, http://www.catb.org/~esr/faqs/hacking-howto.html.↩ A useful tool to get a quick overview of the syntax of something programming related is the “Learn X in Y minutes” website: https://learnxinyminutes.com/.↩ But it will be fun or pedagogically interested. There are resources to learn git in a gamified or at least visual supported way.↩ It’s F7 in RStudio. Yes, get ready for some shortcuts.↩ Feel free to elaborate a way to develop your logging system and bend the tools provided here to your needs. In a way when you start learning you are going to be your main dataset.↩ Sometime Python is referred to as “pseudocode that actually runs”. So it’s not going to be that complex.↩ According to a study, in Italy, ‘technology’ means “something you don’t understand, to achieve something that cannot be done, but that earns you a lot of votes”. Of course the study was never published because of [conspircy theory].↩ Previous drafts had “nor having ideas is a requirement for tenure” in the body of the text.↩ There’s a whole series of learning to program “the hard way” that focuses on writing a lot of code. Maybe you are that kind of learner. You were given a list of irregular verbs to learn. Reading it was pointless, repeating it didn’t help. But you wrote it in your mind by way of writing it 4 times.↩ If you want to jump on Ruby (or rebuild Instragram) there it is https://www.devwalks.com/lets-build-instagram-in-rails-part-1/.↩ Like, super early in the fourth line of the quickstart: https://flask.palletsprojects.com/en/1.1.x/quickstart/#quickstart.↩ Have you ever tried working with two monitors? Programming and editing are different experiences with two screens.↩ "],
["ch2.html", "2 The Universal Typing Machine: Markdown and RStudio 2.1 The Boring Side of Academia 2.2 Installing RStudio 2.3 RStudio Settings: Darkmode and Packages 2.4 RStudio Automation for Humanities: TOCs and Bibliographies 2.5 Markdown Basics 2.6 Comparing this Setup with more Traditional Ones: The Benefits for Academics 2.7 What’s More in RStudio 2.8 RStudio Workflow: Learn, Write, Get It! 2.9 Books with Markdown: the Bookdown Package 2.10 Summary", " 2 The Universal Typing Machine: Markdown and RStudio Your journey at HumanDemia starts in an unexpected way. They want to you to leave behind your wordprocessor. That’s not simply leaving BrandedTextEditor for OpenTextEditor. You are going to write through “a word processor on steroids”. You’ll have your main windows where you write, plus something else, like line control. “If you aim for precision, you’ll love that”. (You may buy into that one.) Further, you are going to write down the specifics of your document. There. At the beginning of your document, not through some window hidden somewhere you’ll forget about it. That’s your first step to learn being procedural. Also, your new typing machine won’t do things you are not telling it to do, like resizing things, switching footnotes or other amenities. On your way down, you are going to learn a markup language you already know (and it’s not HTML). Little by little they’ll get you acquainted with an Integrated Development Environment (IDE), a shell and also the opportunity to execute code. Oh, even if you stop there, you are going to compile to .doc, .pdf, .html, .epub from the same file.13 2.1 The Boring Side of Academia “Formatting and submitting articles, thesis, reviews, etc. should not be how we spend most of our time in academia”. That was on the HumanDemia job ad, and that’s one of the reasons you’ve applied. Unfortunately, in the humanities we struggle to implement peer review, not to mention having clear stylesheets and guidelines to format a paper. Have you ever submitted the same article to different journals all in .doc format, each time dealing with crazy useless specs hard to automate? Been there. Done that. How many files did you have to for that one document sent to four different journals? Maybe you did your share of rebellion. Got into Latex and various .bib plugins. Luckily, there’s a way out to keep the best out of our favourite Mendeley and Latex experience. Further, it extends to Python, Git and other things on the HumanDemia onboarding. Markdown and RStudio come to the rescue. The best of all news is that: we basically know Markdown already. Markdown is a markup (notice the pun) language you need to know. It looks like the internet of the ’90s and early forums. It is also the language of the new web you are about to discover: in fact, most of the readme files on GitHub presenting the instructions of your code are written in Markdown. Also, on Jupyter Notebooks or Google Colab text fields are written in Markdown.14 2.1.1 Sidenote: Survey on Academically Boring Things I’ve conducted a small survey on things in academia that worry us/slow us down and that do not align with our idea of “working in the academia” (Thanks everyone replying to my survey in order to find out more about that, feel free to message me with more suggestions): getting tenured (well, that was not included); waiting for reviewer 2; waiting for someone recovering from missing a deadline; emails; do exams/marking papers for courses you are not teaching; various ways you can be mocked off exceeding those listed here; figuring out a list of n journals to submit our paper; reformatting a paper because reviewer 2 of journal n-1 in the list rejected our paper; getting more data (e.g. papers) from our research; perform a literature review; attending seminars because your boss knows you are going to ask questions (because they make you feel like you’re not wasting time) when you are at seminars you consider a waste of time; meetings; explaining tech stuff to those having double your age. A little bit of coding can account for some of these (as well for other, way bigger issue, like facing impostor syndrome or dealing with perfectionism plus self-underestimation issues, i.e. something will never let you submit your work because it’s either not perfect or, if of decent quality, trivial or not worth publishing.) The Key Idea: “Do Not Sit and Wait, Automate” looks good enough on the on-boarding documents. 2.2 Installing RStudio RStudio is Integrated Development Environment (IDE for short) for R. R is a programming language on its own, used mainly for statistics. Maybe inter-departmental projects led you to bump into R-people.15 Using R you can plot data and analyze them, but we are not interested in that here. Of course, you are encouraged to explore the strengths of R. We are using RStudio as an enhanced text editor. With RStudio we can easily type our Markdown text, and use all the instructions to format a document and manage the bibliography. If you have any experience with LaTeX, the visual impact of RStudio won’t surprise you that much. Plus, through RMarkdown (RStudio version of Markdown) we can access some great tools like rvitae (to write academic resume), blogdown (websites) and bookdown. They target academic needs and the last two packages are documents with books instead of tutorials: super academic friendly! First things first, head over to RStudio download section: https://rstudio.com/products/rstudio/download/. Then pick the relevant version for your system. It’s free (there are also paid versions offering more features). Once you open your first RStudio session go to ‘File’ &gt; ‘New File’ &gt; ‘R Markdown’. Enter ‘title’ and ‘author’ and move forward. You can now see your environment. Most of it is the file you are writing. Let’s briefly go through the main areas. 1. RStudio Open Docs Tab This is where you navigate through your files. You may have more than one file opened at the same time, as you do in the browser. Everything is close by and visually organized. Think about working on different chapters in different tabs, then assemble the whole thing. Now think about doing this in Word. And cry. 2. RStudio Main Working Window That’s right below the list of files. That’s your text editor. This is where you write your stuff. You have line numbers, which is nice if there should be some issue in typesetting your figures, but mainly it’s your Word main page. If you look up in your document you see there is a preamble like LaTeX. The preamble starts after three single lines (like this ‘-’) and finishes again with three lines again ‘—’. That’s the preamble of an empty document: --- title: &quot;Untitled&quot; author: &quot;&quot; date: &quot;13/3/2020&quot; output: html_document --- HTML output is great to make ebooks and compiles faster. If you need a pdf, just replace the output with ‘pdf_document’. Use ‘word_document’ to stick to the boring habits or ‘epub_document’ to get ready to reach ereaders, Kindles, etc. Feel free to add more than one in a raw, but beware of spacing and other issues. The preamble is delicate. You are talking to your machine and everything you type there is sensitive. Feel free to research what you are doing there and what are more commands available. (In the next section we’ll cover adding a little bit more of control to our file, like adding a table of content and adding a bibliography.) RStudio Console Right below the main window, there’s the console. You have a console, a terminal and a panel that shows the status of your R computations (you won’t need that much, unless you are using R for real, doing statistics.) We are going to use the console to install a few packages (like bookdown). You don’t know this yet - see next chapter - but there you have a Command Line Interface (CLI). 4. Managing and Controlling Tools: Right Panel On the right you have two further windows to monitor both the overall installation of R software and packages and the resources of in your folder. The Up-Right table starts with ‘environment’, but you are likely more interested in the ‘History’ tab (showing you the commands you’ve typed) and the Build tab - you can use it to create a book. Down-right you have files, which acts as a file manager. This comes in handy if you are typesetting a book and need to open or delete a preview. With this, RStudio can be your (friendly) panopticon.16 Honorable mentions for the ‘Plots’ tab (though you won’t need it) and the ‘Packages’ tab that lets you know what’s going on with all your packages. 2.3 RStudio Settings: Darkmode and Packages Your eyes are important. If you prefer a dark theme (environmental reasons may play a role as well), you may want to pause for a bit and maybe consider choosing a different theme or background (there’s a dark background). Go to ‘Tools’ &gt; ‘Global Options’ &gt; ‘Apparences’. We are ready to go and start writing some Markdown. Nonetheless, to unleash the full potential of the tools there you may need to boost RStudio with additional resources. I’ve already mentioned packages more than once. Packages are collctions of optional code that allow you to extend the functionality of RStudio. Think browser extensions like and AdBlock (unless you are already using Brave Browser). Here we briefly touch how to install packages, so that you are free to go and add as much as you need to make your best possible work. The console of RStudio is important. This is where you go if you want to edit your package and improve it (something similar to Python PIP install). If you want to figure out what packages are installed you can: go in the Right-down window under the ‘Packages’ tab and inspect it; go in the R Console and type: ‘installed.package(“NAME OF THE PACKAGE”)’ to check if the package is there. To check all installed packages go for: ‘installed.package()’. Finally, to install a package you haven’t installed, type: ‘install.package(“NAME OF THE PACKAGE”)’. (R will access a repository and download it from there. Most of the packages are hosted on something called CRAN.) RConsole is friendly. It is a command-line interface (CLI) tool, we’ll look closer in the next chapter, but it is friendly in telling what went wrong and sometimes it even suggests you your next move (for example: ‘You want me to do X, but in order to that I need Y. Please install Y by doing Z’. - If your colleagues are all as helpful as RStudio console then you’re lucky.) Here are some further resources on R Packages and their installation: https://www.datacamp.com/community/tutorials/r-packages-guide. 2.4 RStudio Automation for Humanities: TOCs and Bibliographies The preamble is where you define all the settings of your document. Things like whether to print a table of contents and how to deal with section headings and numbering, which style of bibliography do you prefer as well as general layout, etc. Here’s a list of some powerful options you have to add below you output choice: toc: TRUE (or yes) – shows toc; toc_depth: value – decide how deep the toc will be; numbered_sections: TRUE – sections are numbered. (Again, ‘TRUE’ being caps-TRUE is important. There are some possible odd things we have to learn to deal with when talking with machines.) Guess what you need to do to avoid showing the table of content or the numbers. As an exercise, write the preamble to that produces a document called ‘RStudio is amazing and I know why’ where you are the author and the day is the current day. You want to print the table of contents without numbers and you want to show sections, subsections and sub-subsections. Ok, below is the code. Ready? --- title: &quot;RStudio is amazing and I know why&quot; author: &quot;Enter your name&quot; date: &quot;enter today&#39;s date&quot; output: html_document: toc: TRUE toc_depth: 3 numbered_sections: FALSE --- (Yes, if you do not want something you use either FALSE or no.) Beware about the formatting. You’re better off nesting all the options and parameters. 2.4.1 Managing Bibliography In the Humanities a huge amount of time is spent (wasted?) in the submit-wait-blame reviewer 2-change the formatting-submit elsewhere cycle. I think the waiting part is probably the worst. RStudio can’t grant you faster responses or better reviews, but it can save you typing time, changing and checking commas and parentheses management when a journal wants you to check that “The article follows author guidance for bibliographies” tick. (Assuming the journal is able to translate its preferences in some sort of standard or known bibliographic style). To add a bibliography all we need to do is to add a ‘bibliography’ parameter in the preamble. That sounds logical. Then we need to specify the formatting style: the information across the different APA, author-date, full cite, Chicago style, etc., references are always the same. What changes is the cosmetics. The concept is super easy. A style file has the needed information to take the raw basic information and apply the relevant cosmetics. Editors are happy they don’t have to check it, we are happy because we gain more time to think and less to dressup our double commas for the next submission. The file containing bibliographic data in a way that can be automatically is the ‘.bib’ file (HumanDemia thinks you are fond enough on file extensions, if not search for it). You can easily write .bib files in a text editor like the Notepad (the one that produces .txt, then you save the file as .bib) but it takes time. It is worth knowing how .bib files are written and what they look like, so that you can tweak them efficiently if you need it. Here’s an explanation of .bib files - https://www.dickimaw-books.com/latex/thesis/html/bibformat.html - they have a lot of horrible {. To produce the .bib file we can make our life easier and use a tool like Mendeley (https://www.mendeley.com/?interaction_required=true) or JabRef (https://www.jabref.org/) or something else. Feel free to do your research and find out what you prefer. If you are lucky some databases (e.g. philpapers.org) allow you to export bibliographies in .bib mode. Both software mentioned above have browser plugins to allow you to retrive biliographical data from the pages you visit. You can work out a comparison on your own.17 Anyway, no matter what tools you are using you’ll find your way to produce your .bib file. Now we have a basic understanding of .bib files. Our goal is to have a .bib file to feed to our preamble. Then, through the preamble, we will manage our bibliographic details and we are going to quote the references through our main document. 2.4.2 Bibliography Template Example Ok, let’s write a working preamble. We add the bibliography field and define a style with ‘csl’ (short for Citation Style Language). Here’s an example: --- title: &quot;RStudio Bib Demo Cas&quot; author: &quot;Guglielmo Feis&quot; date: &quot;&quot; output: pdf_document: default bibliography: demobib.bib csl: europeanjournal.csl abstract: Demo showing RStudio bib management --- In addition to our ordinary parameters we add the ‘bibliography’ field. What follows is the name of the file containing the bibliography (guess what? You’d better put that file in the same folder of your main Markdown file). You can also specify a certain csl, i.e. the citation style language, feel free to read more here about how that works here: https://citationstyles.org/. Just google the csl you need. Different csl means a different look of the references through the document. You just need to find it and type in the right csl. Your bibliography will change accordingly. Say hello to extra time for writing a better paper! To cite the entries in the bibliography you need to use the @syntax (like LaTeX, or mentions in social networks). Suppose there’s a file called ‘myamazing2020paper’ in your .bib file. To quote it, just type @myamazing2020paper and the reference will show up as required. It could be a footnote displaying (Yourname, 2020) or a ‘Yourname (2020)’ or ‘(Yourname 2020)’. It all depends on the csl. At the end you’ll have a list of the files in the bibliography (be sure to add some sort of ‘# References’ section at the end). Beware that @syntax is case sensitive. No typos are allowed and not even confusing ‘Trump2020’ with ‘trump2020’. 2.5 Markdown Basics Time has come to learn some Markdown, i.e. to realize you know it already. Markdown is an easy markup language (think HTML). We type something to get special formatting. Contrary to HTML we don’t have explicit tags like ’ ’ and ’ ’ or ‘’. We are doing most of the marking with signs that are easier to reach like stars * and the (now) over too popular hashtag #. Pipes (|) and hyphens (-) can be used as well, for tables. Ok, time to go into Markdown, the basics are supersimple. If you want to add sections, you number them with a ‘#’. The more you add, the deeper you are going into the sections. So ‘###’ is header3 in HTML or 1.1.1 if you want numbered sections. (There are further options to set this). enclose a word or phrase between one star ‘*’ to get Italics; enclose a word or phrase between two stars ‘**’ to get Bold; Lists are created adding a new line to initialize the list and then listing items either with ‘-’ or numbers followed by a point. Markdown lists: - you need the empty line - above - [ ] this will give you checkboxes And that’s it, basically. You’ll find a full cheatsheet for Markdown at the end of the chapter.18 (Oh, yes, HTML links automatically takes the reference. If you want to add clickable text to the link the syntax is ‘[Text you want to show on the highlighted clickable link] (url of the site you want to link to)’.) Try to type something into Markdown. Maybe a table of contents and a few lines. To have the magic happen you need to build your document. In the preamble you specified the output you want your text to be rendered into. To have such a file it is not enough to save it. Try saving it: the extension is .Rmd which stands for ‘R Markdown’. To go from .Rmd to your .pdf or .html or .epub you need to ‘build’ the document (or compile it, if you come from LaTeX world.) The easiest way to do this know is by pressing the Knit button. (Or ctrl + shift + k, if you are getting used to shortcuts.) RStudio will take some time and produce what you need. If you are outputting to .pdf you’ll realize that RStudio is working with Latex under the hood. Should you miss some packages, you’ll have to install them using R console. (It is likely you’ll need to install.package(‘tinytex’), i.e. RStudio minimal functioning LaTeX. Oh, I wish getting LateX to work was as easy as getting RStudio working and installing an extra package.) 2.5.1 Newlines, Pagebreaks, Cross-references, and further Text Divisions Your text setup may need more operations. Here’s something more. You can search for further options: You can add horizontal lines in your document using six consecutive - or six consecutive ’*’; If you want to insert a page break you have to consider the output you are using. If you are knitting into a pdf (using a tex), you can use the latex command \\newpage or \\pagebreak; If you need to add section references or similar you need to boost your markdown. The easiest option is to install the bookdown package. Once you do so, you can easily refer to sections of your work putting the name of the section between square brackets. Bookdown is also useful to have parts and chapters;19 If you want more layouts you can either choose from a variety of templates (expect LaTeX quality) or go customizing your own templates (see there if you have that need https://bookdown.org/yihui/rmarkdown/template-structure.html). 2.5.2 Creation of Tables Markdown tables are easy to write and cool to watch. You just build the table out of | and -. To define cells are divided by ‘|’. To define a table structure you need to have a set of — under the main table call. Like this | Column heading| | ------------- | # :---: for centered text, ----: for right align | col value | | another value | | etc | Note that you need at least 3 dashes separating each header cell. The outer pipes (|) are optional but looks good. Also, the table will be made even if the pipes are not all vertically aligned. raw Markdown line up prettily. You can also use inline Markdown. If you wrote a big table and want to modify it, that can be harder, especially if you have an empty table you fill little by little. If you have issues, knit the document to help yourself visualize where the modification is going to happen. 2.5.3 Adding Images If you need to add images, the Markdown syntax is close to the one for links: ‘![text of the image if you hover over it with the mouse, aka ’alt text’] (where to find the image)’ Note that the where to find the image can be a url site or a file on your pc. In the latter case, be sure that you are inputting pathnames correctly. Practically: should you get an error, try to change ‘\\’ with ‘/’.20 However, if you are using RStudio to knit your document (and not, say, displaying some text on the internet), RStudio requires you to put the images in the same folder as your main Markdown document. 2.5.4 Cross Referencing If you need to add section references or similar you need to boost your markdown. The easiest option is to install the bookdown package. Once you do so, you can easily refer to sections of your work putting the name of the section between square brackets. See https://bookdown.org/yihui/bookdown/cross-references.html for more. 2.5.5 Adding Code(s) Another benefit or RStudio is that you can insert (and run) code blocks. The code can be Python code, R code (it’s RStudio we are using, after all) and much more. RStudio supports SQL, Java, C++. What’s even better is that you can decide what to do with that code. You can display it and even run it. In that way, if you want to include some fancy graphics that are code-based into your report, you can do that. Further, suppose you are writing a paper with some data. You change the data and all you have to do is refresh your code to have an updated plot. Forget the days of open Word, open Excel, update the chart, export it, remove the old one add the new one. To create a code block all you have to do is typing three backticks (```) - or use the ctrl + alt + i shortcut. The default option is R, but you can change it to your engine (e.g. Python). Given a piece of code (chunk in RStudio jargon), you can select two properties for it: eval: choose if you want the code to be run or not; include: choose if you want to display the code in your document or not. (If you write a tutorial you want to include but not to evaluate the code, but if the code is producing some fancy graphics you just want the updated graph but not code.) Here’s a tutorial like example: ```{python eval=FALSE, include=TRUE}. Be aware that a lot of the extra formatting assistance we are going to have from a dedicated Python editor won’t be there when you type Python code in RStudio. This is particularly important for Python as, in that language, space matters. Should you write some Python in RStudio with the intention to share your code keep that in mind (or learn it the hard way, as it happened to me while proofreading some of the code that follows from chapter 4.) 2.6 Comparing this Setup with more Traditional Ones: The Benefits for Academics Writing Markdown through RStudio offers academics and people working with texts and data a super advantage: the work can be exported as .pdf, .html and .doc. Further, we control the form of the output, whether its a regular text or a slideshow. Besides that, RStudio offers you further tools like control on the bibliography that you can print in different styles by changing a parameter (think LaTeX). Plus you get themes and layouts. After this dense exploration you may wonder why you have to switch to that setup rather than the standard Word-powered one. There’s a lot going on, I’ll limit it to a few bullets. You can speed up the resubmit process. Change the csl and you’re done. No more years spent with fixing details in Word (been there, done that). You can do a bit of that with bib managing tools in Word but my experience with them over a 10 pages project becomes a nightmare. And it gets worst if your work is shared. (The above leads to a better planning for your journal trajectories. You’ll appreciate editors that know their preferences and can point you to the right bib style or csl. If they don’t know that they are probably an Island and not worth your time.) You can export to all outputs. You’ll want HTML if you want to use Amazon Kindlegen and get a smooth transition to mobi format. You’d like to go from a pdf to a doc if you are unlucky and your nice latex-based Ph.D. dissertation falls prey of strange academic publishing standards (been here, hated that). Latex to Word is hard, here you have the Markdown layer that has all the features you need and is able to output in different ways. Given the success of GitHub and the issues with peer review and academic publishing (enter your favourite) we may envisage a day in which GitHub enters Humanities. Guess what is the language of text documents on GitHub. The whole thing is free. Ask your head of Department (if she knows it) how much your University spends on licenses. Translate this into semi-decent research fellows or imagine how a share of that may impact your university’s output. Then please take action and let me know about it. Bonus point: Markdown looks more user-friendly than LaTeX if you’ve been a forum early adopter. It goes easy on \\ and {}. 2.7 What’s More in RStudio We are using RStudio as a Universal Typing Machine, but it offers much more. As we know already RStudio is way more than a cool markdown text editor. Besides its markdown capabilities and its R-based features RStudio also offers the following features you may want to check: shiny app: a nice tool to develop apps that show data on the web. To quote from their website “Shiny is an R package that makes it easy to build interactive web apps straight from R. You can host standalone apps on a webpage or embed them in R Markdown documents or build dashboards. You can also extend your Shiny apps with CSS themes, html widgets, and JavaScript actions”. learn R and develop in R: R is a whole programming language on it own that was (and maybe is) very powerful and suited for statistics. (R also has a whole document documenting some of its issues as a programming language, see the ‘The R Inferno’ document at https://www.burns-stat.com/pages/Tutor/R_inferno.pdf.) use RStudio as a text editor for other programming languages: RStudio allows you to include code boxes from other languages (Python, SQL, JS, C++). This is great if you want to show your code and discuss it. You can also run your code in other languages, but you have to consider whether to use different tools for different programming languages. 2.8 RStudio Workflow: Learn, Write, Get It! RStudio prompts a nice workflow in which you can write your notes and then move them into different documents. You can have code inside them, so it works perfectly to learn to code. Feel free to take notes of this book on that system. You can even use RStudio to type in and run some Python code. 2.9 Books with Markdown: the Bookdown Package The Bookdown package is there to boost your abilities in writing and delivering research products. If you feel restricted by documents, the package has everything you need to make your book come true. Further, getting the bookdown package to work is a useful exercise to review what we know about RStudio. 2.9.1 Installing Bookdown The first step is to get the package. That’s easy. You know both the name of the package and the command to install a new package. See you in the next step! 2.9.2 Setting Up a Bookdown-book Working in bookdown will change our setup a little bit. The bookdown packages allows you to write dedicated .Rmd chapters and then compile them. This requires us to set up properly: instead of single files, create an Rproject: ‘File -&gt; New Project’; bookdown starts compiling the book from a file called ‘index.Rmd’. All the other files ending with .Rmd in the folder of the index are then rendered and included; organize the folder and the naming accordingly; if you need extra .Rmd files, like a list of checks, a bin of leftovers be sure to include in a dedicated folder. Otherwise they’ll get into your main file. For the bookdown file to work, you need other little twists. Instead of knitting you can try Right-Up building options. Still, that works best is to compile your book from the console with the following command: bookdown::render_book(“index.Rmd”, “bookdown::pdf_book”). The other big change is that only the index file will have the preamble. All the other documents, i.e. the chapters, are going to start directly with ‘# chapter’s title’. And, in a chapter, you are allowed only one level one ‘#’. If you need to insert parts, the syntax is the following: ‘# (PART) Part’s name {-}’. The part name has to be inserted at the end of the chapter that comes before the part. 2.9.3 Bookdown Mechanics When you run the command to render the book you specify the index file and the format you want. Bookdown will merge and render your dedicated output. Should something go wrong, you’ll get either instructions in the console or a specific log file as a .txt file. What RStudio does is creating a ’_main.Rmd’ file and try to compile it. If there are issues and line references, they refer to the main.Rmd. That’s why there’s an error at line 2023 despite your chapter being 456 lines long. Before recompiling you have to delete the temporary ’_main.Rmd’. That’s where the Right-Down ‘Files’ view comes in handy. Bookdown is well documented (see more resources). 2.10 Summary The preamble is where most of our magic typewriting happens. We need to feed it a .bib file and a .csl style file. The .bib can be built with Mendeley or JabRef (or by hand). Markdown is easy. If you need to build a whole book, you can use Bookdown. If you need a website, try blogdown. Now you should orientate yourself in an RStudio session, write in Markdown and create simple preambles. 2.10.1 List of RStudio Shortcuts Shortcuts can save a lot of time. With RStudio you are likely to be doing some operations quite a lot, so here are the relevant shortcuts: open a new file: ‘ALT + F’ (then navigate on new file and choose what you need); navigate across markdown files: ‘CTRL + ALT + left/right arrow’; knit the document: ‘CTRL + ALT + K’. next RStudio tab ctrl + tab; previous RStudio tab crtl + shift + tab; knit: ctrl + shift + k; insert code block: ctrl + alt + i zoom in: CTRL + + (sometimes you may accidentally hit + instead of * when you try to add italics); zoome out: CTRL + - (when the above happens, this will bring you back to ordinary conditions). 2.10.2 More Resources Here a few links for more bib-related stuff: More Info on Bib Styles: https://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html More Info on Citations Styles: https://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html#citation_syntax Moving to Markdown: Here’s the promised MarkDown cheatsheet: https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) Yihui book’s on Bookdown is probably your best introduction to Markdown and bookdown: https://bookdown.org/yihui/bookdown/cross-references.html. You can even check the Github version of the boo and contribute to it. https://monashbioinformaticsplatform.github.io/2017-11-16-open-science-training/topics/rmarkdown.html https://rmarkdown.rstudio.com/lesson-1.html 2.10.3 Further Work Here are some idea to practice the things we mentioned here: set up a book template; look into the bookdown documentation; go into RVitae Package; RStudio exports to epub. Still, Amazon Kindle uses a different format, .mobi. If you want to produce a mobi file you can use both .html or .epub outputs and feed them to Amazon Kindlegen software. It just takes a command-line command to do that (compare this to a Calibre workflow). Do some research on Kindlegen. Produce one or more RStudio-based .epub or HTML and get ready for launching the Kindlegen-based command line interface from the next chapter; move to the next step and explore making Blogs and Websites with Blogdown. So, next time you have to write a book nobody wanted to read (and you didn’t want to write) because of the new rules of academic recruitment, you know how to write it.↩ If you have some data science ambitions, it would be cool to test the following hypothesis: there are more freely available books out there in Markdown format than in .doc.↩ Joel Grus has some code-humor on R and Python for data science.↩ Shame moment: before I discovered that, I spent a lot of time getting out of RStudio, searching folders in the resource manager and then back to RStudio.↩ Mendeley has Springer involved with it. JabRef is an open source, you can see the code and solve issues on GitHub (it’s Java-based). I sorted out an issue with a huge .bib file using JabRef. I then build a new bib base with Mendeley relying on the plug-in mainly, which worked decently enough. The Mendeley-Word integration worked but not that smoothly.↩ Remember the Learn X in Y Minutes? That’s the markdown part: https://learnxinyminutes.com/docs/markdown/.↩ And footnotes using this caret (‘^’) and square brackets format, which may appear strange on GitHub.↩ Unix, Mac and Windows follows different conventions to manage paths on the file systems. So if you think the biggest irrationality was that of different pins, sockets and voltage maybe you have to review some beliefs. Maybe.↩ "],
["ch3.html", "3 Command Line Interface and Git(Hub): Get Ready for Machine Talk and Cooperating with the World 3.1 Command Line Essentials 3.2 Version Control with Git 3.3 Installing Git (on Windows) 3.4 Git Operations and Mechanics 3.5 GitHub for the Humanities 3.6 Summary", " 3 Command Line Interface and Git(Hub): Get Ready for Machine Talk and Cooperating with the World Your second installment in the HumanDemia onboard is designed to bring you back to the roots of human-machine interactions. Command-Line Interfaces (CLI) are a primary tool to communicate with machines. Instead of pointing, clicking or touching (graphics stuff of a GUI) you simply write down what do you want your machine to do. Of course you need to agree on some language, which forces you to know what the machine can recognize as a proper command. “This sounds so much like the beginning of The Matrix”, you think. Now, The Matrix is cool - but it is already dated. Still, CLI is even more old school, retro or date (your choice). Neil Stephenson has a terribly good book called In the Begining was the Command Line - the book is on the Cyberpunk library for free: http://project.cyberpunk.ru/lib/in_the_beginning_was_the_command_line/ (you have to read it and, by the end of this book, you should be able to have it in the format you prefer to read it). Stephenson’s title proves the point: this CLI thing is old. This is how (quite a lot of) it started. “Why do the folks of HumanDemia bother me with that old stuff? Isn’t there something more techy and in demand to learn?,” you wonder, despite appreciating being philologically right and going back to where things started. As we’re going to find out, there are CLIs in most of the hyped in demand words you may have thought about. From GitHub, where you’ll share your marvelous applications with the world, to Python programming, R programming or SQL querying. You simply need this and, well, you have already saw some command-line machinery in the previous chapter when packages were installed in R. TL;DR: file operations require some command of command-line navigation (no pun). Updating and installing packages or modules to programming language are command-line based. Further, especially in non-Windows systems, a lot of file and system operations happen in the terminal, the shell or bash… which are command-line interfaces. Ok, let’s dive in this Stephensonian thing: first, we are going to refresh some command-line essentials; then we’ll dive into some GitHub operations. 3.1 Command Line Essentials Do you remember the old days of MS-DOS or Windows 3.1? If you don’t, that’s a short summary of what these days were like.21 Imagine a Matrix-like scenario. There’s a blinking prompt in the up left corner of the screen. But it’s black and white. It says C:\\. Mum and dad told you have to type ‘win’ to start Windows 3.1. There a magic graphic interface appeared. There was a ‘File Manager’ icon looking like an Ikea drawer which did what you now do under ‘This PC’, and there were accessories, games and applications. Mum and dad also told you not to run ‘format C:’, as it canceled all the stuff on the hard drive. And they were right. 3.1.1 Navigating File System with the Command-Line To appreciate what is it like to use a command-line interface think about operating with your computer without using the mouse. This is something you have already experienced in the exercises about practicing the shortcuts. Now, think about this: suppose you want to run a program without the mouse. Of course you can easily navigate on an icon, press enter and run it. But what if there’s no icon or if the path to the exe is far far away? Part of the workflow in command-line system is this: reach the proper folder/directory on your hard drive; run the commands you need in that folder (e.g. run notepad). The first part is all about managing paths and is most of the command line jobs you are going to perform. The second is often where the command line blends into programming or something else. In fact, you are going to use program-specific commands. On Windows 10 there’s a specific CLI called Power Shell - you can search for it with the (WinCmd + S shortcut). While you think that’s gonna be easy you find yourself whispering “curved balls”. The next paragraph of the HumanDemia docs looks like the following. Summon the shell and try to solve the following tasks: navigate to the download folder; list all the files in the download folder; go into your main working directory (i.e. where you have papers and programs) and open one of your recent works. No mouse and no graphics feedback. You are only going to read and type in the prompt. Ok, to complete the tasks above there are some backups for you. The most common operations on various CLI are the following: change a directory: this is done with cd [where to go]. Back in the days maybe you have something like ‘cd windows’. You got to ‘C:\\Windows\\’. And from there if you type ‘SimCity’ you had a game to be played. list files in a directory: you just landed into a new folder and have no idea about its content. Type ‘dir’ to find out. get back one step in the path hierarchy: suppose you are down into a very long path like ‘Your Drive\\A folder\\Another folder\\A program\\A program subfolder\\Something Else\\It should be here\\But it’s not in this folder\\’. Suppose you want to go back higher in the ‘it should be here’ folder. You can either type the same cd path and cut the last part. But you can use ‘cd ..’. The two dots will put you up in the hierarchy. create (make) a new directory: you are now a command-line wizard. You navigate do the path you want, know how to run the different relevant commands, but realize you need a new folder before opening a Jupyter Notebook? mk dir is the command for you. Cool, you can now move around directories, list them and create new directories. That’s enough to be dangerous and, from there, you can explore for more (have a look online at shell scripts to learn further tricks). There are a few things worth knowing if you are moving towards the command line: the kind of machine you operate on matters. Windows has paths with this slash \\. Unix, Mac and Linux go with this ather slash /. This will matter if you install a Git client that works as if it was Unix. (I.e.: something we are going to make in a while.) different command lines tools may use different shortcuts for useful operations like copy and pasting. If you want to copy a git command into https://git-scm.com/download/win you may have to use SHIFT + INS instead of CTRL + C. in the command line the star character * will match everything (see later on when we are going to talk about regular expressions*). This feature will be useful in a while when you are going to commit only your Python and Markdown files, i.e. those ending with .Rmd and .py. 3.2 Version Control with Git Git is a version control system. Think about it as a form of Dropbox on steroids or some enhanced Google Drive. Forget shared spreadsheets, common folders or databases with modifications. Git will do it for you: it will save every change you make and it will allow all your team-mates to see what you did. If something gets screwed on the way, you can rollback. You can freeze instances of your files and their state. If you and your colleagues work on something and then discover your Department webpages is horrible in its version 7.41 and need to go back to the 1.23 one you go back there and restore it. It’s like rolling back your holiday photo album, with perfect annotations. Can we get the picture of me wearing the black coat on the sea after we went for a pint? Yes, that level of details. Git is also where you cooperate with people and make your files accessible to others. Random strangers (if you want to) can see your files and then contribute changes to them. You can review them and, if you like what you see, accept the change. Think about people reading your papers, checking the data (if any) and being able to fix typos without the need to download the paper, send you an email, you opening the mail, fixing the typo, re-uploading the paper, etc. Not to mention that, well, if your paper is somewhere onto a journal chances are you are not able to fix the typo. If this sounds too complex or too good to be true, Git is nothing but a command-line interface tool. You are going to open a terminal (by now you know terminal or bash or shell are kinda equal) and type your commands there. Fun facts: git shell is extremely user friendly (in terms of how friendly a CLI can be); git-related commands in the git shell start with ‘git’. In an organization collaborating and developing things git can’t be avoided. If it is, either there’s something similar in use or nightmares are gonna be there. 3.3 Installing Git (on Windows) To access this magic-git world we have to install it. You’ve been warned: “First weeks at HumanDemia are going to involve quite some installing tools”. To download git, head over there and pick you the version you like the most (a download should start automatically): https://git-scm.com/download/win. As you finish installing in, as soon as you right-click into a folder, you are given to extra options: git GUI here; git BASH here. You know which one to choose. The ‘here’ means ‘in the path you are right-clicking into’. 3.3.1 Git and GitHub Before moving on we need to clear this: what’s the relationship between Git and GitHub?22 This time we are quite lucky. Git is the version control system technology. This is how you manage your files and projects. Once you have the Git client installed - what we installed in the previous section - you are ready to unleash the git powers. GitHub is the social version of Git in the form of a web-based platform where you host your repositories using Git commands. Hosting your repository on an extra platform allows you to back up your files, access them from any machine, etc. On GitHub you can have both private and public repositories and, if you work as a big team, institution or organization, you may use an ad-hoc account with further tools to manage more people. GitHub is also a kind of social network for developers and a library of code. Git powers your interaction with the repositories: updating files, modifying them, etc. The kind of code on GitHub varies: you can use git commands to push into your repository (hard git jargon here) all kinds of files, from Python to Java, to SQL, Ruby and also .doc files if you want. Also, most of the instructions and textual files there are written in markdown, so your previous week building HumanDemia Universal Typing Machine was well spent. If you have already head over GitHub you know that there you find repositories. Repositories are the main containers on GitHub. You put your files there and organize them. They are your folders and allows you too have version control. Besides creating your own folder, you can browse other people’s folders, look into them and do stuff with their files. You can copy these files (clone in Git jargon) and you can contribute the projects (which requires you to fork the repository). 3.4 Git Operations and Mechanics Ok, now we have a git terminal installed. We know: that we can call it by ‘git BASH here’; that git commands start with git. The next step is to figure out what we need to type after the git key, to have something git-related happen. Before moving on, setting up a GitHub account to experiment with would be cool. 3.4.1 Creating a New Repository and Add Contents It is time to start using GitHub. Here’s a condensed summary. Remember that if you need further help the documents on GitHub are great, check them out (https://help.github.com/en/github).23 The basic operations we are interested in are the following: creating a repository; importing a project on GitHub with the command line; cloning a repository; sending content to a repository; forking a repository and contributing with pull requests. The easiest procedure to create a repository looks like that: go on your GitHub page, up on the right there’s your profile menu. Clik on repository. create a new repository: there’s a green ‘New’ button that wants you to click on it. open it: that’s self-explaining. clone it: Git-jargon to say copy (no Blade Runner here), this requires further steps; add files to the repository (see in a while). 3.4.2 Copies on Git: the ‘git clone’ Command ‘Clone’ and ‘cloning’ are git essentials. When you (git) clone something you are making a copy of something that is on git onto your hard disk. The command is pretty straight forward. The operations you want to do is clone. You are running a command in the git shell, so you know that the magic formula to obtain what you want has to be ‘git’ + what you want to do. So here we want: git clone. This tells the shell to download a copy in the folder you opened git into. What’s missing is the url of the repository. So if you want to download the impressive list of free programming books by the EbookFoundation you need to type the following: git clone https://github.com/EbookFoundation/free-programming-books.git. This will create a folder called ‘free-programming-books’ with all the contents. Summing up, to clone the repository you need to: copy the https of the repository you’ve just created; go into a directory you want the repository to appear (bonus points if you are doing this in command-line); git bash into it: this is where the command-line comes in. Now we are in the Git BASH shell; type “git clone [yourrepositorynamehttps you had in step 1]”. You are now invoking a specific command - git clone - and the shell knows what to do with it. Now bash can make you a sandwich. Congratulations, you’ve cloned your repository! (Spoiler time: cloning will also play a role when you want to send changes to someone else’s work. In fact, you’ll need to fork (Git jargon, again) the repository you want to contribute to and then clone it. Once you are done with that, you can commit your work to the repository. Once this is done you can compare and contrast what’s going on: if you added files, deleted some or modified something. All your history will be saved and you can go back to the picture you like the most.) 3.4.3 A Practical Cloning Example Ok, let’s have a practical example. Suppose you bought Joel Grus’s Data Science from Scratch (which you should read). You create a folder on your desktop to work on the contents of the book. Bonus points if you used a ‘mkdir’. There you plan to copy some examples, develop some projects, etc. Then you realize Joel has all the code for the book in a GitHub repository and decide to get it. Here’s what you have to do: go into the folder you created for the book, e.g. “C:\\DSscratch” right-click and select ‘git bash there’ clone the repository, i.e. type ‘git clone’ https://github.com/joelgrus/data-science-from-scratch.git (that’s the link you get in Joel’s book repository - notice something going on with slashes…). 3.4.4 Git: Pushing New Contents into your Projects with ‘git push’ Push is the Git jargon to say you are contributing content to a repository. To do that you first have to tell git that a certain file needs to be tracked by git. The relevant command is: git add [filename]. Through git add you are going to include a file to tracking and version controlling. Git will take care of all the pictures in which the file appears, to keep using the photo book analogy. Once you have added the files you want to add to your repository, type git status. You should see why the git shell is user friendly. The command shows the status of your folder: which files of those present in the folder are tracked (green) and which are not (red). The shell also tells you what to do to remove a file from tracking (‘git unstage’) and to add more files (‘git add’, again). Adding is not enough. Going back to our picture analogy, you have the picture that you want to store in the repository. But maybe that’s not the right one you may take another one and another one. To put the photo in place you need to do two more options. Once you are ready and sure you’ve added all the relevant stuff, you can commit your additions and changes. Go: git commit -m “message”. The -m and message are there to simplify your future work. You want to clearly say what you did. Did you add a functionality? Clean the codebase? Add a picture? That’s your commit message. Only now you are ready to push it. So: git push. You’ll see git sending your files to the repository. In case you are committing a file with the same name as something already in the repository, git will check for differences and merge them. Your latest committed file will rule over the one present before. In this way, git will check for merge conflicts and, if something calls for your attention, it will ask you to choose. Remember that git can be used in teamwork. Suppose you modify something and also someone else in the team committed changes to the main project. Alas, your change and that of your colleague are conflicting. What should you do? Summing up, this is how you put content on your repository (‘repo’ in git talk): git status: check for differences; git add: add all the files; git status: check you’ve added the right stuff; git commit -m“write the commit message”: this message will help you reconstruct your history of changes and development; git status: check everything is right; git push: actually pushing (and storing) the stuff you have committed. 3.4.5 Adding Files Matching Certain Conditions Adding files one by one can be boring. Imagine you have a book with 10 chapters. Do you really have to type ‘git add [filename]’ for 10 times? The git shell is CaSeSensitVE so there are changes you are going to make typos (fit add is my favourite). Luckily, when we installed git shell we get a whole command-line interface that is Unix-based. This gives us access to powerful commands. The first is the * star character which means ‘whatever’, ‘everything’ or other ways that helps you to conceive ‘all’. In our 10-chapters book scenario, it means that you can type: git add * and you will add all the files. This is a nice solution, but it can be problematic. What if you do not want to add all the stuff but only a part of it? Maybe your folder has both .Rmd files and .pdf, .html and .docs. You want to add only the markdown sources. How can you do that? The * comes useful. You want to add whatever ends come before the proper file extension, namely: *.Rmd. Once you’ve found this out, you can type it in your git add query: git add *.Rmd (adds all files ending in .Rmd). Check that it works with ‘git status’ and be happy about that. There are two further elements in a git repository worth knowing: git ignore file(s); readme file. The first can ease up the task we did right now, the second details the scope of the repo. 3.4.6 Git Ignore If you are working on a project with many files that have a different extension and you only care about selecting a few of the files, there can be better ways than using small selecting bash commands with the * character. What if you could tell git to ignore certain files? (E.g. all the pdf and doc outputs of your book, all the files in the resources folder, etc.) Git comes to the rescue with a specific file, the gitignore file. A git ignore is a file that tells git not to consider certain files when you perform a git add operation. You may need this to avoid that some auxiliary files that are due to compiling or execution are added to version control, or you don’t want to commit some data that you keep local. Git ignore files have their own syntax and rules, see here https://git-scm.com/docs/gitignore. Note that if you want GitHub to render your Markdown the files need to end in .md and not in .Rmd.24 3.4.7 Git Readme If you go on GitHub and create a repository there, it will tell you to initialize it with a Readme file. Readme files are written in markdown and GitHub renders them automatically. You can use the file as you first commit. When people visit your repository the readme is displayed and rendered. Use a readme file to tell people about your project. What is its development status, where to find the documentation to use it and how to contribute to your project. 3.4.8 Forking and Contributing to a Project: Pull Requests Forking combines all the operations we did up until now. When you fork you are creating a further copy on GitHub. You use your forked repository as you did with your previous ones. You can then select some of the work you did and push it from you forked branch to the main branch (i.e. the one you forked). This is called pull request in git jargon. Once you do that the owner of the forked repository will evaluate your changes and decide whether to accept your pull request or not. If this sounds all too technical and scary GitHub has more than one project to help you make your first forked contribution without fearing of messing around a complex database. Here’s the tutorial for first Git contribution via pull-request: https://github.com/firstcontributions/first-contributions#tutorials-using-other-tools. 3.4.9 Merging and Conflict Resolution The same file may be modified in conflicting ways. You’ll notice the conflict when you type ‘git status’: you’ll be reported “unmerged paths”. Your task is: identify the file; fix the merge conflict; commit the chosen version of the file that removes the conflict. We already know how to make a commit. We can easily see what’s the file with a merge commit: ‘git status’ will tell us at the end. All we need is to figure out how to find the merge issue and fix it. All we need is a text editor and to open the relevant file. Conflicts are displayed with the following syntax: &lt;&lt;&lt;&lt;&lt;&lt;&lt; - marks the beginning of a conflict; ======= - divides the options: the text above it is what is in your proposal, the one below it is in the other proposal; &gt;&gt;&gt;&gt;&gt;&gt;&gt; - signals the end of a conflict. All you have to do is to pick one of the two and then remove the crutches that signaled it. Then you are ready to commit your solution. (That’s the easiest case of conflict: things can get more complex if they involve removing files, like you updated the OLD draft paper and your co-authored worked on the newer draft and, being the efficient co-author she is, delete the old one. No panic, here’s how to fix that: https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/resolving-a-merge-conflict-using-the-command-line#removed-file-merge-conflicts, Git stores it all.) 3.5 GitHub for the Humanities “Wunderbar,” you think. You are leveling up your Git-fu, still, you are wondering why HumanDemia cares about Git and GitHub. Ok, it’s a cool skill to have; ok, you can remove shared calendars and other bad stuff from your academic routine. But aren’t there already social networks for academics? What are we leveling up, if any? Well, it looks like they are advocating quite a bigger change. These are their pleas for GitHub: everything you find on [Enter your favourite academic social network] is behind a log wall. People can’t see, people can’t read. On GitHub, you can read and browse repositories even if you are not registered on git. Logging in is required to edit and submit pull requests. Further, assume someone reads your stuff and sees a typo. Are they going to write you an email about that? Maybe not. What if people reading and spotting a typo could notify you and you have the opportunity to accept their suggestion without any boring reopening of the file, correcting it, etc.? GitHub makes this all possible and leightweight. Ok, forking a paper to notify a typo is arguably not GitHub standard usage. But notifying bugs and developing projects is the standard. Academia-wise, papers are projects and typos are little bugs. GitHub is changing and evolving. Humanities and academia are… maybe. Why can’t we think of GitHub as the place to host collaborative drafts?25 Try this and use it in your next grant under the heading of cooperation and dissemination. It takes a little effort and opens new opportunities. At least it brings your dropbox and stuff to the next level. 3.6 Summary Chapter 3 was all about command-line interfaces and Git. You installed a git client and refreshed CLI operations. Cloning, forking, git push, and git pull are no longer a mystery for you. Then there are other git commands. 3.6.1 List of Git Commands and CLI Commands Here are the Git commands we should be familiar with: git add git status git push git pull git commit -m “message to commit” Besides these git-commands you have refreshed/learnt some of these command-line magic: dir cd ‘..’ ‘.’ And learnt to use the star character (*) to match all files having a certain ending. 3.6.2 Shortcuts As far as shortcuts are concerned: WinCmd + S: open Windows search bar (e.g.: to run the Shell) SHIFT + INS: past on Unix (i.e. CTRL + V) Command-line commands do not qualify as shortcuts, but you may imagine them as such as they shorten the word they refer to. It is never the case you refresh them enough: dir cd ‘..’ ‘.’ 3.6.3 More Resources If you feel already a bit confidente about your Git Fu and want to go practice right away with graphical feedback check this out: https://learngitbranching.js.org/. The Learn enough tutorials are close in spirit to what HumanDemia wants you t be able to do. The good news is that there’s a “Learn Enough Command Line to Be Dangerous” https://www.learnenough.com/command-line-tutorial/basics The Pro Git book (https://git-scm.com/book/en/v2) is free and will teach you everything Git related. Internals are revealed and blackboxes are cracked opened. Nice tutorial on using GitHub and sharing code in your organization. Show it to your team, faculty and Dean: https://towardsdatascience.com/towards-open-health-analytics-our-guide-to-sharing-code-safely-on- github-5d1e018897cb (At HumanDemia they are doing it already) The Git cheat sheet is something useful to read and bookmark: help yourself here: https://github.github.com/training-kit/downloads/github-git-cheat-sheet/. That’s the tutorial for first Git contribution via pull-request: https://github.com/firstcontributions/first-contributions#tutorials-using-other -tools The programming book for the Arcade library (yes, use Python to program videogames!) have a wonderful tutorial for some git setup and git cloning operations. Still, they use Bit Bucket instead of GitHub. https://arcade-book.readthedocs.io/en/latest/chapters/04_version_control/index.html Python migrated its code development process on GitHub with a specific Python Enhancement Proposal (PEP) 512: https://www.python.org/dev/peps/pep-0512/. 3.6.4 Further Work There is quite a lot you can do to practice Git-fu: Create a repository (maybe a private one). Add some content there. Try the first contribution tutorial. Clone the free programming resources repository (if you haven’t already): https://github.com/firstcontributions/first-contributions#tutorials-using-other-tools). Create a conflict in one of your repositories and fix it. (To do that you’ll need to create to branches on your own. Yep, curved ball!) Persuade a colleague and/or friend to embark on this Git thing. Tell them to buy the book. Use git as a logger for your reading group and to develop further experiments. If something good comes out of that, fork the book repository file and contribute. Practice graphically on https://learngitbranching.js.org/. We discussed walking through a file path and listing contents with dir. It’s time to look ahead into Python and practice some reading the documentation. Have a look at the os module (i.e. the one about operative system) and check what os.listdir() and os.walk() do: https://docs.python.org/3/library/os.html (feel free to read the rest of the documentation, but focus on the two mentioned functions). If you feel nostalgic you can bring these days back with Freedos: https://www.freedos.org/. ↩ IT and programming stuff are full of names looking close to each other, like Java and JavaScript, R and RStudio, etc. There’s also a wonderful meme explaining the difference and/or relationship between Git and GitHub. Feel free to look for it.↩ Good documentation is fundamental if you want an open project to have an impact. And that’s great for us to have great documentation to learn from. The issue is learning how to learn from the documentation.↩ At least as of the time of my writing and committing this.↩ ArXiV papers and papers storing databases link to GitHub. GitHub hosts Jupyter notebooks with conference presentations. It seems that we don’t need a new vision or a highly innovative insight. Looking what’s around and connecting the dots should be enough.↩ "],
["ch4.html", "4 Getting Started with Python: Anaconda, Jupyter Notebooks, Google CoLabs and Virtual Environments 4.1 Installing Python by Installing Anaconda: A Game of Snakes 4.2 Using and Integrated Development Editor (IDE): The Benefits of Spyder 4.3 IPython 4.4 Jupyter Notebooks 4.5 Command Line in Action: the Anaconda Prompt 4.6 Google CoLab or Python on the web 4.7 Virtual Environments: Preview into Coding Best Practices 4.8 Summary", " 4 Getting Started with Python: Anaconda, Jupyter Notebooks, Google CoLabs and Virtual Environments This is the last module in your HumanDemia on board. After that, most of the boring stuff will be completed. The environment will be set and you’ll be ready to use these new tools to build something and make your life easier. In this chapter we are summing up what we did in the two chapters before. We need to install our Python development environment (in chapter 2 we used RStudio as an IDE for Markdown). Here we are going to play a game of snakes, and install Python by using the Anaconda distribution. Through Anaconda we are going to get the following: access to the Python programming language; and IDE for Python: Spyder; a packet manager for Python: the Anaconda installer (conda install); another command line interface tool: the Anaconda Prompt; the full stack of Python scientific libraries and data analysis libraries (this is going to save us some installation pain): Numpy, Pandas, matplotlib and more; IPython: a nice interactive shell to program in real time that we’ve already mentioned; Jupyter Notebooks: shared work books of Python code - think of them as a git hubbed version of IPython sessions. As you see, IDE tools (chapter 2) and command line tools (chapter 3) sum up here nicely, to give us Python. The path for this chapter features installing Anaconda, explaining its benefits and then provide details about Google Colab, another tool to perform Python based operations, this time without the need to install any code. There are no excuses not to code. HumanDemia has another curved ball waiting you at the end of the chapter: virtual environments. Virtual Environments are isolated containers in which you install all the tools you need to run your program in a safe way, i.e. without interacting with the rest of your system. You don’t want an update to Steam to mess up your project, right? Virtual environments are there to ensure this. That’s one of the coding best practices that the sooner you learn, the better it is. Also, it is something you are going to perform in the Anaconda Prompt. So it is a nice way to sum part I up. “Command line operations of an IDE for something Python related,” you mormor “these HumanDemia instructional designer have their idea of balance!” 4.1 Installing Python by Installing Anaconda: A Game of Snakes Back in the days if you wanted to start Python you had to to a lot of researches. There were two main running versions of the language: Python 2 and Python 3. Some of the syntax was different (i.e. how to print on the screen), some of the main tools were only running on one Python version, etc. Today you can save all this struggles. Go and install Python 3 (unless you have a reason to still use Python 2, which should not be the case if you are starting out). Despite the Python versions struggle being over, getting started with Python still has a counterintuitive issue. The best way to get started with Python is not installing Python. Rather, to install Python you have to search ‘Anaconda’. As the snake-based name suggests, Anaconda is related to Python. With Anaconda you are going to install Python and more (which is good, as it saves us installation pains). Installing Anaconda is as easy as to go to https://www.anaconda.com/distribution/ and download the relevant distribution for your computer.26 Basically while installing Anaconda you will be asked: where to install it; if you want Anaconda to be the default program to run Python files; how to interact with PATH variables. If there’s something confusing, the answer is in the installation documentation.27 Ok, now you should have Anaconda installed which means you have Python! Programming is close. If you are impatient and want to start having a look at your IDE for Python, search for “spyder” in your system search box. You will then run the Spyder. (Oh, Spyder is another acronym for ‘Scientific PYthon Development EnviRonment’). If you are not that impatient, we’ll first have a brief tour of: the benefits of using an IDE (like Spyder) and the other tools provided by Anaconda, namely: IPython; Jupyter Notebooks; the Anaconda system (package manager and command line interface) 4.2 Using and Integrated Development Editor (IDE): The Benefits of Spyder Spyder offers a lot of benefits. The one I’ve found the most useful is that you can divide your workspace in different cells. Each cell allows you to run Python code. The importance of running more Python code cells is that you can have a main cell where most of the program lives and as many cells as you need to experiment. If you need to add a new feature to the main program you can test it in the cell, and then include it.28 Plus, Spyder supports you when you are typing the commands. Press ‘TAB’ and it will offer you suggestions about what you can do with certain objects. This also helps you learning. Spyder knows your object is a string and will show you the available methods. As you move your first steps into programming it is likely that make various syntax errors and helps you indent your code properly. Spyder checks your syntax and it can check it also against some formatting rules and styles (most notably, PEP 8 style).29 This can be a double-edged sword. As you are about to know, indentation matters a lot in Python. Tabs and spaces are different and you have to be consistent. Spyder handles this for you, which is cool. You can focus on learning the syntax and approach your problems. But then sometimes you have to start coding in notepad or something else and formatting errors come in from everywhere. I guess this tells us that we need to be aware and grateful for the amenities an IDE can do, but not to get enslaved by them. Another great feature of Spyder is the variable explorer. This window tells you a lot about the entities you have in your projects: are they numbers or strings? Are they filled or empty? What’s their state? Etc. The more your program gets complex, the more you are going to appreciate that tool. (Again, having such a tool is no excuse not to plan on the design of your program. You should be in control of what happens.) 4.2.1 Running your Code in Spyder Ok, it’s too early to have a session on Python and produce a decent program. Still, given we are talking about Spyder it is good to know how you can run programs from there. Assuming you wrote some code in Spyder there are two ways to run it: run the program: press F5. You will be asked to save your file and then your code will be run, showing an outcome (if the code has no error); run the code inside a Spyder cell: you can delimit Spyder cells using the following delimiter line: # %%. If you are inside a cell, you need to press CTRL + ENTER. Example of Spyder’s Cell – ch. 4.1 # %% #cell starts above this line ---- #code of the cell def main(): print(&#39;Hello world&#39;) #cell finishes below this line --- # %% 4.2.2 Other Popular (Python) IDEs Spyder is by no means the only IDE for Python. There are a lot of tools about there: free, paid, Python-specific, etc. The recommandation is to explore some of the options, good comparisons are just a search engine search away. What I like about Spyder is the opportunity to divide and conquer problems by working with cells as well as having an IPython session to work in, all in the same window. This may not work for you. An option worth considering if you want to expand your coding abilities is Visual Studio Code (https://code.visualstudio.com/). Besides being free and easy to install its main benefit is that it allows us to code in a huge variety of languages (different programs requires you to add some plugins and learn to compile, if needed). In a few clicks you are going to have access to the possibility of running code in Python and other tech-tools you may be interested in like: HTML, JavaScript or Ruby. If you want to go into app development with Java, you can. And all the flavours of C-languages are supported.30 4.3 IPython IPython is an interactive shell to run Python commands. Contrary to the Python code you write in Spyder or Python editor, if you press ‘enter’ inside an (I)Python shell that code is immediately executed. No need to run it. Working in the shell allows you to have faster responses. You type the commands and see if they are doing what you want. Prototyping in the shell is fast and it is also useful to stay in the shell after running a program to see what happened. IPython is perfectly suited for this and much more. In fact, the ‘I’ in IPython stands for interactive. Interactivity is gained by tab completion of commands (as in Spyder) and by putting you close to your code. If you don’t know what’s the type of a certain object you simply ask the shell and it will tell you. Just write type(object). Further, you can use a question mark ‘?’ to figure out what the various functions do if you don’t remember them or if you are simply curious. In that way you prototype code and interact with the documentation of the module you are using. Besides that, IPython offers you special methods (sometimes called “magic methods”) that you can use to measure how long does it take to run your code and much more. 4.4 Jupyter Notebooks Jupyter notebooks are a nice interaction of code and text. You run your code in cells or chunks, as in Spyder. Nonetheless, in a Jupyter notebook a cell can also be a text chunk (written in Markdown). This allows to write tutorials in which you discuss a problem and then present the code. The code, then, can be run in the browser. So when you are following the tutorial and run the code, you see the results of code execution. Jupyter Notebooks are perfect for portability. Still, you need to have the dependencies and modules installed on your machine. (With Google CoLabs, see below, this is no longer an issue.) Jupyter Notebooks are nicely integrated in the Anaconda/Spyder workflow presented here. All you have to do to open a Jupyter Notebook with Anaconda is: open the Anaconda Prompt; go to the folder you want to create a notebook into (i.e. use cd to change directory and mkdir to create a new one, if needed); type ‘jupyter notebook’. The notebook will be created and you’ll browser will open in the notebook. (To close the notebook get back to the conda shell and press ‘CTRL + C’.) Oh, there are controversies on whether Notebooks are as super good as they look like. Search ‘notebook skeptics’. 4.5 Command Line in Action: the Anaconda Prompt Git was a reason to see the importance of command line interfaces. Anaconda is a further proof. While coding you’ll need to install new libraries and modules (we do that for laziness: we go through installation pain to have access to functions and commands that were programmed and optimized already - there’s no need to reinvent the wheel). Anaconda comes with its own command line interface called “Anaconda Prompt”. Just search for it in the Windows search bar and start it. You have a command line tool. As it was the case with Git, the Anaconda Prompt has a reserved word to specify you are going to use specific Anaconda commands. In this case the magic word is conda (all the ‘common’ command line commands like ‘cd’ or ‘mkdir’ are stilll valid). Typing ‘conda’ plus something allows you to run the commands and interact with your Anaconda version. The name of the tools (‘jupyter notebook’, ‘spyder’) open the corresponding tools. The commands we need to learn allow us to: install new Python components, update the Anaconda system, activate virtual environments and operate Jupyter Notebooks. Try to guess these commands before moving on. 4.5.1 Basic Anaconda Prompt Commands Anaconda Prompt Commands are pretty straightforward: ‘conda install’ is used to install packages, e.g. conda install pdfminer (sometimes there are specific flags to be added or different channels to download your packages from. Just search ‘conda install [package]’ and you’ll find detailed instructions, e.g. https://anaconda.org/conda-forge/pdfminer); ‘conda update’ is your choice to update the whole system; ‘jupyter notebook’ creates a Jupyter Notebook the folder you are into (as you have already seen); if you want, you can type ‘spyder’ in the conda shell. This will open the IDE; to configure virtual environments the things are a bit more complex. Here’s an anticipation of the first step: conda create –name [environment name] (see later to have the full picture). 4.6 Google CoLab or Python on the web The last option to consider to get started with Python is Google CoLab. If you want to try out Python and don’t want to mess up with installations just go over to https://colab.research.google.com/ and try out Google CoLab. Here’s their explanation of the platform: What is Colaboratory? Colaboratory, or “Colab” for short, allows you to write and execute Python in your browser, with Zero configuration required Free access to GPUs Easy sharing. Nice, isn’t? Basically you will have the architecture of Jupyter Notebooks that you can run on Google’s machines. Notebooks allows you to mix Markdown language and Python code. If this doesn’t look exciting enough, the platform has many built in tutorials on data analysis and machine learning (see in the resource section). Beware that there’s a price for our installation lazyness and for accessing their computational resources: Google/Alphabet gets access to your code. 4.7 Virtual Environments: Preview into Coding Best Practices When you program, it is good to keep what you are developing in isolated compartments. You don’t want a system update to crush your program, neither you want some new module you download to interact and conflict with what you have. Given that, wouldn’t it be nice to keep different programs in different places that do not interact with each other? The answer is building virtual environments. Working in controlled environments is a universal coding best practice. No matter what language you are working in, you want software development to work in its own isolated compartment. There’s a lot on coding practice (both Python specific and general) and it is good to start as soon as possible with that. To build a virtual environment in the present Spyder/Anaconda setup we need to: call the Anaconda Prompt; type ‘conda create –name [environment name]’ (you can specify what packages do you want and which versions, e.g. conda create -n myenv python=3.6 scipy=0.15.0 howdoi, arcade); now the environment is created, but it is not active. To active the environment, type: ‘conda activate [environment name]’; once you have finished working in the environment, you have to deactivate it. To deactivate the environment, type: ‘conda deactivate [environment name]’; as you start creating environment, you may be confused as far as what environments you have created. To print a list of all you created environment type: ‘conda info –envs’ or ‘conda env list’; to remove the created env, type ‘conda remove –name [environment name] –all’. Ok, we now have Python installed with Anaconda and are acquainted with Spyder. We also managed to create a virtual environment for your development. All you we need to do to start coding is running Spyder inside our virtual environment. This requires some further tricks. First, read this https://github.com/spyder-ide/spyder/wiki/Working-with-packages-and-environments-in-Spyder (especially under the heading of “the modular approach”). Summing up, this is how it worked for me: Activate the environment in which you’d like to work (e.g. with ‘source activate myenv’ on macOS/Linux or ‘activate myenv on Windows’). Suppose you installed the arcade library into an environment call arcade. To activate it type: ‘conda activate arcade’; Install the spyder-kernels package there, with the command: ’**conda install spyder-kernels=0.*; **’ Once you have everything up and running (i.e. you created the env and installed all you need there). Run spyder from conda prompt with the environment activated. To do that, type ‘spyder3’ or cmd /c spyder3.exe and you’ll have the dependencies loaded in your environment. 4.8 Summary We are ready to go. Python is there on our machine, installed through Anaconda. We have access to the Spyder IDE and we are ready to start programming. We know how to install packages, develop in safe virtual environments and how to make our learning experience interactive (IPython, tab completion). Many of these operations provide us with opportunities to enhance our CLI-Fu. We are ready to move to part II and actually learn programming. 4.8.1 Conda Prompt Commands Here’s a summary of our new learnt conda command line commands: conda update conda install [package] jupyter notebook conda create –name [environment name] conda activate [environment name] conda deactivate [environment name] conda info –envs or conda env list conda remove –name [environment name] –all Shorcuts of the chapters are Spyder based and are two ways to run code: F5: run the whole script; CTRL + ENTER: run code inside a cell (in Spyder). 4.8.2 More Resources Let’s start with some resources on interactive tools: Here’s the IPython intro tutorial: https://ipython.readthedocs.io/en/stable/interactive/. Here’s a tutorial on running a Jupyter notebooks with Anaconda on Windows with step by step instructions and pictures. (https://pythonforundergradengineers.com/opening-a-jupyter-notebook-on-windows.html) Let’s now move to Colab tutorials, i.e. a great way to explore the Colab tool and Python notebooks in general. Intro to pandas: https://colab.research.google.com/notebooks/mlcc/intro_to_pandas.ipynb tensorflow programming concepts: https://colab.research.google.com/notebooks/mlcc/tensorflow_programming_concepts.ipynb charting data: https://colab.research.google.com/notebooks/charts.ipynb There’s something more you want to check about code editor: LightTable. Open-source, real-time feedback. And more: http://lighttable.com/. We have just scratched the surface of virtual environments, read more on the docs: https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html Book-wise: IPython and its use for data exploration and programming being aware of performances is presented in Jake VanderPlas Python Data Science Handbook, ch. 1. IPython is presented in ch. 3 of Wes McKinney Python for Data Analysis. 4.8.3 Further Work Installing Anaconda was the main task of this chapter. Still, there’s something more you can do: Go on GitHub and find a couple of Jupyter Notebooks you like; make a notebook explaining how nice is GitHub for humanities; R has notebooks as well. Have a look at how they work in RStudio. (Yes, by now you know ‘have a look’ means ‘read the docs’); you can have virtual environments without Anaconda. Anaconda is there to simplify things with its shell. Find out how to work with virtual environments and packages installation outside the Anaconda environment. (Hint: you have to learn what the ‘pip’ acronym is in the Python world and how it works). If you come from Windows as I do, you need to find out if your system is 32 or 64 bit. Right click on This Pc, select ‘properties’ and you’ll find the answer. - If this quick fix doesn’t work, here is more on the issue of determining if you are running 32 or 64 bit OS, for all main platforms: https://www.computerhope.com/issues/ch001121.htm.↩ For bonus points on Windows and path variables see here.↩ With the default Python IDE (called IDLE, from the Monthy Python show) you either have to open more windows or comment out what you do not want to execute when you run your program.↩ Code is meant to be read, hence the existence of formatting conventions. ‘PEP’ is another piece of Python-jargon which means ‘Python Enhancement Proposal’. This is basically how Python evolves.↩ Also, if you are working with a large number of files maybe you’ll find it easier to manage them with VS Code.↩ "],
["ch5.html", "5 Python Crash Courses 5.1 Look How Easy it Is to Write Python 5.2 Python in General: A Readable Design 5.3 General Structure of a Python Program 5.4 Import: Load all the Tools you Need 5.5 Functions: Let your Program Do Something for You 5.6 Data Structure: Everything Has its Natural Place 5.7 Flow Control 5.8 Classes and Comprehensions: More Pythonic Things 5.9 Functions Revisited: *Args Times! 5.10 What’s In a Name: Naming Conventions and Styles 5.11 Saving and Running a Python Program: .py and .pyw 5.12 Working with Files 5.13 Regular Expressions 5.14 Learn by Doing for the Humanities: Matching Bibliographical Patterns 5.15 Summary", " 5 Python Crash Courses “Programming languages are languages,” says the HumanDemia teaching material. “They also have dialects and programming styles. They are alive and have communities”. Here we start with a crash-course on Python, highlighting some of the things we are going to cover in Part III, dedicated to programming things that may have an academic import. The next chapter covers dialects and styles, Python features that can be and feel hard to learn, and how to get the most out of our Python-learning journey. As you already know, HumanDemia suggests you to type the code yourself. If you really want to copy and paste some of it, I understand that. Still, beware of the quirkiness of pdf. Even if you copy and paste the code the spacing is likely to be lost - and, as you are going to find out, spacing is vital in Python.31 Also, to make sure the code fits in the pdf page and e-reader screen, I have to use multiple strings quite often. There two ways to continue a string to the next line and I have used the one with ‘\\’ more than I wanted to. Nonetheless, I thought that made the string continuation easier to be recognized in some cases and so I used it. 5.1 Look How Easy it Is to Write Python Let’s go super experimental and harsh here. Take a look at that. Can you read some of that? Can you guess what the various parts of the code do? Crash impact with Python (Pt. 1) - Ch. 5.1 import re from collections import Counter def words(text): return re.findall(r&#39;\\w+&#39;, text.lower()) WORDS = Counter(words(open(&#39;big.txt&#39;).read())) def P(word, N=sum(WORDS.values())): &quot;Probability of `word`.&quot; return WORDS[word] / N def correction(word): &quot;Most probable spelling correction for word.&quot; return max(candidates(word), key=P) def candidates(word): &quot;Generate possible spelling corrections for word.&quot; return (known([word]) or known(edits1(word)) \\ or known(edits2(word)) or [word]) def known(words): &quot;The subset of `words` that appear in the dictionary of WORDS.&quot; return set(w for w in words if w in WORDS) Here are some things to note: Python reads a lot like English; it does not look too much “programmy”: there are no curly brackets; there are some patterns we can identify: def word(anotherword): - the column is important! things look nice and ordered. Space seems important. we can recognize some commands: return, open, import. Ok, we are going to read some of it together. The first thing we learn about Python is that comments are included with the hashtag symbol #. Yep, comments in Python are different from Markdown syntactically; conceptually they are still comments. So we are going to read this together adding some comments to guess what the code does. Crash Commented Python #we import something import re #that&#39;s mysterious #that&#39;s a counter from collections import Counter #we def(ine)? something related to words #we are getting something in return that deals with findall def words(text): return re.findall(r&#39;\\w+&#39;, text.lower()) #we are doing something to the &#39;text&#39;, there&#39;s this #lower() on it. It has to do with format or capitalization? #now we have allcaps. That should mean something #we open a txt file named &#39;big&#39;, probably #open(&#39;big.txt&#39;).read() probably reads the file WORDS = Counter(words(open(&#39;big.txt&#39;).read())) #WORDS probably contains some form of Counter operation #performed on the big txt file we&#39;ve read #from here we have other definitions # There&#39;s text between &quot; &quot; that tells something about that def P(word, N=sum(WORDS.values())): &quot;Probability of `word`.&quot; return WORDS[word] / N #here we are getting a probability of a word. #we take the word out of WORDS and divide it by N. #Above we know that N is equal to the sum of #WORDS.values... no idea about the internals but sounds ok def correction(word): &quot;Most probable spelling correction for word.&quot; return max(candidates(word), key=P) #here learn we are dealing with spellings. To correct a word #we return the &#39;max&#39; of candidates for the word based on # the key P, i.e. the probability we have just defined. #but, wait, where are these candidates? Move on... #...here they are def candidates(word): &quot;Generate possible spelling corrections for word.&quot; #that&#39;s what candidates def does... return (known([word]) or known(edits1(word)) \\ or known(edits2(word)) or [word]) #ok, this return statement looks programmy #we can spot 4 alternatives listed with &#39;or&#39; #we are mentioning known words and known edits of the words #chances are these will follow... #here we go def known(words): #oh, known(words) are alternative words we know in the WORDS #thing above we generated opening the big txt file. &quot;The subset of `words` that appear in the dictionary of WORDS.&quot; return set(w for w in words if w in WORDS) #we are returning a set probably (set) #the parenthesis looks scary but reads like English: #we get a set of w, for (each) w in words (i.e. the thing we #created with findall if the w is also in capitalized WORDS) Cool! We were able to learn a lot and the program was far from an easy ‘Hello World’ program. Give yourself a pat on the back. The program has two further “defs” and that’s it. Edits1(word) looks scary, but it says to us that it includes “All edits that are one edit away from ‘word’”. (Spoiler: that is called a docstring in Python-jargon). Edits2 iterates the concept (two edits away) and then has another funny parenthesis. Here’s the missing code. Try to read it. Crash impact with Python (pt. 2) - Ch. 5.2 def edits1(word): &quot;All edits that are one edit away from `word`.&quot; letters = &#39;abcdefghijklmnopqrstuvwxyz&#39; splits = [(word[:i], word[i:]) \\ for i in range(len(word) + 1)] deletes = [L + R[1:] \\ for L, R in splits if R] transposes = [L + R[1] + R[0] + R[2:] \\ for L, R in splits if len(R)&gt;1] replaces = [L + c + R[1:] \\ for L, R in splits if R for c in letters] inserts = [L + c + R \\ for L, R in splits for c in letters] return set(deletes + transposes + replaces + inserts) def edits2(word): &quot;All edits that are two edits away from `word`.&quot; return (e2 for e1 in edits1(word) for e2 in edits1(e1)) Ok, we haven’t even started with the rules of Python syntax and we were already able to grasp quite a lot of a far from obvious program. There’s a reason why Python is sometimes referred to as “pseudo-code that actually runs”. If you are curious about what the program was, that was Peter Norvig’s spell checker. Here’s the full code and explanation: https://norvig.com/spell-correct.html. Feel free to have a look.32 “That’s a nice example!”, you find yourself thinking. Ok, it was non-obvious but it resonates. “It seems people at HumanDemia want me to critically reflect on the tools I use in my daily work at quite a different level,” you think. Next time RStudio doesn’t catch a typo we will be able to reason about it from a different perspective. Oh, if this little program about spell checking is making you feel uncomfortable, fear not. We are not going to do “crazy math” or “AI stuff”. This little experiment is meant to show that the “gap” (if any) between Humanities and programming is way thinner than you thought. You were able to read code that does something useful like checking spelling and suggesting what you intended to write but spelt wrong. That’s something amazing. Yes, there were some obscure things. (If you fancy spoilers: ‘re’ is a module to use regular expressions. For now, think of them as detective search tools. Regular expressions are the cause of the r’\\w+ which scream insiders’ jargon. Also, the “funny parentheses” are comprehensions which are one of Python unique features we are going to see in a while.) Last thing. Mentioning Norvig and his book is no accident. Try to read some code examples from the book (same author: Norvig, but a different language: LISP). Here’s one example: https://github.com/norvig/paip-lisp/blob/master/lisp/compile1.lisp. It looks less easy, at least). Ok, fear not and move on! Let’s learn more about Python. Section Credits This experiment was inspired by a similar “dive into the language without knowing it” you can find in the Head First Java book by Bert Bates and Kathy Sierra. 5.2 Python in General: A Readable Design As you have already seen, Python is easy to read. It is “almost like English” and it is not that intimidating. In fact, you can probably type most of the code you’ve seen. There were no ‘{’ or ‘}’ or other signs you need to struggle and figure out how to type. From that point of view LaTeX, is harder than Python and also HTML has a lot of opening and closing tags. Coding-wise, it is often said that “code is most often read than run”, Python builds on this. In other languages weird signs (like { and }) or end of the line signs (like ‘;’) are used to delimit the end of a line or an instruction. Python uses space and formatting to achieve that. This should be something friendly for academics. This also means that space matters. This leads to specific code-formatting strategies you need to care about. When you indent code you are delimiting block of codes. The standard practice is to use 4 spaces for the first level. Add four more to the second level, etc. If you use TABs, they can mess out your code. If you are using an editor, as Spyder, you can configure it so that tabs equals four spaces. Feel free to spend some time in Spyder exploring preferences in the tools. “Ok,” you think checking the first box “these HumanDemia practical programming stuff is not that complex”. To really have a grasp of how code is displayed and what’s Python standard coding practice check out PEP 8 (https://www.python.org/dev/peps/pep-0008/). PEP means Python Enhancement Proposal are official pieces of documentations guiding Python developers community and/or presenting new language features. If you come from academia there are chances you may overestimate the ‘official’. Go and read the document. The tone is informal but on point. It shows good and bad examples with code. You are reading commented Python code and absorbing does and don’ts. Now that we know something about how parts are divided, let’s have a look at the general structure of a Python program. 5.3 General Structure of a Python Program A Python program has a general structure that goes like this most of the times: entry line that starts with ‘#!’ this is called shebang or hashbang. This message is there for your shell and tells it how to use the program. If you see this in the first programs you read, that’s likely to be mysterious; lines of comments (single comments with #, multiline comments between \"\"\" comment here \"\"\"). These contain a license - if it’s not provided elsewhere in the files of the whole application - or an overview of what your program does. Now comes the most common lines; import lines. Python is cool and has a lot of batteries included or extra batteries. You call what you need with the ‘import’ function. This were the starting lines of Norvig’s spellchecker importing the re module and Counter; the instructions of the program. Functions, classes, etc. Norvig’s speller was all about def(), i.e. function; a ‘main’ routine, i.e. what you want your program to do using your functions. Think about the main call as a recipe; a way to call the recipe, i.e. the main() function that goes like this: Main call if __name__ == &#39;__main__&#39;: main() This last line also allows a Python program to check if it is run from the command line or it is imported by a Python program as a module (i.e. with the ‘import’ command list in (3)). Also, this line shows a way in which Python does look programmy: the use of underscores is peculiar and important for the language. In Python the double underscore pattern is referred to as dunder (i.e. double underscore). The list is by no means compulsory. What matters to us now are 3 and 4. Should you go around checking programs on GitHub or reading tutorials, you have an idea of the general picture. On Github and Jupyter notebooks you won’t see many shebangs. The same holds for licenses. Now that we have a general outline of a Python program we can explore importing and writing the main instructions. This allows us to get deeper also in the puzzling main-name line. 5.4 Import: Load all the Tools you Need Before you start building something you need to have all the tools at your disposal. Coding is no different. Once you have installed your tools and chosen and IDE or text editor, it’s time to pick the right tools to construct the logical architecture of our program. The first lines are there to import our tools of the craft. We import modules. Modules are code containers that have some code we need. Go back again to Norvig’s program. We need to count words. There is no need for us to code a device to count things inside a certain collection: we can import ‘Counter’ from a specific module called ‘collections’. The syntax for the import is quite simple, I’ll show it directly in code with examples. Import syntax # importing a whole module: # import [module&#39;s name] import os #os handles operative systems tasks, file handling #importing something specific from a module: # from [module] import [something] from collections import Counter from bs4 import BeautifulSoup #a parsing library #importing something with aliases, to save on typing #or avoid conflicts with name # import [something] as [alias] import pandas as pd #data processing library To use a module you’ve imported you need to have it installed. If that’s not the case you’ll receive an error message. The compiler tells you that the module can’t be found. To install a library you conda install it from the Anaconda prompt (or you pip install from a windows shell - this was already covered in chapter 4.) Beware: sometimes you may receive errors like “module X is not installed” when you know for sure you conda installed it. What happens is probably that you are working with virtual environments and: you are working in the wrong virtual environment; you are in the correct environment with all the relevant modules but you haven’t activated it. “How do I know which library does what?” I hear you crying. Short answer is “experience”. Practically, you can start learning Python’s standard library. The standard library has a bunch of core functionalities. Before looking outside the standard library you can look into it. Do you remember when we talked about the importance of reading the docs? That was one of the reasons. Anyway, at the end of the chapter you can find a list of commonly used libraries, both standard and non-standard. We still have to deal with importing your Python programs but we need to know more about Python to do that. 5.5 Functions: Let your Program Do Something for You Ok, let’s start coding. Open Spyder and reach IPython. We follow the cliché of “Hello world” programs. Machines are nice and they always cheer you. So, go in IPython and type: Hello world - ch. 5.3 print(&quot;Hello world!&quot;) Imagine what happens and see the results. I guess everything goes as predicted. Now move to the next step by messing around. Try removing some ‘(’ or adding ‘;’. Remove quotations or change them to a single quotation. Keep experimenting in IPython so that you don’t have to run the whole program to just see the results of a single instruction. Ok, now think about writing “hello world” as function. Instead of printing “hello world” via a direct print we call a function that will do the printing. Our previous experiment already gave us the syntax: it’s def keyword. And don’t forget the colon. The file 5.3 of hello worlds have that version. The main call is missing, try to add it. Also, can you write a function that says ‘Hi!’ to the name we pass to it? (Think about the Edit1(word) functions…). Cool. Ok, now for something different. Search for the documentation of Python’s print function. Folks at HumanDemia expect you to be quick at that. Reading the docs is a skill you have to learn, like reading a paper or giving a talk. Start using the info in the docs to get a grasp of some of the errors you have received while experimenting. (Bonus points for searching informations about the error Tracebacks.) Ok, the print function is pretty boring and, most of the time, you are going to define your own functions. Actually, the print function is historically controversial for Python and printing to screen is far from that easy and boring in other languages… but coming from Humanities you are already good at history and comparative stuff. Let’s go back to functions. Functions take zero or more argument(s) and are defined with the following syntax: def keyword: tells Python you are defying a function; name of the function; (): contains the arguments of the function, if empty it means there’s none; ‘:’ tells Python the function starts; newline; indent (4 spaces); instructions of the function (could be more than one line); return keyword: tell the function what to return; content to be returned. The last two items are optional. Think about a function. You’ve seen one before in disguise. Here’s function example: A badly named function def main(): print(&#39;Hello world&#39;) (Can you rename the ‘main’ function in a better way?) If you press enter in IPython or run the program in the IDE (shortcut to run the program F5, of CTRL + ENTER if you have created a code cell, i.e. have a line that goes like that: # %%) nothing happens. To have your function running, you need to call it (think Blondie). To call a function, you call its name and its arguments (here, none). Hence to receive: ‘Hello World’ you need to call main(). Like this: Calling a better named function #define the function def say_hello(): print(&#39;Hello world&#39;) #calling the function say_hello() If you now call main() you are going to execute its content. In this case the content is a print statement. Let’s see a function with some argument and a return statement. This function includes docstrings, contents between triple quotes that describe what a function does. We have seen them already in Norvig’s code. (Docstrings have their own PEP, number 257 - https://www.python.org/dev/peps/pep-0257/. If you read PEP 8, you’ll see they are referenced there. Also, by including docstrings into a function (or method, class, module) we are populating the dunder doc of that object.33) Proper named function with docstrings and return - ch. 5.4 #function example with one argument and return def capitalize(word): &quot;&quot;&quot; The function takes a word in and it returns you the word, but capitalized. &quot;&quot;&quot; # that above is a docstring. It tells what a function does and # can be used to document our code # Norvig&#39;s code had them, only in single string mode &quot;&quot;. capitalized_word = word.capitalize() return capitalized_word Copy this function - mind the space - and see what happens if you call capitalize(‘I want this bigger’)? Again, play around with the stuff. What happens if you pass an argument without quotes? What if you pass more arguments? The function above introduced us to docstrings. Docstrings are pieces of text written to tell users about what certain pieces of code do. They are enclosed between triple double quotes, as we know already. A docstring is ignored by the compiler, so you can use it as a multiline comment as well.34 (The next chapter will show you more about docstrings and documentation.) The function above also makes use of a method, i.e. the .capitalize() part of the program. There’s quite a lot to be done with functions, but that already allows us to do some work. Beside that, before moving on with more complex functions, we need more LEGO pieces to play with. 5.6 Data Structure: Everything Has its Natural Place Python is a general purpose programming language. You can build a spell checker on it or a website, perform mathematical computations or use Python to visualize data. There’s a lot you can do with it. To do all these different things, you have to cleverly use different data structures. ‘Data structures’ are exactly what you expect: ways to store and contain data. Different types of data require different data structures. Data structures differ not only for the kind of data they have as the section’s title suggests. It is fairly easy to expect that we have a way to store text data and a way to store numbers… …Well, of course you can spot corner cases: we are from creative Humanities, we ask the questions about possibilities. What about the number ‘pi’ (of pi-day)? What about ‘She scored 98% at the test’? And is ‘A’ in ‘We got A for our team assignment’ a word or a number? When dealing with data structures we have to care at least about three (plus one) things: the kind of data they can store: if we put text in number-containers we are going to get into troubles; the methods and functions associated with that data type: we can do different things with different data types. (We’ll find out in a while.) For example, we expect to be able to divide two (or more) numbers, but dividing pieces of texts sounds bad; the kind of data structure we are dealing with: data structure can be mutable or immutable, for example. Suppose you want to check the number of emails you receive during the day. You find a way to access your inbox every ten minutes and download the number of incoming emails and update your counter. If your counter is an immutable data type you are going to have no update whatsoever after the first data retrieval or an error saying “hey, can’t update or modify a data structure that is immutable”; (actually +1) how the data type is implemented: if you care about performance - and sooner or later you may have to worry about that - it is important to know how your data structures are implemented. This looks tricky (that’s why it’s +1) and is due to the fact that there are different programming languages that can be faster or slower at executing the same task. Python, as you may find out, is not that fast. Still nothing forbids you to use Python to build complex tools and calculations that use faster programming languages or implementation to achieve better performances. That’s the case with numpy the library that powers most of the scientific Python libraries offering faster implementation for arrays (and more). There’s no need to know all the internals of data structures (at least for now). But it’s good to know a little bit of them, just so that we are not going to cry when things do not go as we expected because we provided the wrong datatypes to our functions. (Guess what tells you what kind of data a function expects and what it returns? Yes, the docs!) With that said, we are going to cover a little bit of data structures, their methods and how to access the elements we put into a data structure. 5.6.1 String Literals Strings store text. You’ve probably guessed that. And you know we’ve used strings already when we’ve printed “Hello world!”. To tell Python that there is a string, we need to include the content of the string between quotations, either single ‘string here’ or double “string here”. We can easily assign strings to a variable: to assign something to a variable we use the ‘=’ sign. The ‘=’ sign does not mean that X equals “Hello, there”, but rather that “Hello, there” (the angel from my nightmare) is assigned to X. If it helps, read the ‘=’ statement right to left: what comes to the right is assigned to what’s on the left. To say that something is equal to something else, like ‘2+2 equals 5’ we have to use the ‘=’ sign twice, so ‘2+2 == 5’. A useful formula to remember that difference is that assigning is not equality. The syntax for strings goes as follows: String syntax #string creation with single quote variable = &#39;content of the string&#39; #string creation with double quotes variable2 = &quot;content of the string&quot; #you can add numbers to strings, if you want variable3 = &quot;3&quot; #a number as a string # do you think that &#39; &quot;3&quot; == 3 &#39; is a True statement? #string can continue on two lines stringvar = &quot;this strings goes on to another \\ line&quot; #the \\ does the trick but beware not #to include further code after it #another way to continue strings, using brackets stringvar = ( &quot;first part of the string goes there&quot; &quot;and that is the second part &quot; ) There’s an important thing to notice. To produce strings we are using ’, which is a character we are going to use, for example, if we say “Hi! I’m fine, and you?”. How do we tell our machine friend that some characters are used in the text and some are used to create strings? Welcome to escape characters. If we are using something that is a reserved item of a programming language, as ’ here, and you want to use it with its non-reserved meaning, you have to escape it. To escape a character you have to add the escape character of your programming language, which for Python is ‘\\’ (as for RStudio). When you prompt the user to give you pieces of information and inputs you get them as strings. Remember that, because sometimes you are asking for numbers and you get them as string inputs. (See above the questions on string number three being equal to number 3.) Open an IPython session and write what follows (to ask for inputs we use input keyword): Asking the user for input fav_number = input(&#39;What is your favourite number?&#39;) print(fav_number) Use IPython to check the datatype of fav_number, i.e. use the function type() on fav_number. You’ll see it is a string. It is easy to convert a string to an integer (there’s more than one data type for numbers): use int(). (To go have something converted to a string, use str().) Ok, re-read the paragraph above and come out with some exercise or conversion scenario to put this into practice. Operating a calendar may require conversions: you enter numbers for the dates as inputs.35 If you have a register of mid-term assignments and students you may have numbers (for deadline and, depending on the scoring system, grades) and strings (student names). Additionally, you may have students’ IDs and course names. Ok… There’s quite a lot we can do with strings: we can concatenate two or more strings with the plus (+) sign. Strings concatenation examples #concatenation example name = &#39;John&#39; surname = &#39;Snow&#39; fullid = name + surname print(fullid) #concatenation with space full_space_id = name + &#39; &#39; + surname # &#39; &#39; is the space print(full_space_id) #concatenation with newline full_linespace_name = name + &#39;\\n &#39; + surname # \\n is for nl print(full_linespace_name) we can slice our string, i.e. select a part of it. To do that we use square brackets to include the indexes we want to slice, separated by a column. That’s the formula: string[slice_begin:slice_end] The first index is included, the last is not. To apply the formula you need to know that a string first letter has index 0, not 1. Get used to that. (The reason for that is that strings are arrays of characters and arrays in Python are 0-indexed.) Also, you can have negative indexes like -1. Negative indexes are counted from the end of the string, so -1 indicates the last letter of the string. Ok, let’s get practicing: String slicing examples test_string = &quot;A quite long string for practice&quot; #If you want A: test_string[0:1] #from zero included to one excluded #If you want &#39;practice&#39;: test_string[-9:-1] #(we count from the end, and move backward) #If you want &#39;quite&#39;: test_string[2:7]. #Remember spaces are included in the count. #The first space is test_string[1:2] You can also access single letters: just point the place the latter occupies between square brackets. Remember it’s zero indexed. (So, in the above example ‘A’ is test_string[0]). Strings have a variety of methods. Methods are functions you can call on certain objects, like strings in this case. To access methods we use something called ‘dot notation’ (or dot-syntax). Dot-syntax is common to different data structures. In some abstract form the idea is that we first specify the object we want to deal with, like a string. Then, after a dot we invoke the method (that gets applied to the object that comes before the dot). So: object that has a certain method + . (dot) + method name(). (This is different from functions in which the object we want the function to be applied to is provided inside the brackets. Go and review the previous ‘capitalized’ function to see a combination of functions and methods.) Here’s a more verbose take on dot notation. To access the methods you take the name of your object, add a . and then call the method. The method is a function, so it has a couple of brackets () at the end that are empty if the function takes no parameter but may have them. For example the .replace method takes two parameters: first what you want to replace and then what you want to replace it with. So string.replace(“C”, “D”) will chance all capitalized Cs in the string with capitalized Ds. Ok, let’s provide some examples. Suppose you want a function to shout on webchat, hence it will return all caps. We know how to define functions. Let’s build this up with comments: Shouting objects with dot notation def shout(phrase): #phrase is going to be a string return #here we call the string method to capitalize #capitalize test, make sure we can capitalize test = &quot;Be all capitals&quot; print(test.upper()) #.upper() is the all caps method #get back to the function def shout(phrase): return phrase.upper() #a return will give it back #us the phrase printed #try to shout &#39;Looser!&#39; shout(&#39;Looser!&#39;) #correct #try what happens without passing a string shout(looser) #try also keeping the def #compare with def shout_to_be_called(phrase): phrase.upper() #what happens if you type in the interpreter #shout_to_be_called(&#39;Help me please!&#39;)? #how can you make it appear on the screen? This simulates a way to work towards a solution. With bigger projects you can automate some tests. For example, if we want to be sure that the upper() method is making everything capitalized we can write a statement checking that the result of shout(‘Loooser!’) equals our expected result, i.e. LOOOSER!. This can be done with the ‘assert’ statement. The docs are here (assert, plus more kinds of Python statements some of which we touched and some we haven’t, at least for now): https://docs.python.org/3/reference/simple_stmts.html. If this whole idea of having checks (and balances) and controls in your program - feel free to build an analogy with a constitution or the organization of powers in a State - then testing is for you. And it’s great that you like it.36 There are way more strings methods that do the following: split() (“specify an element to delimit the splitting”): suppose you have a sentence like “There are two apples” and you want to isolate the words. You are going to split on the space. So: sentence.split(\" \"). Beware that split returns data as a list (see in a while); replace() (“element to be replace”, “replacement”). Suppose you want to change ‘cat’ into ‘mat’. Assuming string = “cat”, you call string.replace(“c”, “m”). Go and experience in the interpreter or IPython; lower() (opposite of upper, returns string in lower case). There are many more methods for you to search. It won’t be difficult. Come out with examples for most of the methods you have to be sure you can use them. Then think about how to use them to make something. One last thing: strings are immutable. You can’t go inside the first letter of ExampleString = ‘Case’ and assign it to ‘B’ to have ExampleString = ‘Base’. Try ExampleString[0] = ‘B’ and see. (Use the replace method to achieve that.37) Nonetheless, lists, our next data structure are mutable. 5.6.2 Lists Lists are widespread data structure. They can hold as many things as you like, of different kinds (you can mix strings, numbers, etc). Oh, list is a reserved word so you can’t name your list ‘list’. We convert something into a list with list(), as we did with str() or int(). Lists are initialized with square brackets, like this: []. Objects that are in the list are separated by a comma. List can contain lists as objects. List examples A = [] #is an empty list. A_list_with_numbers = [1, 2, 4, 5] MixedList = [1, &#39;two&#39;, 3] TextToString = [&quot;once&quot;, &quot;opon a time&quot;, &quot;there&quot;, &quot;was&quot;, &quot;a verb&quot;] NestList = [&quot;This list&quot;, [&quot;has a nested list&quot;, 1, 2, 3], \\ &quot;that contains 3 numbers&quot;] The array-like syntax to access letters of a string is valid for strings as well, but this time you are going to access the item in that place. Accessing list items A_list_with_numbers = [1, 2, 4, 5] print(A_list_with_numbers[0]) #prints 1 TextToString = [&quot;once&quot;, &quot;upon a time&quot;, &quot;there&quot;, &quot;was&quot;, &quot;a verb&quot;] print(TextToString[1]) #prints &quot;upon a time&quot; List are mutable, i.e. you can use array-like indexing list[index] to change the list. Changing items in a list chage_2_to_3 = [1, 2, 4, 5] print(chage_2_to_3) #prints [1, 2, 4, 5] chage_2_to_3[1] = 3 #remember: zero-indexed! print(chage_2_to_3) #prints [1, 3, 4, 5] Most of the time we use list to store things we need. Suppose we have a list of words and we want to select those that are longer than 3 characters. To evaluate the length of something we use len(). Depending on the objects it will tell us different things: items in a list, characters in a string, etc. To add an item to the list we need to call: name_of_the_list.append(name_of_appened_it). Yes, that’s a list method. And, yes, it uses dot-syntax. To check if an item is longer than 3 characters we have to check: Conditional statement with a deliberate error (spot it) if len(item) &gt; 3: result_list.append(item) #here we add the item to #a list called result_list If you try to run this code it will throw you an error. Can you guess why? Read it again. Yes, the list. Python has no idea what this result_list is. It was never mentioned. Try to fix the code and tell it that there is a list called result_list. If you are stuck after writing ‘result_list =’ remember we need to tell Python it’s a list. “But what’s in there?” you ask… Well, nothing, for now. So you initialize it as an empty list with two square brackets. Before giving you the whole code I’ll mention briefly how to go through the items of a list, anticipating a bit of flow control (we did that already mentioning the if statement… you see? there’s nothing complex in isolation. Issues arise combining our LEGO programming blocks into something bigger). Basically you want this to happen. For every item in the list, do something. English guides Python syntax: we need a for loop. Here’s the whole program. Iterating a list with a for loop, printing items bigger than 3 - Ch 5.5 #the list we want to test test_list = [&#39;no&#39;, &#39;yesss&#39;, &#39;tooshort&#39;, &#39;arg&#39;, &#39;nop&#39;, &#39;nope&#39;] #initialize the result list result_list = [] #[] empty list #start iteration on the test_list for item in test_list: #item is conventional. Use what you like. #check the item if len(item) &gt; 3: result_list.append(item) print(result_list) #curved balls #what is len(result_list)? and len(test_list)? #what about len(test_list[2])? You can make a list of out something with the list() command. For example if you list(“turn this sentence into a list”) you are going to get a list of 6 words. Commands like this (and str() and int()) that creates a type of object of a certain type are called constructors. You can use constructors to turn data of a certain type into another one. Lists have many methods and there’s quite a lot we can do with that. Many functions return lists. For example: regular expression re.findall() returns a list of matches. We have seen this in Norvig’s program and we are going to use it later. Also, the range(start:finish) returns a list of values from start (included) to the number before finish. (It’s the same logic of the string method slice.) Before moving to dictionaries guess what the following does (get the answers from an IPython session): range(7); range(3:7); range(10)+1. range(10,100,20) Curved ball. What’s the third parameter in range(10, 100, 20)? 5.6.3 Dictionaries Dictionaries are another mutable data structure. They are similar to list but give you more control over the items. Dictionaries stores its items as pairs of keys and values. Think about them as an address book, you have “name” (key) and “value” (phone number). We use keys to retrieve the corresponding values, so we have to provide immutable data types as keys. Dictionaries are initialized with programmy-brackets (curly ones). Keys and values are separated by a column. Dictionary items are comma-separated. Dictionary like phone book phone_book = { &quot;Alice&quot;: &quot;123&quot;, #number as string &quot;Bob&quot;: 231, #this number is an int &quot;Carl&quot;: &quot;312&quot; } Iterating on dictionaries is more complex as we now have to consider both keys and values. Nonetheless, dictionaries allow us to add some further structure to our data due to the key-value pair. Further, dictionary items maintain the order at which they are inserted into the dictionary as of Python 3.7.38 Why do we need dictionaries? Can’t we use lists all time? Well, lists keep track of the order, but there’s no structure into it. If you list [person, number, person, number, person, number] you can see a structure in the list but the list data structure offers you no structure to store it. (Ok, you may do tricks to print only persons and only numbers… can you spot a way? Nonetheless, lists are mutable and it takes a little to make an indexing mistake or drop an item and mess the structure we tried to add to the list.) Remember when we talked about the balance between being exhaustive and concise to the point in the introduction? Data structures are one of the many trade-offs. Dictionaries are a lot of fun and can be useful. Maybe you want to practice a foreign language while commuting or attending boring meetings. You would like an app that throws you some words to test if you know the meaning. Basically you are going to have the vocabulary as a (Python) dictionary of keys (lemma) and values (definition). You are then asked if you know the word or not (you can even add a ‘not so sure’). Depending on the answer, you may want to see the definition of the word (or maybe to add a button with “show definition”). Have fun programming this! (You can use the NTLK module to access a thesaurus of words as a database.) If you think this is too easy, you can save your performances and get asked questions depending on how you did in previous tests. (Maybe you want to build more dictionaries for the kinds of answers where you store the word and the times you get it right / wrong / not sure). Below we are you some methods to: check that a key is in the dictionary; print dictionary’s key(s); print dictionary’s value(s); print dictionary’s key, value pairs; (later on, once we introduce comprehensions, we’ll see how to swap keys and values). Again, we are using address_book dictionary as our dummy helper. And, once more, we are anticipating for loops (see flow control in a little while). Dictionary operations - ch. 5.6 address_book = { &quot;Alice&quot;: &quot;123&quot;, #number as string &quot;Bob&quot;: 231, #this number is an int &quot;Carl&quot;: &quot;312&quot; } # get the value for a certain key # (and return the default, if provided.) address_book.get(&quot;Alice&quot;) address_book.get(&quot;Ann&quot;) #returns 0, no Ann in our dict #Print all values in the dictionary, one by one: for x in address_book: #x takes the key print(address_book[x]) #dict[key] returns you the value #You can use values() function to return values of a dictionary: for x in address_book.values(): #now x is whatever is founf in values() - i.e. values already print(x) #Loop through both keys and values #use the items() function that tell which items we have #in a dictionary, i.e. keys values: for x, y in address_book.items(): print(x, y) # you can replace x and y with what they stand for # i.e. key, value for key, value in address_book.items(): print(key, value) 5.6.4 Other Data Types and Data Structures: Integer and Float; Boolean, Tuples, Sets There other data types and other data structures you need to be able to identify. Again, this is no introduction to the whole topic. Numbers - as Data Types - are represented as Integer (e.g., 1, 7, 42) and Float (e.g., 0.28431). You can do the usual math on them the way you imagine. But there’s also floor division that returns you what’s left. Instead of the standard slash ‘/’ for division where 4/2=2, you use ‘%’. So 4%2=0 and 5%2 = 1. Floor division is useful to check if a control parameter is odd or even. Or to check if we have finished a cycle. Suppose you have papers to group. You want to build stacks of a certain number of papers (user choose it). You want to count how many stacks of X papers you have. A way to do that is to go through the (say 21) papers and every time you can divide the current paper number with a floor of zero (suppose we want stacks of 7) we add 1 to the stack counter. So we are going 1 to 21. At 7 we get 7%7=0, so stack = 1. At 14 we again have 14%7=0 and stack goes to 2. At 21 we get to 3. (If you want to code that remember the machine starts counting at 0 and that a = 1 means we have assigned number 1 to variable ‘a’. To check for equivalence we need two ‘==’.) While talking about data types, there are also Boolean values. As you can imagine these are True and False. Explore what is truthy and falsy in Python. (You can evaluate expressions like ‘X is True’). Do that with IPython or the interpreter. Moving to data structure we are likely to use tuples. They are immutable and are created as follows: listing comma-separated values: Tuple = 1, 2, 3; using parentheses: Tuple2 = (“a”, “b”, 2, 4). Note tuples can hold different kinds of objects; if you want to make a “lonely tuple”, i.e. a tuple with a single object, you need to put a parenthesis after it: LoneTup = (“help!”,). Why is that? Write a tuple, like tup = (1, 2). And print it (or just call tup in the interpreter). Now, try to write a = (1) and print a… Have you seen it? Ask for confirmation. What’s the type of a? Yes, int. Ok, now try reassigning a = (1,). Print a. See the difference? Check for type, now you have the tuple. Next in line, we have sets. Sets are mutable collections of items, unordered, not indexed and without repetitions. If you need immutable sets for any reason, be sure to check out frozensets. Sets are created with curly brackets, as follows: Set = {‘element1’, ‘2’, ‘three’} We can do all the elementary-school set operations we did with Venn-diagrams. Sets are cool to remove redundancy. Try to write a set with multiple elements, i.e. something like test_set = {1, 1, 1, 2}. Print the test_set. See that? You have a set of len() = 2, i.e. just the two different elements (1 and 2). Ok, let’s try to put some sets in action. Suppose you want to count the common words of two different texts. Assuming the two texts comes as big strings, say, ‘Text1’ and ‘Text2’, that’s a viable strategy given what we know: split the first string - Text1 - into words (i.e. where the whitespace is); make a set out of this split; split the second string - Text2- into words (i.e. where the whitespace is); make a set out the split of the second string; calculate set union. Nice, right? If you try this experiment you are going to find it has some quirks: when you print sets (set union is a set) items do not follow the order of the sentence. Remember: sets are unordered. Print the same set multiple times, you’ll have different ordered outputs; if you split using spaces and the text had punctuation, punctuation signs become part of the words; the same word capitalized and not capitalized is not the same word for your machine. CapITalizaTion MaTTeRs. Luckily, you can fix this: strings have a lower() method, remember? That solves (3). Also, strings have a replace() method, so you can replace punctuation signs with… nothing: in that way you are removing them. Ok, well done, here’s the official Python documentation to the built-in data types. It’s though but it’s better than a cheat sheet: https://docs.python.org/3.8/library/stdtypes.html. (We are saving classes for later.) 5.7 Flow Control Flow control is where we structure our code. A program is a small(ish) world in which we check various status and, for each status, we have instructions to deal with it. If something happens and we have no idea how to deal with it, the program crushes. (Crushing is a safety feature: a secure and safe crush is better than some unexpected super compromising behavior.) Checking for every case in our program might seem quite a lot of work, but we are lucky: we can try things and raise exceptions. So we can say “if this happens and we get something unknown, print a message, save that and close everything”. Ok, let’s start thinking about flow control from what we know. Think about our text editor (RStudio) or our browsing the internet experience. How does the computer know which key I am going to press? How does the browser know where I am going to move the mouse? Of course the pc is spying on us, but not in the sense how some tenured old persons (maybe those than can’t sort the list of students alphabetically) say. A way a text editor can check what we are doing it having a loop going on for as long as the program is opened that checks for keyboard inputs (among many other things). The browser checks your mouse position, a videogame has a game loop that goes on as long as the game is opened. This is a while loop. If you need a while loop to go on forever, add a condition that is always true (True is an option, 1 &gt; 0 another - philosophers debate analyticity, but analytics statements - if any exist - can help us here). Conditionals are also good: we want to check if something is the case, if that works something happens. Otherwise (else), we’ll account for that. Then we have other task-specific issues. Like: checking all items in a list and capitalize them. Those are for loops. And try-except things, like: try to open a webpage, except you get an error saying the page can’t be accessed. (We’ll use that while retrieving search engine results.) Ok, so match for an overview. Let’s dive in. 5.7.1 For Loops: Iteration and Unpacking We have already seen for-loops. For loops are used to iterate on collections and perform an action for all the elements affected by the loop. The syntax is the following (items in bold mark reserved keywords and necessary syntax in terms of columns, newline, and spaces): for; indicate a variable for items we want and we are going to manipulate; in; name of the container of the items: it can be a list, a dictionary or even a function that returns them, example: the range() functions, which return numbers in a range; : (this semicolon is really important, it signals the beginning of the loop block); after a colon you have a newline; added level of indentation; operations on the items you mentioned in point (2). Here are some examples: For loops examples - ch. 5.7 items = [&#39;first item&#39;, &#39;second item&#39;, &#39;third item&#39;, &#39;n item&#39;] for i in items: print(i) #i matches the previous i #same output, different names for item in items: print(item) #the name you use to iterate an object doesn&#39;t #matter for number in range(20): print(number+1) #returns numbers from 1 to 20 5.7.2 If you Want to Evaluate Conditionals, Add If Conditional loops are used to evaluate a condition and branch your code into cases. We have seen it already when we checked if some objects had a specific length. The syntax is the following (items in bold mark reserved keywords and necessary syntax in terms of columns, newline, and spaces): if; indicate the item you want to test; provide a condition to be tested; : (this colon is important, it marks the beginning of the code of the statement - other languages use parenthesis for that); after a colon you have a newline; added level of indentation; operations on the item you mentioned in point (2) you want to happen; (what follows here is optional) newline; deindent; else : newline; indent; what should happen if the condition fails. This is a superverbose way to say: “if a, then x, else y”. You can also use elif to test multiple conditions being true and then execute your code as soon as one fire. Note: you can have only one else condition (think about it in terms of if a… else (if a is not the case) something else). But you can have multiple elifs. Think about moving a player with the keyboard: the player moves if you press left or if you press right or if you press up… the first key you press makes the player move. Ok, enough talk. Here are some examples: If statements examples - ch. 5.8 #check if a number is above threshold number = int(input(&#39;Insert a high enough number&#39;)) #note the int conversion if number &gt; 10: print(&#39;Ok, your number is big enough&#39;) #same case, but adding an &#39;else&#39; which reveals the threshold number = int(input(&#39;Insert a high enough number&#39;)) #note the int conversion if number &gt; 10: print(&#39;Ok, your number is big enough&#39;) else: print(&#39;Sorry, it has to be more than 10&#39;) #using elif #another silly game elif make tiers of ambition possible number = int(input(&#39;Measure your ambition. Enter a number&#39;)) if number &lt;0: print(&#39;How modest&#39;) elif 0 &lt; number &lt; 10: print(&#39;Not too much&#39;) elif 11 &lt; number &lt; 100: print(&#39;Wooo&#39;) elif 101 &lt; number &lt; 9000: print(&#39;Gulp&#39;) elif number &gt; 9000: print(&#39;Over 9000!&#39;) #did we cover all the outcomes? Nope! else: print(&#39;case not considered&#39;) Did you spot which cases were not covered in the last example? In you are in doubt try it out in the interpreter. 5.7.3 Make Things Last for a While with While (and Remember to Break them) While loops are used to make it the case that, as long as a condition holds, some operations happen. Suppose you are programming a (poor) spy. The spy only tracks the movements of the target while the target is awake. As we said, in most of the cases we want to set up on-going enduring activities. That’s why we opt for ‘while True’ conditions: this will keep on going. In these cases we have to be sure to quit the loop by inserting a ‘break’ condition. We test this condition with an ‘if’ statement and this allows us to stay away from infinite loops (which are not good for our pc). The syntax is the following (items in bold mark reserved keywords and necessary syntax in terms of columns, newline and spaces): while; indicate a condition that triggers the loop; : (the colon is important, it marks the beginning of the code block that pertains to the loop) after a colon you have a newline; added level of indentation; declare what you want to happen in the condition in point (2) holds; (adding a break statement) if [condition] : (we already know the syntax of if); (newline indent) break Here are some examples: Examples of while loops - ch. 5.9 a = 1 b = 10 while a &lt; b: print(a) #will go on forever a = 1 b = 10 while a &lt; b: print(a) a = a +1 #now it will stop #bonus: calculate the iterations before this stops while True: #asks you things forever answer = input(&#39;Are you happy?&#39;) #unless you are forced into optimism if answer == &#39;yes&#39;: break 5.7.4 Prevent Crashes with Try/Except Sometimes a program is syntactically fine, but unexpected things may occur. For example: we are passing the wrong data type to a function, we end up dividing by zero or we try to access a website that does not exist. As we already know, when errors happen we want to know exactly what’s going on, so that we can promptly fix the code. Most of the errors are re-occurring - think about accessing a webpage that, for some reason, is not displaying - and, for this reason, Python comes with a list of built-in exceptions. The list has different kinds of possible errors and tells us what happened and when the error is printed. It is good to have a look at that list. Also, it helps when we receive traceback errors: https://docs.python.org/3/library/exceptions.html#bltin-exceptions. Now that we know about this list of exceptions, we can use it to our advantage. We can now structure our code such that it tries to do something and, given we know we may encounter some error (like the 404 page not found), we are ready to handle an exception. In that way we are able to detect some errors and provide better feedback on what went wrong. Let’s use ValueError as an example. (From the docs: Raised when an operation or function receives an argument that has the right type but an inappropriate value, and the situation is not described by a more precise exception such as IndexError.) We use ValueError to handle the case in which we ask to enter a number and we receive something else, like a string… With int(string) we have the correct type, because our string (suppose ‘hello!’ or ‘three’) is converted to int. Still, ‘hello’ is the wrong value for an int. Try/Except block, nested into a while loop (with break) while True: try: x = int(input(&quot;Please enter a number: &quot;)) break except ValueError: print(&quot;We said number! Not letters naming a number.&quot;) (Later on in our programs we’ll touch this by using the raise_for_status() method of the requests library that will check if our webpages exist or not. Requests is using a HTTPError from the urllib, which is part of the standard library -https://docs.python.org/3.2/library/urllib.error.html). All this flow control (plus passing arguments to function and calling methods) can be learnt visually. Sometimes mapping down the flow of our program is helpful. You can do it by hand, as it’s a great exercise. Or you can use tools, such as this: http://www.pythontutor.com/. 5.8 Classes and Comprehensions: More Pythonic Things It is time to step into two slightly advanced things. The first is classes. Classes are the blueprints of our objects. Up until now we learnt a bit about data structures and flow controls. With functions we are able to group together pieces of code and make them reusable. Using a function we can easily compute the area of a rectangle given the sides, rather than having a whole program that asks for one side, ask for the other one, and then computes the area. To give you a more real-life example, suppose you are working on social media and politics and need to get followers on Instagram for a certain account. It is likely that you are going to first target the account and then do something like: connect to the webpage of the account, make a request for the page, play around with HTML, isolate the follower count you need, get the number. (We are going to do something similar with search engine results later in Part III.) As soon as you are successful you wonder: what if I can abstract a bit more and make a function out of this program? In that way I can build a list of accounts I want to track for my research and then iterate over them with a for loop. For every account in the list, run the social media tracking function. As you do that, you’ll feel relieved and excited. Your code and efforts start to pay off and, with a few refactoring, you can widely extend your dataset. Ok, now imagine you want to do more with your data. Maybe you want to store weekly social media data, visualize the follower trends and maybe compare an account to a reference account. You keep adding function definition after function definition… you review flow control to have a better organization of the workflow, but that’s not enough. Wouldn’t it be nice to have a further layer of abstraction such that different functions can be grouped together and performed on inside the same big container? Something similar to what happened with strings and their methods. After all, if we can replace, strip, lower, etc strings there should be a way to visualize, compare, extract data for an account… and you are right! Classes allow you to do that. The second thing are comprehensions. Norvig had them in his script. Comprehensions are not related with language tests, they are a specific Python feature that allows you to build lists, dictionaries, or set by way of iterating on certain objects. Suppose you want to find out who are the followers of the followers of a certain account. You want to say something “apply the extract_followers function for all users in account_followers”. That’s a comprehension statement in a nutshell. Basically we are shortening a for loop. Such a thing is sometimes referred to as “syntactic sugar”, a nicer and easier syntactic way to achieve the same result of a more verbose coding practice. Also, comprehensions are considered very Pythonic, in fact, they are a specific Python language trademark. Ok, let’s dive in. 5.8.1 Classes: BluePrints for More Classes are another way of structuring our data. Think about them as blueprints. You define general instructions in class, then you instantiate them to have the actual objects. If this speaks Plato or Types/token debates, you’re welcome. Programming wise you can think about classes as a way to build a deck of cards. The card class has some properties: value (Ace to King), color (red or black) and rank suit (Spade, Heart, Clubs, Diamonds). If you’ve heard about object oriented programming or have friends working with Java, that’s what we are talking about (well, kind of, if you spend some time reading the docs about Python classes: https://docs.python.org/3/tutorial/classes.html). Classes are defined with a served word which, you can guess, is class. Conventionally class names are Capitalized. This is helpful. When you are using libraries and someone else’s code and you import capitalized items chances are that they are Classes. (You have seen that ValueError from our try/except example is capitalized and, if you go through the docs, you find out that exceptions are Classes). This is a convention, so there is no 100% guarantee it will apply to all the code that you read. Nonetheless, it is precious information because you know that classes come packed with their methods, in form of definitions. So now we move to creating a Class and adding some methods. Ok, let’s get back to the social media account analyzer sketched above. The first thing is to initialize our class, which is a complex way to say we have to specify the attributes we want our objects to have. Here there are two odd looking items: classes are initialized with a “dunder init” function (i.e., with this double underscore init: __init__). The double underscores are somehow intimidating; when we initialize a class, we need to tell the class what we are talking about the class itself. So we are passing self as an argument to init. This looks less nice than the example we have seen before. Anyway, here’s a class. Initializing a class class SocialMediaAccount: #initialization def __init__(self, name, category): self.name = name self.category = category When we are calling an instance of a SocialMediaAccount the init function is going to construct SocialMediaAccount that has will take as a name the name we type (‘Bolt’) and as a category the category we specify (‘Athlete’). Basically with the init method we are passing the arguments to the class instance itself. If now we want to create an object for the singer Imogen Heap, we just need to have call the constructor with the different parameters: SocialMediaAccount(‘Imogen Heap’, ‘singer’). Remember that, to construct these objects we need to instantiate class objects we need to assign them. So, if you want to have the two accounts you can do like that. Constructing objects out of classes - ch. 5.10 class SocialMediaAccount: #initialization def __init__(self, name, category): self.name = name self.category = category #initialize the Trump object account_trump = SocialMediaAccount(&#39;Trump&#39;, &#39;politician&#39;) #initialize the Imogen object account_imogen = SocialMediaAccount(&#39;Imogen Heap&#39;, &#39;singer&#39;) #test that account_imogen.name shoows &#39;Imogen Heap&#39; This is cool, but is not going to help. Now we can add methods to a class (instance method). So we can add a method that, given an Instagram url or name, it delivers us the followers. We rewrite our class as follows. Adding an instance method to a class class SocialMediaAccount: #initialization def __init__(self, name, category): self.name = name self.category = category def insta_follower(self, url): #insert processing function #we are not providing this here return instagramfollowers #initialize the Trump object account_trump = SocialMediaAccount(&#39;Trump&#39;, &#39;politician&#39;) #call the method that gives us the follower account_trump.insta_follower(&#39;http://instatrump&#39;) I am sorry not to give the whole Trump Analytics kit, but we were interested in seeing an approach to classes. I thought it was better than having a tutorial with barking dogs or playing cards.39 Getting back to the analytics projects, there is something worth discussing to persuade you to go into the project. First, data structure-wise, our class has a pair of values: do you remember a data structure that does its best in saving key value pairs? Still, if we develop the project, we may end up adding methods that target different urls for different social media. Why track only Instagram when we have Twitter as well? This is an issue. Different social media requires different functions, which is fine. Nonetheless, different social media are hosted at different urls. Some users have the same alias across platforms, some don’t. So we need to find a way to store a list of social urls. A dictionary with dictionaries? Something else? That’s up to you. Or, to simplify the functions, we may encode all these data in the init of the class. If we are lucky, we can store only the ‘social_id’, if that’s consistent. When we call the twitter function there would be no need to add an url. We can find out to construct it with some form ‘Twitter’ + ‘social_id’. Otherwise we store all the social urls. Below is a mock implementation of this latter scenario. Class-based mock Social Media Analyzer class SocialMediaAccount: #initialization def __init__(self, name, category, instaurl, twitterurl): self.name = name self.category = category self.instaurl = instaurl self.twitterurl = twitterurl def insta_follower(self): #insert processing function #we are not providing this here instagramfollowers = extract(instaurl) return instagramfollowers def tw_follower(self): #insert processing function #we are not providing this here twfollowers = extract(twitterurl) return twfollowers #initialize the Trump object account_trump = SocialMediaAccount(&#39;Trump&#39;, &#39;politician&#39;, \\ &#39;instaTrump&#39;, &#39;twitterTrump&#39;) #call the method that gives us the follower account_trump.insta_follower() #no need to specify the url #that&#39;s already in the class account_trump.tw_follower() #no need to specify the url #that&#39;s already in the class 5.8.2 Comprehension Python allows us to write comprehension. On the one hand, comprehensions are great, compact and Pythonic. On the other hand, comprehensions can look a bit esoteric at first. We can think about comprehensions as ways to shorten a for loop. We can generate a list of output that is the result of performing some operations on a set of items (e.g. items in a list). A general template for this is: Well-known for loop (written in a non-Pythonic way) items = [&#39;first item&#39;, &#39;second item&#39;, &#39;third item&#39;, &#39;n item&#39;] #initialize output output = [] for item in items: operation = item + item output.append(operation) You can squeeze all this in this one-liner using comprehensions (bold is for the comprehension): A list comprehension #comprehension begins with [] telling it produces a list #that&#39;s list comprehension #first we say what we want as an outcome, i.e. specify the #process to be followed #then we define for which items output = [item + item for item in items] (What should you add to the code above to be able to run it and see the output displayed?) The pattern for the comprehensions is that of output = operation you want to perform for items that are in a certain container. The code above is equivalent to the more explicit for loop. We can rephrase this a bit further. In fact, item + item is not the best example of an operation to perform on items. Suppose you have a dedicated function you want to run on some arguments. The comprehension looks like the following: (List) comprehension passing arguments to function - ch. 5.11 def yourfunction(x): print(x) print(x*x) output = [yourfunction(item) for item in items] This is equivalent to the way longer: Function and for loop (not-Pythonic) def yourfunction(x): print(x) print(x*x) output = [] for item in items: output.append(yourfunction(item)) The best way to get proficient with comprehension is by practicing them. You are welcomed to turn previously used for loops into comprehensions. Now try to write comprehensions and for loops for the following cases: check that all the elements you scraped from a website matches a certain pattern; check all the lines of a text and ensure that there are no cases of double spaces, if a double space occurs, correct it to a single space; You can extend comprehensions to sets, by turning the square brackets of a list into curly brackets. You can also use comprehensions in dictionaries and sets. Explore these yourself, maybe squeezing some of the above dictionary-related tools into comprehensions. 5.8.3 More Comprehensions Comprehensions extends to sets and dictionaries. For dictionaries we need curly brackets and a colon. We define our pair of key: value and then use the comprehension syntax for key, value in container_of_keys_and_values. The best example is this nice comprehension to swap keys and values which I’ve kept you waiting for way too long. Swapping dictionaries comprehension a_dict = {&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3} {value:key for key, value in a_dict.items()} #prints {1: &#39;a&#39;, 2: &#39;b&#39;, 3: &#39;c&#39;} 5.9 Functions Revisited: *Args Times! There are more things we can do with functions like using passing one function into another one. This looks a lot like first you solve (1+2) in the parenthesis and then multiply by 3, as in this old elementary school expression: (1+2)*3. The difference is that this time we can define all sorts of functions, we are not restricted to maths and fractions. (And we have to keep track of data types and data structured so that all the functions can be plumbed together producing the result we have in mind.) So we go back to our shout function but this time we pass it a function to a different function, namely one that repeats the input. Passing functions - ch. 5.12 def shout(word): return word.upper() def repeat(word): return word + &#39; &#39; + word #want to &#39;Say what?&#39; screaming twice? if __name__ == &#39;__main__&#39;: print(repeat(shout(&#39;Say what?&#39;))) Ok, we can successfully take something that is produced by a function and input it somewhere else. Cool. What if we need some default value, i.e. something to be used as a value should you not assign anything to the function? We can do this by adding the default value we want after the argument of the function, adding = ‘default value’. Let’s apply a default argument to our shout function. Default values in action def shout(word = &#39;this capitalizes stuff&#39;): return word.upper() shout() #returns THIS CAPITALIIZES STUFF shout(&#39;let it all out!&#39;) #returns LET IT ALL OUT! What if we want to pass more than one value to our repeat function? Welcome *args. We can define functions that take an arbitrary number of arg(ument)s. The issue is that *args provides us with arguments as a tuple (that’s why we have to cover them). We then need to find ways to unpack the arguments in this tuple. Suppose you want to repeat more than one word at a time. This will throw an error: we can’t concatenate tuples! Error is coming… def repeat(*words): return words + &#39; &#39; + words #if you type word you #have error of unknown variable #we want the word in words, but &#39;word&#39; is not #in our current code. To fix this we want to extract single words from the items in the tuple. A list comprehension comes to rescue us. It provides us string items (the items in the list) and it allows us to unpack the tuple. Basically we are saying “repeat each word that is supplied in the *words field”. There it is below. Unpacking with comprehensions def repeat(*words): return [word + &#39; &#39; + word for word in words] We can give our functions even more stuff. Sometimes you have functions with options or default messages. For your Python explorative pleasures we have to say there are also **kwargs, i.e. keywords arguments. Kwargs accept positional or named arguments which, given what we know from the data structures section above, we can identify as dictionaries. 5.10 What’s In a Name: Naming Conventions and Styles Ok, our tour into Python is almost over, at least to get us started. We have already seen quite a lot on the way: from spell checkers to basic tools for textual analysis. We’ve also sketched classes to analyze social media! It is time to enumerate some naming conventions and style guidelines, listing things that we said explicitly or saw in action in the example. Names tells you a lot in programming: ClassesHaveCapitalLetters: when naming classes, we use capitalization to signal that; CONSTANTS_ARE_ALL_CAPS: sometimes programs have a parameter. Suppose you have a fixed view of items per page, that’s a constant value in the whole program. Or suppose you are using lifes at the start of a game or gravity, speed, max number of opened windows, etc. When you encode constants, they go all capitalized, so that you can easily spot them; you can’t use reserved words in your naming variables: no ‘in’, ‘is’, ‘for’, ‘list’ or other. You can escape problems with ‘list’ going for ‘list_’. But maybe it is better to use a more informative name for your list; spaces are not allowed in variable names: this leads us to choose between CamelCase vs. snake_case. This depends on the codebase. leading underscores (like ‘_this’) are conventionally for throw-away variables: suppose you are in need to have a dummy variable to use just once. You need it to perform a calculation or to filter some data. Put an underscore in front of it and name it. Conventionally who reads your code will know that the ‘_x’ is not going to last for long. 5.11 Saving and Running a Python Program: .py and .pyw We know how to run our code in the editor, but what about saving our precious experiments? You’ve probably already saved some code from Spyder as .py, i.e. the standard python extension. It is good to know that there’s also the .pyw ending. The difference is that, in the case of .pyw we are running the file without opening the interpreter. (Which makes it perfect if you want to run a program or a tool in the background, as a daemon, as they say in geek speak.) In fact, if you try to double click on a .py file, your system will try to execute the code and not to open it in the editor. (If you want to edit a .py file you right-click it and open with python’s IDLE or open it in your editor of choice). When you run a Python file, an interpreter session is opened as well for you to get feedback on what happened. This helps if your program is outputting something or if an error occurs. In fact, in the interpreter you’ll see the error’s traceback. Learn to read traceback errors, they are the quickest way to fix the code. If you want to package your file for a friend to use it, you need to research a bit on the topic of freezing code. On windows, you would like to have a .exe file for your friends to click on. And your wonderful PDF magic tool will be there for them to use. Unfortunately, that’s not the case. The easier solution is that you: lure your friends into Python. Then they’ll have access to your tool on Anaconda or similar; find a web-based environment to have your tool available. Try Colab or Jupyter Notebooks (which needs Python installed nonetheless); tell them about this book :). 5.12 Working with Files Ok, we know quite a bit of Python. We now need to move onto files. File operations are necessary to open files in order to read data from them, saving data to files, etc. We can’t have self writing papers if we cannot create or read (text) files! 5.12.1 File Types: Text and Data In Python we can deal with Python as text objects or as bytes objects. We most of the time use the “ordinary” text files, but we’ll also use binaries when dealing with pdf later. These two types are easily distinguished: text file: ordinary file, you can open them with any text editor; binary files: specific data files, with a specific encoding (.xls, .pdf - even if they have text, .bmp, .jpeg, .mp3). When dealing with file modes, Python defaults to text files. If you want to work in binary mode you have to specify that adding an -b flag at the end. 5.12.2 File Modes: What Do you Want to Do with Files? You may want to do different things with your file, both text files and binary files. Depending on what you want to do you choose the appropriate mode by specifying a flag. The file modes are the following: ‘r’: Read mode. This is how you access the information. You have to think about it as read only. You can’t alter the content. If you want read mode for binaries, the flag is ‘rb’; ‘w’: write mode. This is how you can modify a file. Modify includes creating it. This may be counter intuitive. Try thinking about this as “writing a file for the first time”. Also, when we write a file we are starting all over again. So if you have two lines to write on a file and you call the file in write mode to write line 1, then you call again the file and write line 2 you’ll see only line 2. Calling write mode for the second time will let you restart the writing process. To work in write mode with binaries use ‘wb’. If you want to keep writing on the same file (think “turning the pages of a book, rather than restarting on the first page every time”), we need the append mode; ‘a’: append mode. This is what you need to append (i.e. add) information at the end of a file (think “keep turning the pages of the book, instead of buying a new one and read page one again. Then repeating this whole buy-read page one business”). This is what you should use to add content to a file line after line. Again, to work with binaries change the flag to ‘ab’; ‘r+’: Read and Write mode. This allows you to read from a file and write to it. Writing works as ‘w’, so erasing the old content. To have this work in binary mode, we keep adding the -‘b’ flag at the end: ‘r+b’; ‘a+’: Append and Read mode. This allows you to read from the file and append to it. To work with binary files use ‘a+b’; ‘x’: creation mode. This is used to create a file and only for that (should you need that specific option). The binary version is ‘xb’. 5.12.3 Opening and Writing to File To open a file we need to assign it to some object and then call open(‘filename’, ‘filemode’). Files have to be closed when you are done with them (think of this as clicking the X on a program window). This helps in managing resources. We close files with the close() method. Putting this all together: Open and close a file (file dentist) #open file, be sure it&#39;s in the working directory file_object = open(&#39;yourfile.txt&#39;, &#39;r&#39;) #close the file file_object.close() This looks tedious. There’s a lot of things we have to do while programming and we may forget to close the file at the right time. But we can ensure that it is done for us by the computer. We need to use a with statement. By using with statements we can assign certain operations a specific name as an alias and perform operations on that. As we exit the with statement, that acts as a container for the operations, all files are closed. Here is how to read from a file - you guess it, with read() using a with statement: Reading a file with a with statement #open file, be sure it&#39;s in the working directory with open(&#39;yourfile.txt&#39;, &#39;r&#39;) as dataobject: a = dataobject.read() #do something with that #ok, move to something else Cool, we can open and read files efficiently. But how do we create a new file? Either we use the x mode or, whenever we open a file with w or a mode a file is created. So, to create a file called ‘result.txt’ we can do the following: Creating a new file #open file, be sure it&#39;s in the working directory newfile = open(&#39;result.txt&#39;, &#39;a&#39;) #or newfile = open(&#39;result.txt&#39;, &#39;w&#39;) #or with open(&#39;result.txt&#39;, &#39;a&#39;) as file: #do something with that file Ok, now it is time to write some lines into the file. This works a lot like appending content to a list: we first ensure our list/file is there, then we specify what to add to the file/list. In case of a file there is an extra condition to verify: the file needs to be opened and we need to open the file in a way that allows us to write on it. Let’s demonstrate how to create a with our ‘dataresults’ using a with statement and writing some lines of results. Create a file and write in it - ch. 5.13 #create the file with open(&#39;dataresults.txt&#39;, &#39;a&#39;) as file: file.write(&#39;These are the results of our experiment&#39;) file.write(&#39;\\n&#39;) #add new line file.write(&#39;Account X has N followers on social Z&#39;) file.write(&#39;\\n&#39;) This is just a template. You can add the newline at the end of the line and not as a dedicated write statement. Also, you can have the X, N and Z as arguments that you pass to a certain function. In that way have your function or class to be able to write its own data.40 5.12.4 Matching Files with a Certain Ending, System Paths, and Working Directory There’s another operation that you may want to do. Chances are that, when running programs, you are going to iterate on folders and do things to specific files. The good news is that the os module (you guessed it: operative system) allows you to run most of command lines operation like dir in Python. Suppose you want to merge all your pdfs in a certain folder. You need to find out all the pdfs there. That’s easy. You need all the files in the directory ending with pdf. You can check file endings with the .endswith() method. All you are missing how to perform the equivalent of CLI ‘dir’ command. The os module has what you need. The method is: os.listdir(). From the docs we learn that the function Return a list containing the names of the entries in the directory given by path. The list is in arbitrary order, and does not include the special entries ‘.’ and ‘..’ even if they are present in the directory. Suppose you want to collect all the pdfs in a folder. You just need to find them and append them to a list called mypdfs (for example). Then you can run operations on them. The files you want to operate with must be available to your Python session. If you operate on files and call functions like open(‘myfile.txt’, ‘r’) Python assumes the file is available in the current working directory. If the file is not in the current directory, you get an error. To find out what your current working directory is we can use the os module again. The method is: os.getcwd(). You can change your working directory with os.chdir(‘path/of/new/directory’). If you want to operate on file outside the current directory you can access them providing the full path, taking due care of proper formatting of your string. Here are the docs to be a path manipulation master: https://docs.python.org/3/library/os.path.html. 5.13 Regular Expressions Regular expressions (or ‘regex’ or even ‘regexp’) are a powerful tool to search and modify text. The idea is pretty simple: with a regular expression you assemble some specific LEGO bricks that stand for different elements (characters, digits, punctuation, repetitions) to form a pattern. Then you use this patter against an input and retrieve the matches. You are given multiple options on where and how to match: at the beginning of a line, parsing each word, inside a word, etc. You can retrieve segments of what you match using capturing groups, which we’ll use in a while, and choose to perform specific operations with your matches, like changing all the matched ‘\\’ to ‘/’ or the other way around. In a famous piece advocating regex knowledge, Corey Doctorow writes: “Regular expressions are part of the fundamental makeup of modern software. They are present, in some form or another, in every modern operating system. Word processors, search-engines, blogging programs … though it’s been decades since software for everyday people was designed with the assumption that users would know regexps, they still lurk in practically every environment we use”. We’ll perform our regex workout in Python and we’ll extract bibliographic data from academic papers. If you are eager to get started skip the following short historic section. 5.13.1 Regex Notable Features Regular expressions were conceived by Kleene - yes, that Kleene you know from logic41 - early in ’50 when he described regular languages.[See https://en.wikipedia.org/wiki/Regular_language for a quick intro.] Later on, they were implemented Unix text processing utilities. All advanced nerdy text editors (Vim, Vi, Grep, sed, AWK, and co) have them. Doctorow’s piece inviting the school system to teach regex to the kids (read that here: https://www.theguardian.com/technology/2012/dec/04/ict-teach-kids-regular-expressions) has already been mentioned. What wasn’t mentioned is one of the best paragraphs to motivate some research in Digital Humanities and building technical literacy: “Much of the world you interact with, from cash machines to your bank’s website to the website where you sign on for disability benefits to the alarm clock that wakes you in the morning to the phone that tracks your location, social network, and personal thoughts, are underpinned by software. At the very least, a cursory understanding of the working of software will help you judge the reliability, quality, and utility of the software in your life”. 5.13.2 Matching Expressions Regular Expressions are a small(ish) language on their own. You have short symbols that stand for something else. We use this regex LEGO to build a pattern. Then we are going to match the pattern against a given text. (There are different flavors and different implementation of them, as it’s often the case). Regular expressions are at first hard on the eyes, but all you need is just a little patience, as Axel said. Most of the LEGO bricks start with a \\ followed by something. Most of our LEGO bricks are two characters set. Here are some of the most used: do you want to match any digit, i.e. a number going from 0 to 9? Use \\d do you want to define a customized class of ranges to be matched? Use square brackets and put the range limits inside, separated by a dash (-). For example: if you want to match numbers from 1 to 7 go for [1-7]. If you want to match any digit and don’t like the \\d syntax we have used above, go for [0-9] if you want to match any character, use the dot . if you want to match one or more occurrences of a certain pattern use the star * if you want a certain component to be optional, add a ? after the component. This is a quantifier meaning “zero or one occurrence” if you want to match a space, use \\s parentheses ‘(’ are a symbol of the language, in fact, they define capturing group - see later. If you want to match a parenthesis you have to use regex escape character, i.e. \\ if you want to match whatever is not a white-space you can use \\S (in that way you will catch Capitalized and lower letter, digits and punctuation) if you want to match a word character use \\w (word characters include letters Capitalized and not capitalized and digits and the underscore character) 5.14 Learn by Doing for the Humanities: Matching Bibliographical Patterns Our task is that of identifying the bibliographic data in a paper. We assume the paper is given as text input. Our task is to develop regexes for the different styles of bibliography, in particular: Author (Date); (Author, Date); (Author Date); fulldata: which, more or less, has the following form: “Author separator title separator publication separator date”. We want to be able to match these different styles and we aim at a standardization of these inputs. For each of these we’ll extract Author and Date. We’ll need capturing groups for that. 5.14.1 Capturing Groups We want to standardize the references we find in different styles to something simpler and common, like Author Date. No fancy parentheses or similar. This standardization can then be used to make some analysis on most quoted or influencing paper or whatever you want. We need to detach some information so that we can compare the bibliographies across different journals employing different styles. To produce that standardization we can use capturing groups. They are groups that allow us to retrieve just a part of what we matched (here: Author and Date). To add a capturing group to a regular expression all we need is to delimit the group by using brackets. In Python, the groups are accessed as items in a list. Suppose we have a regular expression like regexbookchicago that captures books under the Chicago style. If we single out two capturing groups from that, we can access them as list[0] and list[1] a code example may help. Regex and capturing groups template import re #mock regex matching chicago style regexbookchicago = &#39;(authorpart) title (date part)&#39; text = &#39;Some text with Chicago style references&#39; #store a list of lists of all our matches match_pattern_to_text = re.findall(regexbookchicago, text) for match in match_pattern_to_text: print(&#39;Match found: &#39;, match_pattern_to_text[0] + &#39; &#39;, match_pattern_to_text[1]) 5.14.2 Matching Author (date) Let’s start with matching Author (date). Our basic task is to build regex-LEGO bricks to match Author and date. A date is pretty easy, it’s just a block of 4 digits (we are ignoring referencing stuff 3 digits, like Giustiniano 529; or dealing with 2003a or similar). A date is nothing but something like this: Date as regex import re dateregex = &#39;\\d\\d\\d\\d&#39; We develop this adding a sample test that features textual elements. We are going to match dates in this test and then print the result. Regex data test - ch. 5.14 import re dateregex = &#39;\\d\\d\\d\\d&#39; sampletext = (&#39;The biggest contribution to the field is due to &#39; &#39;Master (2001) and its impac cannot be denied&#39;) match = re.findall(dateregex,sampletext) print(match) Run this and see we are catching ‘2001’. Now we need to add author with is nothing but a surname, i.e. a Capitalized letter followed by some non capitalized letters. To catch the author we basically want a capital letter in the range [A-Z] followed by any number of letters in [a-z] range. A first implementation would be: author1 = ’[A-Z][a-z]*’ Note that this is not the same as author2 = ‘[a-zA-Z]*’. In fact author1 requires a Capitalized letter in at the beginning of the match; author2 does not. It will match continuos strings of capitalized and non capitalized letters, included tHisOneHere. (Note that author2 if written as ‘[A-Za-z]*’ may result into errors on some compilers online.) You can also implement the author as author3 = ‘\\S*’ solving the capitalization issue. Beware that here you will also get all the words into the text punctuation included. To exclude the punctuation go for: author4 = ‘\\w*’. The code template below allows you to play around and understand the various ways to catch the author. Substitute the different author expressions above into the authorregex variable and try to match Master only. A regex matching more than we wanted to - ch. 5.15 import re authorregex = &#39;INSERT ONE OF THE AUTHOR REGEXES ABOVE&#39; sampletext = (&#39;The biggest contribution is Master (2001).&#39; &#39;Its impact cannot be denied, on pain of miSbeHaving.&#39;) match = re.findall(authorregex,sampletext) print(match) As you could see, we are overmatching our text. Depending on the expression used we are going to get whatever starts with a capitalization (‘The’, ‘Its’) and more. Don’t panic, we are on the right track. We need to connect the two elements we have identified. What’s linking them together in a unique way? First, parentheses are around the date, so we have to add them to the date (remember to escape them). Then, there’s the space in between. The resulting code is below. I’ve opted for ’[A-Z][a-z]*’ to match the Author as it is easier to see what we are asking to match. Matching author date regex import re authordateregex = &#39;[A-Z][a-z]*\\s\\(\\d\\d\\d\\d\\)&#39; sampletext = (&#39;The biggest contribution is Master (2001).&#39; &#39;Its impact cannot be denied, on pain of miSbeHaving.&#39;) match = re.findall(authordateregex,sampletext) print(match) Run this and be happy, we are getting the ‘Master (2001)’. Now it’s time to isolate the elements with capturing groups. We want to isolate author and date, without the parenthesis. See if you can match the two groups adding parentheses. Here’s where to put them: Regexes and capturing groups - ch. 5.16 import re capturingauthordate = &#39;([A-Z][a-z]*)\\s\\((\\d\\d\\d\\d)\\)&#39; sampletext = (&#39;The biggest contribution is Master (2001).&#39; &#39;Its impact cannot be denied, on pain of miSbeHaving.&#39;) capturingmatch = re.findall(capturingauthordate,sampletext) for item in capturingmatch: print(item[0] + &#39; &#39; + item[1]) 5.14.3 Matching (Author date) and (Author, date) Things start getting nasty here. First, we have to choose if you want the same regex to perform both matches or not. It seems that the second expression (Author, date) is nothing but the first (Author date) with an added comma. That’s a tasty opportunity to use optional matching (zero or one quantifier above, i.e. ‘?’). Still, if we go down that path we had to be aware that not all the equivalent author options we saw above are still valid. In fact, if we match the author with ‘\\S’ we are going to catch the comma after author in (Author, date) as part of the author name. So it will be in the author capturing group. The nice part about this expression is that whatever we need to capture is between the parenthesis, so there’s no need to match the two parts and then find a way to join them. Here’s the code to match the expression, with the optional parenthesis. Our new regex is called capturingparenthesis and the sample text now includes (Author date) and (Author, date). Multi matching with optional comma import re capturingparenthesis = &#39;\\(([A-Z][a-z]*),?\\s(\\d\\d\\d\\d)\\)&#39; sampletext = (&#39;The biggest contribution to the field is due to &#39; &#39;(Master 2001). Nonetheless, (Slave, 2002) is probably a more &#39; &#39;accessible version of these ideas.&#39;) capturingmatch = re.findall(capturingparenthesis,sampletext) for item in capturingmatch: print(item[0] + &#39; &#39; + item[1]) 5.14.4 Fulldata Fulldata is the worst part of our mission. Not only the style varies across the different items (article, journals, etc.); often you won’t get a bibliography at the end to have a simplified tool to check for accuracy. The bad feature for us is that the information we care about are far away from each other. Author is somewhere at the beginning but the date is at the end, surrounded by a ridiculous amount of stuff like title, editors of volumes, issues of the journal, journal names, etc. Every element adds more complexity to our guessing and singling out a scheme. Think hard and try to find a solution. Here’s an attempt: Regex for fulldata, an attempt import re fulldatatextsample = (&#39;Murphy, &quot;Was Hobbes a Legal Positivist?,&quot; &#39;Ethics (1995)&#39;) regexfulldata= &#39;([A-Z][a-z]*),\\s&quot;[A-Za-z\\s?,&quot;]*\\((\\d\\d\\d\\d)\\)&#39; What is doing the heavy lifting here is the following term: \"[A-Za-z\\s?,\"] In fact, we know how to catch the name and the year, the hard part is that of getting the re modular part of the title. The title of the work is going to include letters (both capitalized and not capitalized) and spaces, as a title is often composed of more words. We also need to catch special delimiter, like double-quotes. Note that this will catch also the name of the journal. In fact, we don’t know how many words are going to be in the title. The rest of the implementation of the script is the same as before, so you can use it 5.14.5 Limitations, Open Issues and Regex Building Tips There are several issues with our first attempts. In fact, right now we can’t get titles that include parenthesis. We can’t include numbers. A better attempt would be to parse the fulldata string as: author; title; journal/book/whatever; year. We need to use proper separator matching the style of the journal. We only scratched the surface but nonetheless showed that we have a powerful tool here. Some of the limitations are: we are not capturing a, b, c in the date: how can we handle that? we are not considering two parts surnames like von Fintel, von Wright, van der Torre, De Re, De Seh, etc. And what about De Las Casas? (You may say that’s not an issue as we are going to get the last surname) sometimes we have multiple quotations from the same author, like Master (2001, 2002, 2003, 2004) (No, that’s not a sample of Federer’s Wimbledon series). How can we cope with that? Author (date) is cool, but it can get worse. Our implementation fails to get Master (2001, 2002) as well as Master (2001: 112-121). Is there a way around that? What about coauthored papers? We are to work on ‘Author &amp; Author’ and also ‘Author et al.’. I find it useful to build the regular expression piece by piece. So, in this case, I try to isolate the author and the date. This helps to see how your regex may fail, like matching any capitalized word in addition to the Surname of the Author. If something more complex is needed, like in the case of better implementing the fulldata case, you can try going the other way around: first, you match most of the string and then try to reduce what you matched. 5.15 Summary We’ve seen quite a lot of things here. This is probably the most dense chapter so far. It covered both basics and ways to use them. Most of the interesting ways to use the basics were merely described and not implemented. Come back here and try to realize these programs after you have more experience (e.g., after going through part III). We also start working on more applied research-based stuff exploring regular expressions. 5.15.1 Programming Concepts, Methods and Functions Recap We have gone through the following functions and methods. Make sure they make sense to you: input() type() int() str() set string_slice[beginning_included:end_notincluded:step] string.upper() string.lower() string.capitalize() string.split(“separator”) string.replace(“selection”,“replacement”) len() list.append(“item to add”) list() range(beginning_included:end_notincluded:step) dictionary.get() dictionary.values() dictionary.items() floor division % try … except if (elif) (else) for in while comprehensions defining functions and classes (what are init and self?) os.getcwd() os.listdir() os.path 5.15.2 Re module (useful regex Commands) re.match() beginning of the string re.search() any position in the string re.findall() all matches in the whole document (non-overlapping matches) re.finditer(): all matches in the whole document (overlaps included) re.sub(): replace goes regex needs a comparison between findall and finditer 5.15.3 More Resources Of course you want to know more about code specifications. Python Enhancement Proposal 8 (PEP 8 in jargon - https://www.python.org/dev/peps/pep-0008/) is where the format standards are defined. Resources on Python abound. Let’s start from free resources: python’s official tutorial is great https://docs.python.org/3/tutorial/. Be sure to check out parts 10 and 11 on the standard library. Part 12 about virtual environment (you’ve seen them already) and also part 9 on classes if you want more details on them; IPython’s tutorial is great as well https://ipython.readthedocs.io/en/stable/interactive/ but a bit less beginner-friendly. It is closer to a documentation page than a step by step tutorial. Check the introducing IPython section, the “IPython as a system shell” section (now you know command lines) and the “IPython Tips &amp; Tricks” as well as the “Built-in magic commands”. Come back to this quite often. If you feel I let you down with dictionaries, here’s a nice visual introduction https://www.freecodecamp.org/news/python-dictionaries-detailed-visual-introduction/ Here’s a training on dictionaries and the various retrieving techniques we previously only mentioned. In the training you analyze craft beers. HumanDemia says cheers! https://www.dataquest.io/blog/python-dictionary-tutorial/ The LearnXinYminutes website is great to skim over / learn / review essentials. Here’s what we’ve seen and more on Python: https://learnxinyminutes.com/docs/python/. A more comprehensive treatment of errors can be found in the Python docs: https://docs.python.org/3/tutorial/errors.html If you need some motivation and/or perspective on what we are doing, this piece on profession and trade, have a look here: https://medium.com/@christianalexanderbonilla/theprogramming-toolkit-wheres-my-screwdriver-rb-8913473eab4. Time to move to books: Mark Pilgrim’s Dive into Python 3 is free: https://diveintopython3.problemsolving.io/. (Harry J.W. Percival - an author you’ll see mentioned in the next chapter, obey the testing goat! - mentions this, together with Invent Your Own Computer Games with Python by Al Seigwart and Learn Python the Hard Way as the book he used to learn Python). Moving to paid ones: Joel Grus’s Data Science from Scratch. First Principles with Python chs. 4 and 9 have, respectively, a super concise and practical Python crash course and then a crash course on file operations. The rest of the book is also great. (Joel starts with the Zen of Python and venvs, then whitespaces, functions and data structures.) Al Seigwart’s Automate the Boring Stuff with Python is a super gently introduction to Python basics while helping you construct your Python programs that have a purpose and, hopefully, will save you some time. Wes McKinney’s Python for Data Analysis ch. 3 has a nice introduction to IPython. 5.15.4 Further Work There’s quite a lot we can do here: remember the print() function you looked for in quest for its documentation? What’s standard for you learning Python form Python 3.x wasn’t standard in Python 2.x. Unfold this story. every .py file can be imported as a module, included your own programs. Try to look for more. (Hint: ‘namespace’ is a concept that can get you there.) Dictionaries 40 dictionary related exercises (with clickable solutions): https://www.w3resource.com/python-exercises/dictionary/ Regex Programs and Exercises add a / to \\ and the other way around converter; develop date to match also 2003a or similar; write your program to capture internal references in a text. These references could be cross-references to sections or chapters in a book or references to articles and laws in a legal corpus or even more. A hard one: From a Feature to an App? Now you have the basic concepts, if you want to build an app out of this, consider the following user stories, i.e. tech industry way to mean ‘features of the program/app’. If this sounds weird remember that the things you do as a programmer are supposed to have people using it and interacting with it. When was the last time you thought about who was going to interact with your paper, project, or talk slides as an Academic in the Humanities? User stories: user is able to input text; user selects the biblio styles that are relevant for the paper; the output is stored somewhere. If you want a copy and paste approach, clone the GitHub repo of the book.↩ Norvig works at Google and, among many other things, he has a book called Paradigms of Artificial Intelligence Programming you can read for free here: https://github.com/norvig/paip-lisphttps://github.com/norvig/paip-lisp. ↩ Remember? Dunder is the double underscore pattern, so __doc__ is ‘dunder doc’. By saying that we are populating the dunder it means that we are storing the docstrings information somewhere they can be used. Suppose we have a tool that creates software documentation. This tools will look for the information in dunder doc and organize them. Remember using IPython to know more about functions and pieces of code? Often you are getting info stored as docstrings.↩ Still they will populate dunder doc if they happen inside functions, classes and methods.↩ Time objects are quite complex, if you plan to work on task scheduling and optimizer be sure to read the datetime module.↩ I prompt you to explore testing more: the module you are looking for is unittest: https://docs.python.org/3/library/unittest.html?highlight=unittest#module-unittest and there it is.↩ How can we succeed with the replace method if strings are immutable? That’s the kind of great questions that prompts your ever-learning attitude and grasping of the internals of Python. Docs for replace have your answer. And then you’ll want to find out more about copy↩ There are reasons to call ‘conda update’.↩ The latter is quite a good exercise. If you want to explore more about objects and classes have a look at Java and the Head first book mentioned a while ago at the beginning of the chapter. Also try to read some of Design Patterns: Elements of Reusable Object-Oriented Software by Gamma, E., Helm, R., Johnson, R. e Vlissides, J. (known collectively as the ‘Gang of Four’). While the book is Java-based it will show you what you can do with classes in real life.↩ With statements have their own pep: https://www.python.org/dev/peps/pep-0343/. ↩ This one https://en.wikipedia.org/wiki/Stephen_Cole_Kleene.↩ "],
["ch6.html", "6 Moving Forward: From Beginner to Pythonista 6.1 Introduction: Five Sources of Mystery 6.2 Approaching the Tutorials in a Good Way 6.3 Reading the Docs 6.4 Summary", " 6 Moving Forward: From Beginner to Pythonista ‘Congrats for mastering Python syntax,’ says the HumanDemia welcome screen. ‘You are probably already playing out with your newly hardly-acquired knowledge. Enjoy this phase.’ You think they are kinda joking. But what you read next is interesting.42 “Chances are that you’ll move from euphoria and god-mode to depression as the most complex things you’d like to build returns errors or foolish stuff. Or as you figure out that something that should be so conceptually simple to achieve is a pain to be implemented. Fear not, this chapter is there to mitigate this.” Ok, the table of content has something about sources of perplexities in Python, something mysterious about reading the documents and then tips to take tutorials. It looks like a piece of cake. “I wonder where I’ll be thrown the curved balls, here” you think a bit too loud. 6.1 Introduction: Five Sources of Mystery It’s (relatively) easy to get started with Python (as you’ve seen already). Still, after setting up your environment and learn the syntax, there are some hurdles and mysterious mechanics of Python that are hard to face as a beginner and that pro-coders can’t recognize as such. The more you investigate and talk with people, the more it seems that either you are a programmer or a beginner: there’s no in between. Further, once you level up your skills it is difficult to go back to when you failed to grasp basic concepts. (Remember when you tried to add things to a list without having the list initialized? And now it’s obvious you can’t do that? It’s more or less that feeling.) It seems once you enter a new mindset you can’t go back to when you used to struggle. The difficulty in bridging the gap from “I know Syntax” to actually be able to code might be compared to knowing grammar and actually speaking or knowing that the Lydian mode has a #4 degree and actually perform a moving Lydian improvisation. Such skills are difficult to acquire and, once you have them, it is hard to help others reach a similar fluency. Once something that took you a long time to learn, something that you practiced on a daily base until you finally have it, it’s hard to remember what ignorance was like. (I can’t go back to a single monitor setup, my guitar teacher is surely aware of how the world changes the more you know where scales and arpeggios are on the guitar and how they sound, but it’s not easy to guess how much it will take me to get there and feel comfortable about something). Corey Doctorow has a nice quote to explain that with references to regular expressions, or regex or regexp: “Knowing regexp can mean the difference between solving a problem in three steps and solving it in 3,000 steps. When you’re a nerd, you forget that the problems you solve with a couple keystrokes can take other people days of tedious, error-prone work to slog through.” (https://www.theguardian.com/technology/2012/dec/04/ict-teach-kids-regular-expressions) (I guess we don’t have to blame our teachers. I guess for them we are asking questions that are as hard as “how was it when you couldn’t read English?” or “how did you learn the multiplication table of 5?”.) The more you spend time coding and learning the more it seems that Yoda strikes back: Aspiring or great programmers. There is no in-between. So let’s explore this feeling and this “ok, I know my syntax, I did some project, where do I go next?”. We can identify the following sources of mysteries. 6.1.1 Vocabulary Python has its specific jargon, this can be mysterious when we first start studying it. This can be easily fixed by developing a vocabulary or looking for one. That’s the reason books have indexes, recaps, and lists of definitions or key terms. It is way too easy to use acronyms (PEP, pip install, API) or other Python jargon (the most intimidating is probably the dunder to mean double underscore). It makes us sound proficient, it is cool, it lets us save time. But before we get into this puts us off. ‘Cloning’ and ‘forking’ might be intimidating for new git users. We can solve this issue by building a reference dictionary or vocabulary. There are some already packed ones, but it can be good to develop your own specific one (or to re-arrange preexisting resources in a way that makes sense to you). 6.1.2 Coding for Others Sharing code with others is a complex process but it’s part of the business. As they say “code is most often read than run”. Entering into the mindset of coding for others (or with others in mind) is complex. First, it requires us some confidence in what we are doing. Then it forces us to explore many other issues like: how to properly code for readability; how to follow code standards. Isn’t this all too complex? I mean, we are already trying to learn how to code. Further, as soon as you develop something you feel is useful to others and you have to pass it to your non-techy friends (how can they be our friends, then?), we have to face the issues of freezing code or building apps. (My first technical presentation suffered a lot from that. That’s how I met Go and Ruby. If distribution is your main concern consider moving to JavaScript - everybody has a browser in their pcs, or something app-related). The more you get into readability concerns, the more things we need to care about. Here are some sources of mystery related to readability and sharing code: coding styles: things like PEP 8 (https://www.python.org/dev/peps/pep-0008/) and other formatting recommendations. What and how we indent, how to prompt readability, CamelCase vs. snake_case, etc. There are standards out and a good Integrated Development Environment (IDE in jargon, i.e. PyCharm or Spyder) may help; writing comments or type annotations or assert statements to check the sanity of our code: those things require some time to sink in. You learn the book and would think \"hey, it’s obvious I can read my program. I know the syntax and I know what I’m doing. It was such an effort to get to this print(‘Hello world!’). Then you see your code in two days and… what was that? Flash forward. This happens the more you learn: from procedures to functions, from functions to classes, from a framework to another to “hey, this trick works way better”. That’s why you need comments and some sort of tests. The good part: type annotations will teach you more about data structures and writing tests can open a tester career to you. testing in generals: testing is a beast on its own. Automation and testing, code coverage, continuous development are all things you are going to learn. The first Python step is getting some grasp of the unittest module.43; Pythonic ways of doing things: this is when coding styles and conventions start having consequences not only on the eyes of the reader but also on the runtime of our program. Previous versions of this paragraph had some examples. Reviewing the book and exploring Python I realized that there are two videos by Raymond Hettinger that are actually there to make us appreciate writing great code. Here they are: https://www.youtube.com/watch?v=wf-BqAjZb8M (Beyond PEP 8 – Best practices for beautiful intelligible code - PyCon 2015) and https://www.youtube.com/watch?v=OSGv2VnC0go (Transforming Codde into Beautiful, Idiomatic Python – PyCon Us 2013). Those are hard to figure out because ‘Being Pythonic’ is something you can achieve once you sort out some of the mysteries. It means you: have an understanding of how things work; can solve the task in different ways; know what is it like to be Pythonic (a mystery in itself); are able to evaluate which of the implementations in 2 is the most Pythonic. This leads us to another big topic. 6.1.3 Python Specifics and Internals These things are hard to learn. Ok, probably all books tell us about import this and the Zen of Python. That’s for sure part of the essence of Python and its “spirit”, as are some other things that are beginner-friendly like the fact that whitespace is important. The specific and internals we are talking about are those that will have an impact on performances. Or maybe we are talking about what makes the language you are studying (Python here) different from another language. The point is that, if you are moving your first steps into a language from the humanities chances are you have no idea about another language. Assuming we have some grasps of different languages, we need to be aware and detect “code smells” (another piece of jargon). “Code smells” are pieces of code that work but are not written following the style and best practices of the language. You see that the code works, but there’s something about it. If you have seen the video of Hettinger linked in the previous section, you already have an idea. That’s tricky to develop the ability to detect code smells. Memes might help (stop using i += 1 in for loops!), but the task is still a big one. I mean, we are already studying the features and the language. Maybe, depending on your book and sources, part of these are not presented to you as they might mess around with a more user-friendly learning curve. Nonetheless, this work in a safe environment of an introduction or a book. Then we go out into the wild and some of these things really start to have an impact. And we have no guidance. Here are some of the possible sources of concerns: namespace, python design (GIL, threading), class operations and design patterns, MRO. Other things like shebangs line or main calls. One way to approach these topics is to find the relevant documentation, read it, and try digesting it with small ad hoc pieces of code. 6.1.4 Being Pythonic We have seen this already but it probably deserves an entry on its own. Pythonistas use their own language, their code is cool and, well, Pythonic. Still, getting what it means for code to be ‘Pythonic’ is hard if we are starting out with Python and if you have no exposure to other programming languages. In fact, a perfectly good explanation like: “This is so Java, you see, you initialize the counter of the loop and then go into it updating. This smells Java. Python has a built-in enumerate() function to do that. Not to mention comprehensions…” is quite hard for us to get if we have not enough experience with the compared language. We can try to fix this learning something from other languages. And, when you are there, trying to implement something in your new language (say Java) into your old one (Python). That’s a good way to start comparing things, get a feel for Pythonic ways as well as alternative solutions and implementations. And that’s a reason to have Visual Studio Code installed, you’ll have access to many different languages with just a tool (through plugins). Still, it’s hard to learn many different things at the same time and achieving depth. Be aware of that. Maybe you can use features a language is famous for to better understand the features of your main language. Here’s an example of how this may work. We know Python is dynamically typed. We’ve read a bit about type annotations. What happens if we move into a statically typed language and write our hello world program in Java or C? What happens to programs that are a bit more complex? Another experiment you may want to do has the goal of demystifying Python classes. Someone says to you Java is the best language for object-oriented programming (there are dissidents at HumanDemia?). Java is all about classes and object blueprints. You read a few tutorials about object-oriented programming in Java, build a deck of playing cards or a set of formatting standards for the class PeerReviewedJournal and then you re-build you Evang… sorry, you try to re-implement them in Python. 6.1.5 Black boxes Black boxes are another issue. Python is so good with all its modules and functions. This leads to another problem: we trust Python modules or internals to do the work for us (after all, that’s what we do with machines, right? We don’t question the internals of a washing machine…). We trust some code on StackOverflow or something similar. We are doing something we know it works, but can’t explain why. This is harder to solve. It requires reading the docs and having a look at the internals. But when we succeed, knowledge is built. Nonetheless, there is something positive about Python and also about the fact that there are a lot of modules, packagings, and libraries around: most of them are built in Python. And many are open source. Long story short: most of the black boxes you are using are black boxes only in theory. The code is out there, and you can inspect that. We know about GitHub to explore the code.44 Relying on Python codes in the module, especially those of the standard library, will expose you to a clear written code that complies with Python style guides. You are readying the backbone of the language, after all. The same holds for “industry standard” libraries. Official documentation is another tremendous learning opportunities. Python PEPs always talk to you as a complete developer, showing you a broader picture than a tutorial or even a book. They can also have some nice short programs, like the space trimming algorithm in PEP 257 on docstrings, see here https://www.python.org/dev/peps/pep-0257/. These will give you moments of (Python) Zen. Enjoy. 6.2 Approaching the Tutorials in a Good Way I spent some time learning things by reading tutorials and there are a few words to be said about that. Tutorials are great but there are programming phases know as “tutorial hell” (or “infinite syntax loop”) in which you feel you are trapped into learning syntax all over again, you are able to do things by way of following instructions but can’t program on your own.45 So, as for the main book, there are some instructions in dealing with tutorials that highlight the importance of awareness and interactivity. Here we go. Tutorials are there to get your feet wet and get you started. By no means they are everything you need to know (they are tutorial, right?) and by no means they are there to be the only way. Here’s a list of four pieces of advice to work your way through tutorials to get the most out of them: Tutorials Are Not The Only Right Way: There are other ways to do the things in the tutorials. Maybe there are more Pythonic ways or more efficient approaches. Tutorials are there to get you started and, therefore, they should be easy (or, at least, not necessarily over complicated). Tutorials Are No Sacred Text: Sometimes I was working on a tutorial and thought about “what if I do Y instead of X?”. But then I gave up because I wanted to finish the tutorial first. That’s not how it is supposed to work. Your Work with a Tutorial Doesn’t End when you Finish it: Tutorials are there to get you started. The rest is up to you. Add a feature. Rework the tutorial with different constraints (different languages, only standard library tools, etc.). A good tutorial should have ways to tell you that it is not finished and you have an opportunity to do your part. If you feel that’s a good time to re-read Eric Steven Raymond’s piece on hacking and the incremental-hacking cycle, I’ll spare you the time to look for your bookmark: http://www.catb.org/~esr/faqs/hacking-howto.html Make the Tutorial Your Own: Don’t follow a tutorial passively, engage with it. At least rename the variables. Write tests, add docstrings if there are not. Add comments. Given the things above, I’ve tried to modify the way I approach tutorials. (At least the tutorial that range on something we already have some grasps of, like programming). This is a condensed list from HumanDemia: If You Know Something, Take Guesses: Think of a tutorial like a guided and heavily hinted problem solving session. Before reading the solution (that is, the tutorial) at least take guesses and sketch your own solution. Use your Universal Typing Machine and IDE: When you are working your way through a tutorial instead of having just a file opened where you follow the tutorial (remember point 4 above, try to make it your own) have two. The first one is your main tutorial window. There you follow the tutorial and know that at the end the project will work (assuming the tutorial has reproducible code). The second file is your experiment based on the tutorial. There you add functions or try alternative ways. You have no fear of screwing things up because that’s the point of this file. You have the first safe file to achieve the goal of the tutorial. (What’s the Third File? If you go heavy on notes, you may need a third files to take notes, e.g. in RMarkdown). Extend It: Congrats, you’ve finished the project. Now build more on it! Can you add a saving function? What if you have two players instead of one? What if the program works on more than one search engine? Can you make it faster? Can you move instructions to functions? And functions to class? 6.3 Reading the Docs Tutorials, as said, are just the beginning. Where to go next, often, includes documentation. You want to extend your tutorial, you know that the module you are using has the function you need to add features to your code… but you need to learn more about it. That’s where you read the docs! (The web is wide, but there’s not a tutorial for every function you may end up using. Or, if there is, it is not as accessible as the docs.) Further, tutorials often may point you towards to docs to explore things a bit more, try other ways, etc. So here we go with the Docs. Reading the Docs is a skill we need to learn. We successfully mastered reading papers in our fields, academic writing, proofreading, and much more. Some were able to accept academic and intellectual slavery, and maybe received adequate compensation. Be as it may, to become proficient at coding there’s an extra skill to acquire: reading the documentation. The first thing we need to clarify is what are the docs we are talking about? The first answer is the official documentation of the module or library we are using. Here ‘official’ means: the one produced by those that created the code we are using. You already get what that means: these docs all do the same thing: they (try to) explain someone else what the code and its functions and methods do, but there are no standards. If you want to know more about the webbrowser module or the os module or something else that is inside Python standard library, you can expect some sort of standardization in terms of layout and way in which contents are organized. Documentation is consistent and good also in case of “major” packs: requests, pandas, BeautifulSoup, Flask. Still, expect different choices. (We can conventionally establish something like the following: a package is “major” if it has at least a relevant part of a book dedicated to it. Feel free to tweet me the failures of this definition.) Some docs will include a tutorial or a quickstart. Some may have both. If the library is specific to something, chances are the docs start with a minimal implementation of an app that does exactly that. (That’s the case with Flask). Coming from an academic background, there are a few things that may happen. The documentation of the standard library might look a bit too terse. It is basically a list of the methods and functions. It details the options and parameters available and the kind of data passed. But those are all the important things you need to know. Also, the documentation - beyond its terseness - provides links to other modules, reasons for specific choices, and updates on what has changed over time. The documentation of the standard library is also a document in a historical sense. You also get minimal working examples. It’s ok to read through the documentation of a module from start to finish, multiple times. But it’s also ok to just go there to refresh a specific point, like the order of parameters of a method. On the other hand, some kinds of documentation are huge. For example, if you download pandas references in pdf you may easily get more than 3.000 (thousands, yep, no typo) of pages. That’s quite a lot. If you approach reading things top-down, that would be an issue. Be sure to have a purpose and try to come up with a plan about what you want to grasp and improve by way of reading the (huge) docs. 6.3.1 Why Read the Docs? (A Real-life Case with Bookdown and Ebooks) Suppose you are writing a book with bookdown. You are excited to read your book on your e-reader. For historical reasons you have a Kindle. So you build your book to an epub (bookdown::render_book(“index.Rmd”, “bookdown::epub_book”)) and you already know that you have to perform some epub to mobi conversion magic, for example using Amazon’s Kindlegen. You head over to kindlegen and run it through the command line Powershell (it saves clicks over calibre, you think) and get the mobi. In mixed feelings of anxiety and reverence you open the book - your book. And you realize that there’s no table of content. Of course, you go out and do your research - imagining a long struggle with LaTeX parameters. Here’s what you find: 3.3.1 EPUB To create an EPUB book, you can use the epub_book() format. It has some options in common with rmarkdown::html_document(): epub_book(fig_width = 5, fig_height = 4, dev = &quot;png&quot;, fig_caption = TRUE, number_sections = TRUE, toc = FALSE, toc_depth = 3, stylesheet = NULL, cover_image = NULL, metadata = NULL, chapter_level = 1, epub_version = c(&quot;epub3&quot;, &quot;epub&quot;), md_extensions = NULL, pandoc_args = NULL, template = &quot;default&quot;) Here you have all you need to know about the building options for epub. There’s a toc option set to false. What if you turn this to TRUE? No struggles, it is just an option you need to find out. The docs are even more explicit and continue like that in case you are wondering “[?!?!] they are not including a toc as a default?”. Again, read the docs. When docs are good, they have reasons: The option toc is turned off because the e-book reader can often figure out a TOC automatically from the book, so it is not necessary to add a few pages for the TOC. (As you go through, you’ll also find that there’s a wrapper around Kindlegen to produce mobi directly from RStudio, assuming you can manage your path variable.) 6.3.2 What to Look for in the Docs The example above was easy both conceptually and practically. Here is a more general list about what to read in the docs. One of the first things to be aware of our inputs and outputs of a specific piece of code. Sometimes you know that there’s a nice piece of code that does exactly what you want. You use this piece of code and pass data to it, and nothing happens. That probably because we are feeding the wrong kind of input to it. We can’t pass text to a function doing some fancy computation. (That’s why in NLP we struggle to represent text as numbers.) We can’t pass tuples when lists are expected. As we can’t modify tuple elements (tuples are immutable), if we need to update some values and we store them in a tuple, that’s not going to work. This instructs us on another important issue: if we are getting our values from some other piece of code or function, it is important to know what we get as an output: are we getting lists or dictionaries? What’s the return value, if any? How do we access that? Let’s think about a practical example. Suppose you have to assign students to specific desks in a room, to give them a test. Further, you have to give them a different shuffled version of the test, depending on where they seat. How would you represent this situation? Another important issue is to figure out what kind of object we are getting when we are using a specific module. Say we draw something with the turtle module.46 The turtles we use to draw our figures are the result of instantiating objects of the class Turtle. This helps us in figuring out what’s going on in our code and what kinds of objects populate our projects. Remember to be active while reading the docs. Types of object can be checked using the variable tracker in your IDE or using IPython type() command. You can also start doing things interactive and run your small documents-related experiments and then include the results in the main code. When we are provided with complex classes or functions we have a list of all the arguments and options available. It is good to know that we can’t pass two arguments to a function that requires one nor to call something with no values when one is expected. There’s a whole series of error messages that goes like “you called X with some values, but I was expected a different number of values”. That’s a different kind of error message compared to the previous “you called X and gave X an object of type T, but X wants a different type of object”. 6.3.3 Know your Error Messages and Exceptions Documentation is also useful when it explains the error messages that it can return to you. Looking at the error messages you receive is the first step to identify a problem and work at a solution. It is good to know the specific messages you can receive as well as the exceptions. We raise exceptions to prevent our program from crashing. Think about checking exceptions as control failures. Sometimes packages offer you specific classes for errors or exceptions so that we don’t have to rebuild them. 6.3.4 Patterns and Examples Big packages and libraries may have a list of code recipes. These are interesting to learn if approached right. On the one hand, they can offer us some solutions or blueprints for a solution. Beware that they are not to be trusted as black boxes. We have to figure out what the recipe does and why. These recipes, patterns, and examples are also good as minimal working structures to expand. On the other hand, a list of patterns and examples is a way for us to get an idea of what can be done with a certain tool as well as what kind of code it produces (remember code smells?). So suppose you read somewhere that “X is more Pythonic than Y”. You can grab examples of both X and Y doing the same tasks and try to figure out if that’s true. 6.3.5 Docs Creation: The Impact of Automation Big projects provide you with some automatically realized documentation. They are not cheating. Imagine we are developing a project as a team. Folk at HumanDemia asks some of those further away in the onboarding procedure - as you are - to start working on the code. They want you to focus on code because you like it. You think that coding is more fun than writing about code and documenting it. They think it is more productive to have you working on code rather than documenting it. Documentation is handled by someone with better writing skills who also has some abilities in reading code and understanding what it does. We are not questioning this idea of labor division, for now. Imagine how this development can proceed. You are all pushing and pulling work from GitHub, and the programming team has different branches and versions. Those documenting are following the work, but the official version keeps changing. After a code refactoring some of the names of the main functions are changed (alas!) and this causes a lot of frustration between docs-team and programming-team. Then someone from neurobiology and psychology come to visit both team and say the words: ‘docstring’ and ‘Sphinx’. After doing the relevant checks you remember some of the fundamentals. Docstrings are used to insert documentation inside the code. Docstrings are a tool to mitigate the issue of writing documentation for code staying too far away from the code itself. Given that docstrings are a pretty powerful tool, wouldn’t it be nice to build the documentation of the functions and classes of the code directly from them? Enter Sphinx (https://www.sphinx-doc.org/en/master/). Sphinx is one of many services to automate the generation of documents. If you want to document your code, you are free to explore it (as well as other related software). What is important for this chapter is that we learn to recognize how this automatically generated documentation looks. This explains some of the terseness of some documentation and also provides us with clues on where to find the relevant code. Don’t forget that more often than not, you can move from the documentation of the code to the actual and real code of the modules. You are advised to read the modules you used (if they are written in Python). In that way you are going to explore the internals of your modules and you’ll also start to figure out which parts of Python are written in Python and which relies on something else. 6.3.6 Special Kinds of Docs Software documentation interacts with the whole standards and rules of a language. For Python, this means that some of the Python Enhancement Proposals (PEPs) can be considered part of documentation or docs we need to know. For example, the first Python formatting standards are on PEP 8. That’s a doc we have to learn. The Zen of Python is itself a PEP (20). Sometimes new language features, e.g. docstrings or decorators, were introduced inside peps. This makes PEP 257 (https://www.python.org/dev/peps/pep-0257/) on docstrings convention kind of “the doc for docstrings” and PEP 318 (https://www.python.org/dev/peps/pep-0318/) the one for decorators of functions and methods. Beware that PEPs have their rules and different statuses. In fact, not all proposals get passed and actually implemented. 6.4 Summary This chapter provided you with the information to go out alone and use your programming skills to do what you feel you need to. Fluency in every language comes with practice and this chapter (and the one before it) is far from giving you all the exercises and practice contexts. Nonetheless, you were given guidance on how to explore more about the Python world. You are aware of some of the main issues that may block you down your road to Pythonista: you have a first scheme with roadblocks and boxes to fill your Python knowledge. Go and fill them! And you now that a lot of your learning time will be spent trying to figure out things from the doc. 6.4.1 More Resources Free-stuff: The best way to know what’s in the Python standard library is to have a look at the table of contents of the docs for the standard library: https://docs.python.org/3/library/ which is pretty huge. Before trying to reinvent the wheel, have a look there. Vocabulary-wise, here’s a nice learners’ glossary on GitHub: https://github.com/catherinedevlin/python_learners_glossary (try to contribute with more, if you want); This is my attempt to come up with a Python glossary. A more extended list is still growing: https://medium.com/analytics-vidhya/python-acronyms-and-vocabulary-bd2cd0c53bb6 Norvig’s Infrequently Answered Python questions: https://norvig.com/python-iaq.html will show you a lot of Python internals; Hitchhiker’s Guide to Python Python Best Practices Guidebook (free at https://github.com/realpython/python-guide). This was one of my first teach-yourself Python books. If you want to learn about web development and shape your software building abilities by learning about testing, Test-Driven Development with Python (Obey the testing goat!) by Harry Percival is a real banger. There are no excuses not to read it because we also have a free version: http://www.obeythetestinggoat.com/pages/book.html Bookwise there’s quite a lot you can read: Dan Bader’s Python Tricks is an excellent book that digs deeper on a variety of Python issues, from internals to data structure to best practises while coding with others. It has a lot of code snippets, but it is not a cookbook. Every piece of code is there to make you think. (I have a longer review here: ) Julien Danjou’s Serious Python: Black-Belt Advice on Deployment, Scalability, Testing, and More is not your intro to Python book. The book is there to bring you to another level and let you see something different from hello world. The book Seven Languages in Seven Weeks teaches you more than one language in a pragmatic way. For the curious, languages are Ruby, Io, Prolog, Scala, Erlang, Clojure, and Haskell. The languages follow different kinds of programming methods. Do you remember Norvig’s spell-correct program from the previous chapter? If you scroll down the page with the code you can find links to the same program being written in different programming languages. Have a look: https://norvig.com/spell-correct.html. You already know you can even try some of this code on Visual Studio Code, don’t you? Think Python. Probably that’s an introduction to Python. Still, the exercises are above the average and the book fear not exposing you to Markovian chains and other machine-learning oriented stuff. On clean code and sharing code with others we stumble on two classics: Robert Cecil Martin’s Clean Code: A Handbook of Agile Software Craftsmanship Andy Hunt &amp; Dave Thomas’s The Pragmatic Programmer. They use different languages (Java, mainly) but the concepts transcend the programming language. Further, you’ll get exposed to a different language and use it as a tool to learn fundamental principles. The advice you get applies to Python, but you’ll have to work on it to get its Pythonic application. Cool! (Clean Code has exercises that The Pragmatic Programmer hasn’t.) 6.4.2 Further Work Take a look at libraries doing similar or overlapping things. Try to highlight the differences relying on the docs and what’s the more Pythonic option by looking at some examples. If you lack ideas try: PyTorch and TensorFlow, Matplotlib and Seaborn, Selenium and webbrowser, Flask and Django. You can explore some python tricks (or contribute yours) here: https://github.com/sahands/python-by-example. If you want to start doing some work and projects try this out: http://pythonpracticeprojects.com/. Bonus points for reading this in GeoHot’s accent. If the note makes no sense, use your search engine and happy learning.↩ Docs are here: https://docs.python.org/3/library/unittest.html?highlight=unittest#module-unittest .↩ If you spot typos please commit corrections.↩ The former philosophers at HumanDemia often go back to the Chinese room after reading this, a footnote says.↩ You know what’s coming in this footnote. Doc. https://docs.python.org/3/library/turtle.html?highlight=turtle#module-turtle ↩ "],
["ch7.html", "7 StartUp Optimization, Corpora Builder and Corpora Opener 7.1 Startup Optimization: The Challenge 7.2 Corpora Builder: Program Overview 7.3 Corpora Opener: Program Overview 7.4 Summary", " 7 StartUp Optimization, Corpora Builder and Corpora Opener It is time to start building something that has tangible results. We already had a taste of practicalities for Humanities exploring regexes and we know how to expand and improve our Python knowledge. As at HumandDemia (and, also, as researchers in general) we are still thinking in terms of time and efforts (we are into programming when we could be reading and thinking and wasting time pretending we are doing “research” while we are browsing social media or failing at properly replying emails) there are some fun facts about the programs we are going to make. A lot of these programs are less than 300 lines of code long. When printed, they are shorter than a 3 pages hand out. “Oh,” you think “at HumanDemia they went lightweight on marketing. They could have said something like some super cool and useful scripts are shorter than 500 words, i.e. a (mostly useless) abstract of any paper we have to write. It’s good they don’t have me as their marketing ops chief.” Here is what we are going to build. The list ranges from utility tools to entire programs: a startup optimization tool that will open your main programs; a tool to retrieve and open links from a search engine; a tool to extract bibliographic data from papers. Module-wise, we are going to use mainly the following tools from the standard library: the webbrowser module (to handle browser opening); the re module to perform regular expressions. We are also going to need some tools outside the standard library (i.e. that you’ll have to conda install, possibly in virtual environments): the requests module: to handle downloading and processing data from the web; pandas: to manage data table (pandas is included with Anaconda distribution of Python) tqdm: to add progress bars; BeautifulSoup to do some parsing on the webpages. On the way to build all that you’ll be pointed out to other tools and resources that will help you to: build a timer; build games (pong, Tetris, snake); Well, enjoy your building. 7.1 Startup Optimization: The Challenge The days start in similar ways. Chances are there’s a moment in time we flash our pc and we go through a kind of routine: emails, browsing, opening various software, etc. Why waste time opening the same stuff every day? Luckily a simple script can do that for us and save us some clicks. We only have two steps to cover: write the automation script; schedule its daily execution. 7.1.1 Automation Script: A Description Each person is different and each day is different. Spend some time thinking about your main HumanDemia activities, identify a pattern, and code it. I assume that the tasks you have to do are the following: open specific programs; open specific webpages. After that, the real work starts. The script will work like that: we import os module to manage paths and open files; we import webbrowser to handle browsing operations; we define a list of our websites; we define a list of the programs we need to open; we define a function that opens a webpage in a new tab; we define a function that opens the program; we define an automation functions that does the following: iterate through the list of webpages and open them; iterate through the list of programs and open them. Easy, right? An implementation of the script is below. Notice that we have to pass path variables for opening the programs. You will need to find where the .exe files are on your machine. Be sure to pass raw strings to that variable, so that you don’t run risks of escaping characters. Be sure to enter your relevant websites and programs before running the file Startup optimization code - ch. 7.1 # Overcommented for extra explanation purposes # Start with imports import os import webbrowser # Construct your daily routine WEBSITES = [&#39;mail&#39;, &#39;some other website&#39;, &#39;telegram&#39;, ] PROGRAMS = [&#39;Rstudio&#39;, &#39;word.exe&#39;, &#39;somethingelse&#39;, ] # Functions def openwebpage(url): &quot;&quot;&quot;Return a browser tab for a given url&quot;&quot;&quot; webbrowser.open_new_tab(url) #openprograms def startprogram(path): &quot;&quot;&quot;Open the path with a .exe program&quot;&quot;&quot; # We use raw strings (r&#39;) to avoid escaping # path characters pathlocation = r&#39;path # os has a method to start a file ready for us os.startfile(pathlocation) # Main automation function def automationfunction(): &quot;&quot;&quot;Open all websites and programs in the routine&quot;&quot;&quot; for site in WEBSITES: openwebpage(site) for program in PROGRAMS: startprogram(program) # Run the main function automationfunction() The program starts out importing the relevant modules (os and webbrowser). They are part of the standard library, so there’s no need to worry about them. We then define the pieces of our daily routine: websites we need to open and program we need to run. Feel your list instead of the placeholders. Websites are pretty easy to be opened, we’ll pass them to webbrowser and use the webbrowser.open_new_tab() function. (I assume you want your sites opened in different tab rather than in N different windows. Feel free to look at the docs to learn how to open them to multiple windows.) Yes, this is the first time we see it and it sounds mysterious. So we check out the docs: https://docs.python.org/3.8/library/webbrowser.html. Programs are slightly more complex. Our pc doesn’t know how to click on an icon. So we need to feed python the .exe file of the program we need to run. Basically we need to: know the name of the file that runs the program; figure out the path of the file. (The first seems obvious but it can be tricky, e.g. if you want to run the SQL database SQlite, which is included into Python). Once you find the program open the folder in a new window. You can right-click on the path and click the copy path option. Now this is the path you have to paste in the PROGRAMS list (be sure to include the .exe file: you need a path and a file). We then define a function that opens the webpages (using webbrowser) and one opening the programs. For this function we convert the path inserted in the PROGRAMS list to a raw string (r’) to avoid escaping all the slashes in the path. All we need is to define an automation function that iterates through the two lists of tasks. 7.1.2 Scheduling the Task Ok, we have the program. Test it and be sure everything goes as intended. Our program actually opens all we need, still, it is not able to run every time we fire our workstation. (Bonus points for writing tests for that. The testing goat book has a routine to check that the page opened is the right one.) To schedule this automation - at least in Windows - we need to call the Task Scheduler. (Look here if you have troubles finding it: https://www.isunshare.com/windows-10/4-ways-to-open-task-scheduler-on-windows-10.html). Then we need to create your activity that runs our program. Suppose we save it as automationscript.py. Creating the task is intuitive except for the action part. In fact, you have to set three different parameters, two of which are optional. when asked about which program or script to run type in the path to your python.exe; the first optional field (argument) is the name of the program you want python to run, i.e. how you named the script; the last parameter (second optional field - called start or something similar) is the path to the folder you stored the program into. To recap, here’s what these parameters are for our script: the python.exe path, something like “C:\\Users\\AppData\\Local\\Programs\\Python\\Python37”; .py script (here automationscript.py); path for the .py script (i.e. where you saved it), something like “C:\\Users\\Desktop\\PythonDigitalHumanities\\”. Nice, isn’t it? 7.1.3 Extend It We said tutorials are only a first step and should prompt you to do more. So here are a few extra ideas. First general consideration. As it is now, you get the same setup every time the program runs, that is every time you fire your pc. Weekends included. Wouldn’t it be nice to set the script to work only on workdays? There should be some condition checking, maybe an if statement. You check what’s the day in the week and then you fire your setup 5 days out of 7. So, the flow control is easy. Now you need to interact with time objects. That’s more tricky, you’ll need to find a way to deal with it and then read the docs. A first way to go through time objects in Python is the datetime module, which will keep you inside the standard library. What if you are reading or studying something that requires your pc to access the material? Think about extending the program to open a pdf at a specific page. To make it really hard, think about ways to track your progress of the day: either add a while loop that asks you the page you reached at the end of the session and updates the page or write an extra program. What if we change the data structure and use a dictionary? (Hint: use to keys to store the different activities). How do we have to change the automation function? Is there any change in the performances? (Hint: you’ll need to run specific tests adding many inputs to see if something is changing. Read the unittest library docs.) 7.2 Corpora Builder: Program Overview Our task for Corpora Builder is more ambitious. People from HumanDemia want you to create a text corpus for collaborative research (you’re right, you’ll be in charge of publishing the results on GitHub). The issue you have to track is the different methods and debates on the adoption of Digital Humanities tools both in secondary school and university. From the human point of view, this requires something like: perform a variety of searches on different search engines; open all the links; check them and see if they fit or not. While we can narrow down items that are not going to match our criteria with a decent query, we can’t but open the resulting links to see if they match our criteria or not. (Unless probably we turn full time into programming and do some super cool machine learning trick… but that failure is good for us: researcher are still needed and not all research is carried out in a way that can be easily automated.) Once we go through all the results of the search, we probably store elsewhere the links to the articles we are interested in. This whole process is time-consuming and complex. Further, with the ever changing news you may end up with significant methodological issues such as the fact that the data selected are nonrepresentative because the order of the search results changes: (i) over time, (ii) over browser, (iii) over cookies, (iv) etc. To solve the previous point you end up freezing time at a certain point. It is then really hard to justify why time was frozen on a certain date. Even if you have a decent justification for that, the research may benefit if you can track what goes on after you froze the time. Maybe you’ll get extra data for your research, maybe you can further prove your point, develop a new hypothesis, squeeze in another paper. Alternatively, you may defuse the above objection ending up selecting your corpus and sources in a kind of arbitrary way that is highly peculiar such that it gets close to being a personal preference (hardly justifiable, no matter how reasonable) and then say “according to the literature”. With a bit of code we mitigate these issues by way of tracking down data and what has been used. Our first implementation of our Corpus Builder will do the following: take as an input the string we want to search; perform the search on a certain search engine; save the results of the search across all the pages; extract the links from the above pages; saving them to a file, together with the date in which the whole operation was performed; (opt.) sending all to reviewers. We’ve already seen that these operations can take quite long, if there are a lot of results (i.e. if the search is poorly defined). We then may be in need of considering some safety device such as: interrupt the whole process after some time; skip items in case there are issues connecting to the page. To build this more complex program we are going to divide and conquer the different operations and implement them one after the other. We’ll try to always have a program that is working: the first goal is that of having some that works. Then we are going to iterate and add functions. 7.2.1 Connecting to the Search Engine and Performing the Search The first operation we want to do is that of connecting to a search engine and perform the search. This is going to be quite simple. We use the requests module to access the web. From there, we access a search engine and do our query. We need to accept an input from the user for the search she wants to perform. Let’s write our first bit of code. Comments are included to start explaining what we are doing, a full discussion follows. Searching a term - ch. 7.2 # Overcommented for explanatory reasons # Load the library that handles connecting to the internet import requests # Ask the user for a search term query = input(&#39;What do you want to search?&#39;) # Performing the search searchres = requests.get(&#39;https://www.google.com/search?q=&#39;+ query) We import the requests module that, as it says in its documentation (https://2.python-requests.org/en/master/), is meant to make HTTP handling easy for humans. We then define a variable that stores the term we want to search, called query which is filled through an input. The next step is initializing the search, which basically simulates what goes on when we access our search engine and perform the search. Here we are using Google for convenience. Basically we want to access Google and type in the search term. In order to do that we need to find out what’s the form of Google results. After a little messing around with the https bar, we find out that if you type this in the browser: https://www.google.com/search?q= then whatever we add after the ‘=’ will perform the search for us. Once we discovered this, we can name another variable to store the results of our search - I chose searchres, but you are encouraged to change this. We use the requests.get() method to store a copy of the page of the results we want. The page with the result is found at ‘https://www.google.com/search?q=’, which tells our machine to search on Google, and adds the text we wanted to search for (which we stored in the query variable). 7.2.2 Corpora Builder: Adding Safe Tests and Ensuring our Connection Works So far so good. But what if the request to the server doesn’t work? Suppose the connection gets down or something goes wrong and the page does not exist? (Ok, probably that’s not gonna happen with a search). We want to handle this event for us to avoid the program breaks down. Luckily, requests have this feature built-in. All we need is to add the following instruction: raise_for_status() to the object that contains our request (searchres for me). Thanks request library for making it that simple to check that.47 Code-wise, we get this: Check with raise_for_status() - ch. 7.3 # Overcommented for explanatory reasons # Load the library that handles connecting to the internet import requests # Ask the user for the search term query = input(&#39;What do you want to search?&#39;) # Performing the search searchres = requests.get(&#39;https://www.google.com/search?q=&#39;+ query) # Make sure the request works (check it) searchres.raise_for_status() Remember when we said it’s good to know the exceptions and functions of the modules we are using? By looking at the documentation for this function (https://2.python-requests.org/en/master/_modules/requests/models/#Response.raise_for_status) we find out that it has a try/except statement and we are checking a variety of error codes. Test your code now: access a legit website and see what output you get. Then test a non-existing website. It is also good to figure out what the various error code means, i.e. beyond 404 Not Found. (Bonus points for writing tests with unittest or similar instead of manually inputting them while running our program.) 7.2.3 From Search Results to Links? Ok, our searchres is already storing an object with all the content of the first page of results. We are going to process this so that, once this works, all is left is to extend these operations to the following pages. We can now attempt scraping the links. This is the other big and complex operation of our program. Thankfully the BeautifulSoup library is there to help us extract all the links. Our template of web scraping goes as follows: we need to inspect the page with the information we want to extract (search results, in our case); we open the inspect view on our browser and start looking at the HTML in a quest for what we need; we need to isolate the relevant element and tag; we then use BeautifulSoup to extract what we need from the tags. BeautifulSoup helps us creating an object that stores all the structured markup language and allows us to browse the tree structure, extracting content from the various HTML tags. The resulting template is something like that: Making the soup - ch. 7.4 import requests from bs4 import BeautifulSoup as bs # [Build a request as before, called request] # Create a beautifulsoup object (soup, by convention) soup = bs(searchres.text, &#39;html.parser&#39;) # Extract what we need extraction = soup.select(&#39;[insert relevant tag]&#39;) If you struggle enough you find out that, after searching quite a lot in the HTML through inspection mode (if you have problems accessing this, it’s CTRL + SHIFT + I on Brave or right-click and then ‘Inspect’), .r a should match the urls of the links. Let’s include everything into a single code snippet and run it. Adding bs to extract links - ch. 7.5 import requests from bs4 import BeautifulSoup as bs # Ask the user for the search query = input(&#39;What do you want to search?&#39;) # Search for our term with requests searchreq = requests.get(&#39;https://www.google.com/search?q=&#39;+query) # Ensure it works searchreq.raise_for_status() # Creating the Beautiful Soup object soup = bs(searchreq.text, &#39;html.parser&#39;) # Getting and printing results results = soup.select(&#39;.r a&#39;) # Hopefully print(results) Are you ready to get the results? 7.2.4 [] Bad Outcomes The outcome of our printing the results is [], i.e. an empty list. This is unexpected. We inspected the HTML and the element we are looking for was there. We struggled to find it. So, what happened? A first good idea is to print the object that stores the information of our BeautifulSoup object, i.e. what we called soup. The idea is to figure out what’s going on in the object we are using to retrieve the information. Given you’ve been toying around with HumanDemia’s tech training for quite long, you already did a print(soup) and are looking for the .r tag. The issue is that… the .r tag is no longer there! That’s why the list is empty. Something happens when you watch the results on your browser and when you automate the extraction of links. Obfuscation comes in! You can start thinking about data ethics and human/machine interactions: they are your search results, you typed them in, why can’t you retrieve them? You can think about different options (change the search engine, download the page and see what happens, etc). Nonetheless, the first thing we can try to do is to retrieve all the pages with some href (i.e. a link). We can use BeutifulSoup to isolate all the elements with an href element. We are going to look for all the ‘a’ HTML tag, select those with ‘href’ and make a list out of them. To do this we are going to run the function find_all() on our soup object. We then make a list of all the links. That’s a first implementation of the code (note we fixed the query term to ‘Goofy’, here we are testing retrieving the links and do not want to waste much time keep typing in what we want to search). Working our way around: getting all the href links in the page we requested Goofy goofy search - ch. 7.6 # Imports import requests from bs4 import BeautifulSoup as bs # Searchrequest and soup searchreq = requests.get(&#39;https://www.google.com/search?q=Goofy&#39;) searchreq.raise_for_status() soup = bs(searchreq.text, &#39;html.parser&#39;) # Getting links as a href links = [] for a in soup.find_all(&#39;a&#39;, href=True): print(a[&#39;href&#39;]) links.append(a[&#39;href&#39;]) If you type ‘print(links)’, your list is going to get printed. That’s perfect! We are getting results. Links are still there! The issue is that now we are getting way too many of them. Remember, we requested the first page of the results from our search engine. Usually, it has a list of 10 results, plus some video o Wikipedia entry on the right. Now, evaluate how many items are there on our list of links. If you go for len(set(links)) you’ll find out there are way more than 10 unique elements. Remember that len() returns the length of its item, here the set of our list of links. We are turning the list of links into a set to squeeze out possible repetition of elements. If we reflect on what we are doing, it is clear that we are catching more than our list: in fact, the ‘next’ button and the ‘image’ tab all have links we are extracting. If you use gmail and are logged in, these are all href true elements. TL;DR: we move from zero link to way too many. What can we do now? 7.2.5 Extracting more Specific Links Let’s recap what’s happening. We got a task, we map it out in pseudocode and start implementing it. We choose some tools (BeautifulSoup) and we were pretty confident that a single piece of code would solve that. (If you search around “how to retrieve links from a search engine” chances are you bump into the “.r a” solution.) But reality is quite different. The easy solution did not work. Obfuscation came in. Here we are really programming. We need to find our way around an obstacle. To create our corpus we have an available strategy: given our links are still there and we managed to extract them, we have to filter this excessive pool of links. There are different ways to do that: noise filter: we can compare the various search results across different pages for the same query as well as across different queries. We are looking for what stays constant across these searches. These are the alien elements we want to get rid of. After we have identified these ones, we get our results by subtracting these to the original (excessive) pool of results; query-based filter: we filter our (excessive) list of results by keeping only the elements that were present in the keywords of the query. This requires us to elaborate more on the query we get and requires us to make further assumptions of what’s relevant in a query. Neither solution is super excellent and accurate. But at least it is principled and it allows us to keep adding features to our program (and to build a shareable corpus). 7.2.6 Filter Through Keywords We start filtering based on keywords. Our leading assumption is that what we searched in the query, matters for the results. We can turn this assumption into code specifying that the terms that we searched are featured in the url of the link. Of course there are issues: what if the term we are searching for is one of the terms that are part of the noise? (e.g. ‘video’, ‘next page’ or others). Still, before trying to improve on that we need to start processing the query. There are at least two things to isolate and care about: the query has one word: we are only going to use that word; the query has more than one word: we split the case and make sure to have all the terms of the query to be available for filtering; (wasn’t it two things?) standardization: we need to ensure that the query is usable for the machine. Remember Python is case sensitive. Suppose we search for ‘Goofy’. We are going to use ‘Goofy’ to select only Goofy-links and ignore user-policy-links, etc. If the links are in lower-goofy-format we are going to miss them using our Capitalized Goofy. Code-wise we get this: Query processing - ch. 7.6 # Previous imports etc omitted userquery = input(&#39;What do you want to search?&#39;) searchreq = requests.get(&#39;https://www.google.com/search?q=&#39; + \\ userquery) searchreq.raise_for_status() # Query processing: lowercase query = userquery.lower() # Quey processing: splitting if it has more than 1 word if len(query.split()) &gt; 1: query = query.split() If you are hard testing this, feel free to remove the input part of the userquery and hard code a term. Then print the items in query and see what you get. As a quick exercise, make a function out of it that scrapes a page given a certain query, something like def scrapeterm(userquery) which returns the items in the query. Our next task is that of building a filter based on our query. The items we need are: the request for a certain page; a soup object to parse it; a list of links obtained with BeautifulSoup; a processed query to activate the filter; a device to check that, for each item in the list of links, the terms isolated in the query are present. We already know that this tool in point 5 is, regular expression can be pretty handy for that. This time we are only going to re.search if the term in the query is there or not. Go back to chapter 5 for a refresher on regular expression and check the docs for the re module (which is part of the standard library).48 Assuming all the items from 1 to 4 are there, a filter is basically doing what follows: Basic query-based filtering mechanics - ch. 7.8 # Import to have regex import re # We have links list from bs4 links = [&#39;items&#39;, &#39;from&#39;, &#39;soup&#39;] # We processed and split the query query = [&#39;terms&#39;, &#39;of&#39;, &#39;query&#39;] # Scrape links for relevant terms # Initialize a list of filtered results filter = [] for link in set(links): for q in query: if re.search(q, link) is not None and link not in filter: link = link.replace(&#39;/url?q=&#39;, &#39;&#39;) filter.append(link) Some comments are needed here: we try to process as few items as possible, so we remove the duplicates from the links, if any, with set; we check that we have a match with the “is not None” idiom, which is discussed in PEP 8 under “Programming Recommendations”; we make sure the link is not in the filter before adding it. We don’t want duplicates. This condition wasn’t there the first time we isolated the problem and thought about the filter; we need to clean the link we are appending to the list. We want a list of items that can be easily copied and pasted into the browser. Keeping the ‘/url?q=’, if it’s present, is not going to work. (The file in the repository comes with a slightly different list and an assertion statement to check it works.) Ok, we can now move on to the next strategy. There we start to consider moving to a different page. Once we are done with that, we’ll include saving the results to file and moving our search through different pages. 7.2.7 Filter Removing Common Noise For this implementation of the idea, we are going to code a function that will filter the links. The function will act on our list of links. Basically we want to define a sublist of links that are made of noise, i.e. reoccurring links. To build the noise list, we need a variety of noise detection expressions. Assuming we build our list of expressions for noise detection, all we need to do is to check each link in our list on the different expressions in the noise detection list. If the test is successful (i.e. if our regex gets a match), then we add the link to noise. The function then returns a list of the set difference between the set of all links and the set of noise. Here’s the code, we then explain how we the noise detectors were selected: Filtering noise - ch. 7.9 # Initialize the noise list noise = [] # Definition of the filter function def filter_noise_from_links(links): # List of expressions to detect noise noise_detection = [&#39;/search\\?rlz&#39;, &#39;/search\\?ie=utf&#39;, &#39;/search\\?q=&#39;, &#39;/policies\\.google\\.com/&#39;, &#39;www\\.google\\.com/policies&#39;] # Checking detectors on links for link in set(links): for noise_item in noise_detection: test = re.search(noise_item, link) if test is not None: print(test) noise.append(link) return list(set(links)-set(noise)) filter_noise_from_links(links) A few notes about the code: feel free to add type annotations: ‘links’ is a list. That’s not obvious! we need to escape the dots in the urls because they are going to be passed as elements of a regular expression. In regex the dot ‘.’ is a special character and this will compromise our search. There’s a way to fix this with raw strings. Fix that this way if you prefer; try moving the noise initialization inside the function and then access the list of the noise you detected from the outside. That’s one (harsh) way of learning about scope. (Yes, at HumanDemia they pass you some sub-optimal code and expect you to fix it. It is still academia, after all.) Ok, now we need to explain how we constructed the noise_detection list. In pseudo code the thought behind that is the following: we have a function that gets all hrefs for a certain request; we run that function for the first page of search results; we run that function for the second page of search results; we compare what’s in (2) and (3): given that search results on different pages are going to be different (there are no duplicates) what stays constant is background search engine noise; we print common elements: they are going to be our noise_detectors. Implementation-wise, let’s start with what we already know. Getting 1 is easy. We already have all the code parts: request, query process, soup links extraction. All you need to do is to make a function out of it (the argument is going to be the url which includes the query, not the query). Also, 4 is easy. All we need is performing set intersection. This is nice and easy. Assuming A and B are set, we need to call A.intersection(B) and we have it. So, to accommodate also 5, we can say: intersection = A.intersection(B) print(intersection) What’s still puzzling are 2 and 3, namely, how to move across the pages of results returned by a search engine. How do we get to the next page? You expect something like: google.com/search=?TERM/page=NUMBER But that’s not the case. Obfuscation strikes back. How do we get out of it? We need again to work with the url of the search. Start browsing the different page result and read what comes out. Consider this: https://www.google.com/search?q=Goofy&amp;sxsrf=ACYBGNTZSgTK_0-vONXFac4v_ jWb0EiyeQ:1579169835573&amp;ei=KzggXpDTIpK3kwXLvJPADA&amp;start=120&amp;sa=N&amp;ved= 2ahUKEwjQlNuI8ofnAhWS26QKHUveBMg4WhDw0wN6BAgMEEM&amp;biw=1280&amp;bih= 578&amp;dpr=1.5 Noticed something? It says it’s page 13 of results. Now have another look at the url. See the ‘start=number’ line? That’s it: https://www.google.com/search?q=Goofy&amp;sxsrf=ACYBGNTZSgTK_0-vONXFac4v_ jWb0EiyeQ:1579169835573&amp;ei=KzggXpDTIpK3kwXLvJPADA&amp;start=120&amp;sa=N&amp;ved= 2ahUKEwjQlNuI8ofnAhWS26QKHUveBMg4WhDw0wN6BAgMEEM&amp;biw=1280&amp;bih= 578&amp;dpr=1.5 Ok, you know on what you have to act to have two (or more) searches for the same term. Have fun! Beware that this automated part is not the one-catch-all-solution. If you find that there’s more that keeps popping out that you don’t want in your results, feel free to add them to the noise detection list. Further, as we have already seen, there can be implementation issues (with the ‘.’). So, beware! 7.2.8 Saving Our Queries Ok, we can retrieve some links. Can we save them? Saving is a rather easy file operation. Let’s take the same approach we’ve been using so far. We start with our consolidated program. First, test the new feature, then we include it in our main script. Saving to a file is nothing but: create a file object; writing content in it; close the file. We can do all that using a ‘with’ statement. It ensures the file is closed and allows us to rename the opened file, if needed. Tackling the saving issue from our latest implementation, we are likely to use the data we filtered. A simple saving with-statement filteredlist = [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;end&#39;] with open(&#39;Data.txt&#39;, &#39;a&#39;) as file: for item in filteredlist: file.write(item + &#39;\\n&#39;) There’s not much to say, except that we are adding a newline (\\n) after the item. Now we have to move this saving feature into the main program. Before adding it, let’s think about our use of this saving feature. We want to build corpora out of it. This requires us to put some efforts into how we organize our folder of saved results: The name of the file should reflect what we’ve searched. We don’t want a data.txt file cluttered with different queries; It would be a nice feature to include a time reference telling us the date the search was performed (we are going to import datetime for this). The code below accomplishes all this: we rename the data file using the query. Beware to use a string element, not our split query (that is a list). Now you see why it’s good to be aware of our program structure; we organize our data document with a general line saying we searched the term X on a specific date (we are using a today variable which calls a datetime object - remember to convert it to a string or you’ll have a hard time writing it to a file). Such a line helps us as humans. If we were to use this information for some machine-related tasks, these are better stored as a table like query performed, link, date or similar. In this way we get a human-friendly report about our data. Saving searches to file - ch. 7.10 # Overcommented for explanatory reasons # Imports - standard library first import datetime # Needed to deal with time import re import requests from bs4 import BeautifulSoup as bs # Ask the user for the search and process the query userquery = input(&#39;Enter your query&#39;) searchreq = requests.get(&#39;https://www.google.com/search?q=&#39;\\ + userquery) searchreq.raise_for_status() # Query process query = userquery.lower() if len(query.split()) &gt; 1: query = query.split() # Soup objects and all links soup = bs(searchreq.text, &#39;html.parser&#39;) links = [] for a in soup.find_all(&#39;a&#39;, href=True): links.append(a[&#39;href&#39;]) # Initialize results results=[] # Date processing - get today&#39;s date today = str(datetime.datetime.now()) # Creating the file to save links with open(&#39;Data_for_&#39; + userquery +&#39;.txt&#39;, &#39;a&#39;) as file: file.write(&#39;Results for \\&#39;&#39; + userquery + \\ &#39;\\&#39; performed on &#39;+ today + &#39;:\\n&#39;) # Processing links for link in set(links): # Loop on queries # q is what we want to search on every item in the links for q in query: if re.search(q, link) is not None and \\ re.search(&#39;google&#39;, link) is None \\ and re.search(&#39;search&#39;, link) is None \\ and link not in results link = link.replace(&#39;/url?q=&#39;, &#39;&#39;) results.append(link) file.write(link + &#39;\\n&#39;) file.write(&#39;\\n&#39;) In this code we are doing some rough filtering hard coding something to be excluded from our lists of results (i.e., removing ‘search’ and ‘google’ from the list of links). You can improve the code by way of using the previous function. Also, the readability of the heading of the text can be improved using formatted strings instead of concatenation. Look PEP 498 to find out how to do it (https://www.python.org/dev/peps/pep-0498/), trading a ‘+’ sign for some parenthesis can be a good choice. Ok, now we have to deal with multiple pages of results. 7.2.9 Iteration: Moving to the Next Page We are almost there. We fought obfuscation and came up with two different strategies to retrieve links. We can save them and keep track of the time of the search. Now we need to iterate through different pages. We already know something about the format of page results, we went through that pain while exploring what was beef and what was noise across different pages of search results. If we include the number of pages we want to scrape, these are some of our new challenges: we can ask the user how many pages we need to scrape; we need to figure out where we are among the different pages of results; we have to consider the case of one-pager search results (most often with errors or super-specific searches). These are some of the changes we can implement: our scrape function now takes two arguments: query and number of pages; our scrape function needs another loop to go through the different pages. From our previous experiments we know that search results pages have this format with a ‘start’ field. So we need to look for the start. Introducing a page tracker loop # Add usual import # Add usual data structure # Initalize counter to track the current page visited pageloop = 0 # Specify how many pages to scrape NUMPAGES = 4 # Make the first request # Find the start element of the url start = [] for link in set(links): # The url we need has &#39;start&#39; in it if re.search(&#39;start&#39;, link): # We find it and we add it start.append(link) # We turn the list into a string and process it start = str(start) start = re.sub(&#39;\\[\\&#39;&#39;,&#39;&#39;, start) start = re.split(&#39;start=&#39;, start) # Check if we have more than one page of results # Single page case if start == []: # Run the scrape function. No iteration. else: # Loop on all pages for pageloop in range(0,int(NUMPAGES)*10,10): nextpage = &#39;https://www.google.com&#39;+ start[0] + \\ &#39;start=&#39;+ str(pageloop) searchpage = requests.get(nextpage) searchpage.raise_for_status() # Run our extractor function on the searchpage There’s quite a lot happening there. The basic idea is to keep track of the page we are at with a pageloop variable. The issue is that we need to introduce a variable counter to update the ‘start part’ of the search engine string. We basically need to extract the string of search results and then be able to insert different numbers so that we can access the different pages of results. Assuming we are able to do that, we can then split the case in which there are more pages of results and the one in which results are just on a single page. If we have more results we need to obtain all of them (with a range function) and construct a request for each new page. On this new page we can run a function to extract the results. You now have all the pieces of the puzzle. Feel free to experiment and assemble them to get a full working program. Consider what might happen at corner cases like when you ask to retrieve more pages of results than those available or what happens if one of the requests returns a ‘not found’ error. 7.2.10 Helper Functions Helper functions do what they say. Assume you start using your program and figure out there are some combinations of the basic operations you do quite often. For example, what if you want to run more than a query? Do we really have to say “get_links(arg1)”, “get_links(arg2)”, etc? Here optional arguments come handy. This is all you need to do to have a function with multiple arguments that, then, runs your main search function for each term. A multi query search helper function def searchterm(query): # Insert the specifics for your search pass def multiscrapecheck(*queries): &quot;&quot;&quot; Retrive links for multiple queries. &quot;&quot;&quot; for q in queries: searchterm(q) You can now see the advantages of working in this way. Different functions take care of different aspects. What to search, saving, extracting. Etc. (Remember that *args is a parameter that returns a tuple.) You can build your program as you prefer. What if we ask the user to specify arguments as tuples (term, number of pages to scrape) and pass them to a function? What if we want to add more inputs, like which function to take? What if we want to repeat our search every Monday? 7.2.11 Adding Progress Bars: Tqdm Our program has a very small interface. If we run a search across 10 or more pages chances are this is going to take long. Our user may start wondering what’s going on. All our programming is super low in terms of interfaces and design. We are running the program from the command line, IDE, IPython or similar. Nonetheless, we have an opportunity to add some feedback. What if we add progress bars to have some sort of feedback? The Tqdm module (read the docs to find out more about the name - https://tqdm.github.io/) is there to help us. What the module does is that it allows us to add progress bars when we run iteration. All we need to do is importing tqdm and change the range function of the page loop to trange(). We are now using a tqdm shortcut that calls tqdm on the range function, giving us our progress bar (see more on https://tqdm.github.io/docs/shortcuts/#trange). 7.2.12 Corpora Builder Limitations Assembling Corpora Builder is a useful exercise to go show how we can create useful programs for our daily academic life. Beware that limitations abound for how we realized the pieces of the program. Here is a list of limits and things to improve: Every term we add in the noise_detector is something we cannot retrieve in our links. We are not checking the spelling of user inputs and queries. If we have multiple word queries, we are using all the outcomes of the split. This includes one letter word like ‘a’ (say in ‘a taste of collapse’) or two-letter words like ‘an’, ‘or’, ‘of’, etc. These can have terribly bad consequences of matching random links we do not want to get. Some of these can easily be fixed (go try!), some are more complex. Again, awareness is the key. 7.2.13 Iterating Further A second iteration can actually help us address better our methodological needs. What about: performing the search from multiple browsers? performing the search on multiple search engines? taking track of where a certain item was returned from the search engine (i.e. your amazing paper was the third item on the first page or was it buried in the 11th page of results?) what about adding a feature that, after opening the link, asks us if it fits or not in our research plan (and, in case, delete the bad link from the list of results)? We’ll need to work on our corpora opener program, which follows. 7.3 Corpora Opener: Program Overview We finished Corpora Builder having a list of files in .txt format. Our human eyes can read it and that’s great. Still, we have a problem using the data. Are we going to copy and paste all the documents retrieved in the corpus to see if a link meets our needs? Not at all. HumanDemia is not hiring those with a Ph.D. to do that. Let’s see if we can come up with a better solution. For this corpora builder tool to open we also need a function that opens all the retrieved links. Here is where our needs as humans clashes with those of the machine. Things we value as the date and the queried term are only a distraction for the machine. For a machine the easier way to do what we need is something like that: open a file; read the first line; open a browser with the first line as the url; read the second line; open a browser with the second line as the url; … . This looks quite easy, programming-wise. It something like the following: import webbrowser with open(&quot;urllist.txt&quot;) as f: for line in f.readlines(): webbrowser.open(line) (Go read the docs for readlines(): https://docs.python.org/3/library/io.html?highlight=readlines.) If you prefer, you can open a new tab instead of a new browser. We already have our data stored as a list of urls on different lines, don’t we? Query and date were isolated in the file name, so we almost have a list of urls only, except for the first line. We can either ignore it (the browser will probably return an error), but there are some issues. In fact, we can’t open 20 or more tabs/windows. We should think about a way to ask the user at least: how many items to open each time and whether to continue with another set of items or stop. 7.3.1 Opening Only a Specific Amount of Files We now have to modify our program so that: it asks for the number of tab views it has to open; it iterates through the file with the links using the determined parameter. This requires us to add a few complexities. The most tricky items on our desiderata are: be sure that exactly n links are opened on each cycle; avoid an out of list error when we display the links. Here’s how to do that. Comments follow. Corpora Opener mechanics - ch. 7.11 import webbrowser with open(&quot;urllist.txt&quot;) as file_with_urls: # Build a list of all the links and find length links = file_with_urls.readlines() length = len(links) # Ask how many pages to open # remember int conversion views = int(input(&#39;How many links do you want \\ to open per batch?&#39;)) # Initialize counter to retrive links link_count = 0 # Open the first link webbrowser.open(links[link_count]) # Start iterate on the length of all the links while link_count in range(length): # Move to the next item link_count = link_count+ 1 # Check if we reached the end of the file if link_count == length: print(&#39;You opened all the links&#39;) break webbrowser.open(links[link_count]) # Check if we have displaued all the items # in the view if (link_count+1)%(views) == 0: question = input(&#39;Do you want to see \\ the next &#39; + str(views) + &#39; results? \\ (y to get them, n to close)&#39;) if question == &#39;y&#39;: link_countlink_count = link_count + 1 webbrowser.open(links[link_count]) if question == &#39;n&#39;: break There’s nothing too complex. We have to note that: we are prompting the user to answer ‘y’ or ‘n’. (We are not checking for different inputs…) to check if we have opened the required number of windows (suppose: 4) we check that the remain (that’s the % division) between our current link, plus 1 equals zero. In this case: 4%4 = 0. We need to increase link_count by 1 because lists in Python are zero-indexed. beware of the types: you can’t print int in strings and can’t do math with numbers-as-strings. 7.3.2 Issue Opening Links If you try opening your search results list, chances are you’ll get quite a lot of ‘file not found’ or similar. If you see the links we retrieved in the txt file for Goofy you’ll see they do not look very nice on the eye. For example: https://it.wikipedia.org/wiki/Pippo&amp;sa=U&amp;ved=2ahUKEwivrPvAi8LpAhVRu54KHbn2BIwQmhMwDHoECAwQDg&amp;usg=AOvVaw3iTam18fbOrKonOQf3UPJB or even https://www.pinterest.it/lesleygc49/pippo-disney/&amp;sa=U&amp;ved=2ahUKEwivrPvAi8LpAhVRu54KHbn2BIwQFjAeegQICBAB&amp;usg=AOvVaw1PWlSxqSE0mb3ExFfQEvWZ. In my case, the first link doesn’t produce any result, but the second does. Why is that? The second link succeeds because of a redirect to https://www.pinterest.it/lesleygc49/pippo-disney/. If you inspect this more, we are getting quite a lot of extra stuff after the ‘&amp;’. What is we cut the first link after the ‘&amp;’? Ohh, it works. Now there’s a choice to make. It seems we need to clean our urls to fix this ‘&amp;’ issue. We can split the link on ‘&amp;’, then link[0] has the good part of the url. The choice is: do you prefer to do this in the opening function (here) or back in the corpora builder program? 7.3.3 New Iteration Implement user feedback: after a link of the corpus is opened, ask the user whether it fits for our research goals or not (and, in case, delete the bad link from the list of results). This will force you to explore message boxes. 7.4 Summary In this chapter we started to build programs based on our needs and diving into the unknown. We optimize our pc startup, create a corpus accessing a search engine and we have found our way into proficiently using our data. While building some things we learnt about common operations and put them in practice: opening webpages and programs using Python; keyword-based filtering; reading files line by line; saving to file; performing requests to the web; scraping and parsing webpages. 7.4.1 More Resources If you are interested in building cool things, a lot is going on. This tutorial on writing timer is pretty cool: https://medium.com/@fidel.esquivelestay/build-a-pomodoro-timer-using-python-d52509730f60. Also, remember the “try to write something in a certain language and then rework it on a different language”? Here’s a list of 100 projects for beginners… in JavaScript. Nonetheless the list and descriptions of the projects are pretty good: have a look https://jsbeginners.com/javascript-projects-for-beginners/. If you prefer to build games, that’s a nice video tutorial: https://www.youtube.com/watch?time_continue=7&amp;v=XGf2GcyHPhc&amp;feature=emb_logo. I have mixed feelings about video tutorials. On the one hand you can’t follow them at your pace, you have to wait for the instructor to type in the code. On the other hand, there’s a lot you can learn while following someone that’s coding: how are they testing the code? What strategy are they using? Further, you can receive bonus explanations about Python internals. 7.4.2 Further Work try to run SQlite. It’s the database manager bundled in Python (it may be a bit complex to locate it, though). Add it to your automation start. Build a simple database (e.g. your books or cd collection, you papers). Does using the following BeautifulSoup code change something in our scraping programs? for link in soup.find_all(&#39;a&#39;): print(link.get(&#39;href&#39;)) Implement a spell checker for Corpora Builder in case the query is miss spelt. Norvig has a good one: https://norvig.com/spell-correct.html. If you like to develop other productivity tools, here’s a list of interesting things: build a timer; build tools to help you formatting in Markdown (e.g. adding or removing ##, adding or removing list items); build tools to merge and cut PDF (Hint: search for Automate the boring stuff with Python); build customized search engines for your needs. For example, a program that runs your searches for papers and references on your specific databases. Have a look at the HowDoI program to see an amazing example. You can think about this exercise as a form of Corpora Builder that runs the query on a more specific search engine (for example, jstor or your university proxy to the online library). You are encouraged to look in the models.py file (yes, on GitHub) for the code actual code of raise_for_status(), here: https://github.com/psf/requests/blob/9ed5db8ed28e816b597dafd328b342ec95466afa/requests/models.py ↩ Here we go: https://docs.python.org/3/library/re.html ↩ "],
["ch8.html", "8 Scraping Bibliographies with Bibliographer 8.1 Bibliographer: Program Overview 8.2 Summary", " 8 Scraping Bibliographies with Bibliographer The program for this section is a more systematic implementation of the practice session of regex we had in chapter 5 - Cory Doctorow was right after all, regex matters. This time we are going through the whole process: we start with a pdf paper, read it, extract the references, and end up with a .csv file with the needed references. From there, you can go into whatever program you like and represent the references in a graph. Welcome data visualization! Here we are going to work on: data extraction (references from papers); data conversion (from pdf to txt, from txt to csv); data cleaning (there will be a lot to fix from the pdf); regular expressions (many of them). We are going to extract more data than we are going to use (for now), like how many times a certain reference appears in a paper. 8.1 Bibliographer: Program Overview HumanDemia wants you again. This time they need a program that reads a file (pdf files, you learn) and tries to extract bibliographic references from them. Scopus or other platforms are not enough: you cannot find everything there. Humanities is full of standards or supposed standards for bibliographies. Further, a lot of publications are not archived. You need to work on your corpus and extract the data from there. Now that it is clear what we want our program to do, here are the main building elements we are going to cover: get the input file from pdf to txt: pdf is good for humans, bad for machines. We need to turn this into a txt, then the machine can read the txt and extract data from there; cleaning the txt: we need our txt to be cleaned such that we can process it with regexes; regex processing: we scan our text with a series of regex to get the data and process them to a standard output format. We use this format (‘Author Year’) to visualize a citation graph; save the data: self-explaining; export the data in a visualization friendly mode: we are going to handle the visualization over to other software or, at least, that’s what HumanDemia requires us. We need to properly store our files as a CSV (comma separated values). The areas we highlighted offer us a first idea of the main function of our program. One of the most problematic issues is that we have no guarantee the regexes are going to match everything we need. In fact, we know something about the formatting of the references, but that’s not enough to be able to get everything: references are everywhere in the pages, titles can be arbitrarily long, etc. Still, it’s worth trying it out. 8.1.1 General Settings and Imports There is quite a lot we need to import for the project, mostly to handle the pdf to txt transcription. Bibliographer imports import re import os # Type annotations from typing import IO, Text # Reading pdf from io import StringIO from pdfminer.pdfinterp import PDFResourceManager from pdfminer.pdfinterp import PDFPageInterpreter from pdfminer.converter import TextConverter from pdfminer.layout import LAParams from pdfminer.pdfpage import PDFPage # Pandas and NumPy for visualization import numpy as np import pandas as pd We are also using typing to insert some type annotation. Pandas is used to format the data and output them to CSV. 8.1.2 From Pdf to Txt Here we start reading the pdf and turning it into text we can use (txt). Pdfs are great for humans to read, but terrible for machines to operate on. The code below is far from being optimal. It required me a lot of search, tries, and attempts. Most standard procedures did not work: I wasn’t able to read the pdfs. So I have to resort to pdfminer (a module no longer maintained: https://github.com/euske/pdfminer) but that somehow got me where I need to. In the process there were black boxes to trust. Anyway, we start slicing the pdf name to keep only the file name and not the .pdf extension. We are going to save the text as Paper 2019.txt and not Paper 2019.pdf.txt. The conversion happens as follows: we need an interpreter object - PDFInterpreter - that takes a manager object and a converter object. We import both from pdfminer: PDFResourceManager() and TextConverter(); all the conversion process revolves around these three items: the interpreter (1) matches a manager (2) and a converter (3). We pass all the pages of the files we want to convert to the interpreter and get our result; the output we use is StringIO(), i.e. a buffer for input/output, https://docs.python.org/3.8/library/io.html?highlight=stringio#io.StringIO; we set the pagenums value to the empty set (i.e. set()); the conversion starts when we open the infile by opening the pdf in read binary mode; we then start a for loop to get all the pages with the PDFPage.get_pages and then we call the interpreter on each page; we then close both files (infile and converter); all the information is in the output as a StringIO. We get the values from there, assign this content to filetxt, and close the output; now we have all the data we need and are ready to write it to txt…; … well, we are not. Before our with-statement and a standard write to file, we need to encode the stream tobyte. The latin-1 encoding was the only one able to go through to pdfs I wanted to analyze, the same holds for the backslashreplace error. I had to experiment. Hopefully your corpus will be nicer than mine. Are you ready? Here comes the code… Pdf goes txt def read(pdf: IO) -&gt; Text: &quot;&quot;&quot;Acquire a pdf and return a text file&quot;&quot;&quot; pdfname = pdf [:-4] # Setting the conversion trio pagenums = set() output = StringIO() manager = PDFResourceManager() converter = TextConverter(manager, output, laparams=LAParams()) interpreter = PDFPageInterpreter(manager, converter) # Opening the pdf infile = open(pdf, &#39;rb&#39;) # Readiing loop: get the page and use the interpreter for page in PDFPage.get_pages(infile, pagenums): interpreter.process_page(page) infile.close() converter.close() # Get the values and turn them to byte content = output.getvalue() output.close() # Specify encoding tobyte = content.encode(encoding=&quot;latin-1&quot;,\\ errors=&quot;backslashreplace&quot;) # Coping to txt, finally! with open(pdfname + &#39;.txt&#39;, &#39;wb&#39;) as txt_file: txt_file.write(tobyte) Ok, that was hard. I managed to retrieve the text only with Latin1 as encoding. Usually you would expect a suboptimal start at your first level to propagate at a further level. The bad news? Programming follows the usual. We have to take care of Latin1 encoding next.49 8.1.3 Cleaning the Txt Somehow we managed to have our pdf turned into a txt. We can now read it but, before we do it, we need to preprocess it. Depending on what you want to do with a document, there a variety of operations to perform. If you do some natural language processing, you will remove stop words (i.e. articles, propositions, etc.) that may clutter your analysis. Remember machines are dumb. If you count what is the most occurring world in a paper you don’t want it to be ‘the’ but something more significant. Of course, identifying stop-words is complex. What to do with ‘no’ and ‘not’? Their input on meaning is quite important. Anyway, head over to SpaCy (https://spacy.io/) or NLTK (https://www.nltk.org/) to explore this more. Also, as far as pre-processing is concerned, you are likely to have all your words in lower case. Python is case sensitive and you don’t want your word count to be messed by the fact that ‘This is this’ doesn’t have two ‘this’ for your machine. Here we have different concerns. Capitalization will be important to match the authors’ surnames. It’s one of the few elements we have to spot the references! Nonetheless, get ready for a lot of false-positive like June (2006), etc. Journals like to repeat the month of the current issue every other page! We do not recognize this as readers, but our machine reader spots this… further, we can’t exclude authors named that way. Suppose you work on Japan in the media and have to deal with May (2020)… To extract the references, we need to remove the newlines. You don’t want a newline to break our regex. We also need due care with items that occur in the references formatting information: dots, coma, semi-colons, etc. Nasty spaces are to be avoided. This processing is going to make our hardly converted txt file very hard to be read for us, but pretty easy to be processed for our machine. Still, even before we go there, we need to be sure that all characters of our text went through the pdf to txt journey. That is not going to be the case. Latin-1 fails with many characters. They appear as ‘u25a0’ and other strange characters. Before working on our hardly acquired data we have to check out for their integrity. Search these codes and figure out what they mean. Then go heavy on the replace function. Basically cleaning the txt is nothing but a with statement reading the file and then a lot of replace statements to insert back the code that was missing. That’s the (long) cleaning function I had to use. It is extra-long and super verbose, but at least it explains what it does. You may have used a dictionary with key and value pairs to specify the replacement operations. Then you have to loop on each pair. Feel free to go that way. Cleaning the txt def cleantxt(filetxt: Text) -&gt; Text: &quot;&quot;&quot; Fix all the latin-1 badly imported chars. Remove extra newlines Ensure there&#39;s always a space after the dot Adjust bad inputs, such as: a. Ò is &quot; b. Ó is &quot; c. Õ is &#39; d. Ð is - e. Ñ is -- (longdash) Fix spacing the * Fix space after ) Fix space after ] &quot;&quot;&quot; with open(filetxt) as f: ftxt = f.read() ftxt=ftxt.replace(&#39;\\\\u25a0&#39;, &#39; * &#39;) # Black dot ftxt=ftxt.replace(&#39;\\\\u2013&#39;, &#39;-&#39;) ftxt=ftxt.replace(&#39;\\\\u2014&#39;, &#39;-&#39;) ftxt=ftxt.replace(&#39;\\\\u2019&#39;, &#39;\\&#39;&#39;) ftxt=ftxt.replace(&#39;\\\\u2018&#39;, &#39;\\&#39;&#39;) ftxt=ftxt.replace(&#39;\\\\u201c&#39;, &#39;\\&#39;&#39;) ftxt=ftxt.replace(&#39;\\\\u201d&#39;, &#39;\\&#39;&#39;) ftxt=ftxt.replace(&#39;\\\\ufb01&#39;, &#39;fi&#39;) ftxt=ftxt.replace(&#39;\\\\ufb02&#39;, &#39;fl&#39;) ftxt=ftxt.replace(&#39;\\\\u0152&#39;, &#39;oe&#39;) ftxt=ftxt.replace(&#39;\\\\u0153&#39;, &#39;oe&#39;) ftxt=ftxt.replace(&#39;\\\\u2022&#39;, &#39;-&#39;) # Point ftxt=ftxt.replace(&#39;\\\\u27a4&#39;, &#39;-&gt;&#39;) # Right arrow ftxt=ftxt.replace(&#39;\\\\u27a5&#39;, &#39;-&gt;&#39;) # Right curved arrow ftxt=ftxt.replace(&#39;\\\\u2122&#39;, &#39;&#39;) # TM logo ftxt=ftxt.replace(&#39;\\\\u20ac&#39;, &#39;euro&#39;) ftxt=ftxt.replace(&#39;\\\\u221e&#39;, &#39;infinity&#39;) # Infinity ftxt=ftxt.replace(&#39;\\x0c&#39;, &#39;&#39;) # Up arrow ftxt=ftxt.replace(&#39;VC &#39;, &#39;&#39;) # Copyright # Umlaut related ftxt=ftxt.replace(&#39;\\\\u20aca&#39;, &#39;a&#39;) ftxt=ftxt.replace(&#39;\\\\u20aco&#39;, &#39;o&#39;) ftxt=ftxt.replace(&#39;\\\\u20acu&#39;, &#39;u&#39;) ftxt=ftxt.replace(&#39;\\\\u2026&#39;, &#39;...&#39;) # Slavic ftxt=ftxt.replace(&#39;\\\\u017&#39;, &#39;z&#39;) ftxt=ftxt.replace(&#39;\\\\u0161&#39;, &#39;s&#39;) ftxt=ftxt.replace(&#39;\\\\u0106&#39;, &#39;C&#39;) ftxt=ftxt.replace(&quot;\\.&quot;, &quot;\\. &quot;) ftxt=ftxt.replace(&quot;Ò&quot;, &quot;\\&quot;&quot;) ftxt=ftxt.replace(&quot;Ó&quot;, &quot;\\&quot;&quot;) ftxt=ftxt.replace(&quot;Õ&quot;, &quot;\\&#39;&quot;) ftxt=ftxt.replace(&quot;Ð&quot;, &quot;-&quot;) ftxt=ftxt.replace(&quot;Ñ&quot;, &quot;--&quot;) # Ad hoc cleaning given my corpusx ftxt=ftxt.replace(&quot; eg, &quot;, &quot;&quot;) # Messes up fulldata ftxt=ftxt.replace(&quot; Ltd 2004&quot;, &quot;&quot;) # Bad input ftxt=ftxt.replace(&quot; Malden 0214&quot;, &quot;&quot;) # Bad input # Spacing ftxt=ftxt.replace(&quot;\\n&quot;, &quot; &quot;) # Newlines to space ftxt=ftxt.replace(&quot;*&quot;, &quot;&quot;) # Clean * ftxt=ftxt.replace(&quot;)&quot;, &quot;) &quot;) # Space after ) ftxt=ftxt.replace(&quot;]&quot;, &quot;] &quot;) # Space after ] ftxt=ftxt.replace(&quot; ;&quot;, &quot;;&quot;) # No space after ; ftxt=ftxt.replace(&quot; ,&quot;, &quot;,&quot;) # No space after , ftxt=ftxt.replace(&quot; .&quot;, &quot;.&quot;) # No space after . ftxt=ftxt.replace(&quot; &quot;, &quot; &quot;) # 2 spaces into 1 return ftxt To preprocess the txt all you need is to apply the cleaning function on the text. Note, again, that we are dividing the tasks: one function defines all the replacement, another calls the replacements to be applied. (Here we keep track of what happened to a file by adding a specific name after it is processed. A preprocessed file is saved with the ’_prep.txt’ ending. In that way we know that we can retrieve the file name by slicing -9. You are invited to achieve the same results using the endswith() string method.) Code-wise, we have what follows: Applying cleaning, i.e. preprocessing def preprocess(txt: Text) -&gt; Text: &quot;&quot;&quot; Clean txt for regex processing using the cleantxt function. &quot;&quot;&quot; filename = txt[:-4] with open(filename +&#39;_prep.txt&#39;, &#39;w&#39;) as preptxt: preptxt.write(cleantxt(txt)) return cleantxt(txt) 8.1.4 Regex Processing Now that we have the text ready to be processed, it is regexes time. We already know how this is going to work from chapter 5. Nonetheless, here we are testing a whole paper on different regexes. If you have a small set of papers you can define further rules to optimize the regex for the different journals, but if you are working on a general purpose tool you can’t rule out cases. Different regexes are stored in the constant list REGEX_LIST. Feel free to uncomment some of them if you need to. Another major difference is due to how we retrieve the information: we want to know which regex we are using to see the one that is bringing us the best results. We can keep track of this by printing with regex is giving us the results. We further standardize all the results as Author Year, so watch out for capturing groups in the regexes. In that way, we can produce a CSV of ‘Author Year’, ‘Author Year’, which we can graph easily. REGEX_LIST = [#&#39;\\(([A-Z][a-z]*),?\\s(\\d\\d\\d\\d)\\D?\\)&#39;, #&#39;([A-Z]\\S*),\\s&quot;[A-Za-z\\s?,&quot;]*\\((\\d\\d\\d\\d)\\)&#39;, #&#39;([A-Z]\\S*),\\s&quot;?[A-Za-z\\s?,\\(]*(\\d\\d\\d\\d)\\)&#39;, #&#39;([A-Z]\\S*),\\s&quot;?[A-Za-z\\s?,\\(]*,\\s(\\d\\d\\d\\d)\\)&#39;, &#39;([A-Z]\\S*),\\s\\&#39;?&quot;?[A-Za-z\\s?,:\\(]*\\&#39;?\\s\\(?(\\d\\d\\d\\d)\\)&#39;, &#39;\\(?([A-Z][a-z]*),?\\s\\(?(\\d\\d\\d\\d[a-f]?)&#39;, &#39;[A-Z]\\S*\\s([A-Z]\\S*),\\s[^\\(]*\\s\\([^\\(]*(\\d\\d\\d\\d)\\)&#39;, &#39;[A-Z]\\S*\\s([A-Z]\\S*),\\s[^\\(]*\\s\\([^\\(]*\\s\\(?(\\d\\d\\d\\d)\\)&#39;, &#39;[A-Z]\\S*\\s([A-Z]\\S*),\\s[^\\(]*\\s\\([^\\(]*\\([^\\(]*(\\d\\d\\d\\d)&#39;, &#39;[A-Z]\\S*\\s([A-Z]\\S*),?\\s[^\\(]*\\s\\([^\\(]*\\([^\\(]*(\\d\\d\\d\\d)&#39;, ] def extractbiblio(txt: Text) -&gt; Text: &quot;&quot;&quot; Apply regex patterns in REGEX_LIST to a (processed) text. References are stored in &#39;Author Year&#39; format. &quot;&quot;&quot; # Initialize the list containing the extracted refs extractedlist = [] filename = txt[:-9] # The file passes ended with &quot;_prep.txt&quot; for regex in REGEX_LIST: print(&#39;Processing &#39;, regex) # Open the paper as corpus corpus = open(txt).read() # Run regexes over corpus matches = re.findall(regex, corpus) # Save matches in the extracted list for match in matches: # We using capturing groups for author and date extractedlist.append(str(match[0]) \\ + &#39; &#39; + str(match[1])) # Print statement to have an idea of the search # feel free to comment it out print(sorted(set(extractedlist)), len(set(extractedlist))) return extractedlist If you want to save the data you need to add a save-to-file part like the following or a dedicated save_bib() function, your choice. # Saving to file with open(filename + &#39;_biblio.txt&#39;, &#39;w&#39;) as f: for item in sorted(extractedlist): f.write(item + &#39;\\n&#39;) 8.1.5 Getting Data with Regexes If you are using this tool you have to build you own regexes. A lot depends on the journals you explore. It is way better to use papers from one source. Even better if they use Author-Date and if the have a reference list at the end. Having a reference section will make it easier to check we extracted all the data and evaluate the performance of our regexes. Choosing if and when to save to file is a difficult call. If you are working only on author-date you can do it as part of the extracting functions. Otherwise you may not want to save too early. Your regexes might be full of false-positive or missing cases. You may want to have a different file for each regex (you can use an identifier for the regex pattern in the file name, like “paperX_refs_regex1.txt” or similar). You probably don’t want to save data to txt if you are processing your text with 20 and more different regexes. Check the results against the reference list (if provided - join me in hating styles that don’t do that). You can try to automate such a check. In general: fulldata is hard, process it all and get more matches. Sometimes you discover errors by the authors and issues with the journal instructions that were not respected (nor caught by the reviewers). That is cool. Note that there’s more to the data we are extracting than what we are printing. We get all the occurrences of a reference. This means we can check how many times they occur. We can attach a weight to the references. This is something worth considering. Further, from the txt you can go further and extract named entities and create conceptual maps. These are more advanced features that require more machine time and some performance optimization. Again, NLTK and SpaCy are probably going to be your extraction tools. 8.1.6 Exporting to CSV Ok, we are almost there. I assume you manage to have a clean version of the data. Now it is time to export them to visualize them. We are actually buck-passing it Gephi (download and install it, you know the deal by now - actually beware of Gephi). We need to have them in a CSV format and we are going to use pandas to achieve this. Pandas is one of the main data analysis tool in Python. It gives us a new kind of object, dataframe (frames for short). You can think of a frame as an Excel table (on steroids). Pandas is imported as pd by convention. And, also by convention, a dataframe is created as df. We created our dataframe based on the references we extracted from the paper. To do that, we need to read our text file with the bibliography. We can do this with the read_csv() function of pandas. In fact, CSV are txt files with a specific separator. While reading the references we specify our separator using the ‘sep’ parameter and we use the newline ‘\\n’. (In a standard CSV you are likely to have either, or ;). We then skip any header (if present) with ‘header=None’ and we start assigning the names to the columns of the frame. Gephi needs a list of edges (paper - reference) and a weight indicator, in that order. We start importing the references and add paper and weight. Then we add the missing data and reorder the columns. To access columns in the dataframe we use square bracket syntax. In this way we assign the weight value to 1 and the paper name takes the paperwithyear value we pass and capitalizes it. Our function has no idea about who is the author of the paper we are processing. According to the structure of the program, the naming depends on the starting pdf. There’s no one-catch-all solution to go from a file name to the author(s) of a paper. That’s why we ask the user to input it. The format we need is Author(space)year, i.e. one that matches the one we have in the references. Be sure to capitalize it, otherwise you risk to have a format like ‘author(space)year’ which is not going to match. def extract_to_gephi(biblio: Text, papernamewithyear) -&gt; Text: &quot;&quot;&quot; Format the data for usage in gephi. The gephi table has: - a &#39;paper&#39; column: the paper we exteracted references from; - a &#39;references&#39; column: the outcome of our biblio extraction; - a &#39;weight&#39; column: Gephi needs it set to 1. The parameters are: -biblio: a txt file with the extract biblio (_biblio.txt is the output name of the extractbiblio(txt) function); - papernamewith year: the paper we are extracting the references from given the format we are using of &#39;Author year&#39; you have to insert it this way. Otherwise your Gephi network will not display there references to the paper you are processing. &quot;&quot;&quot; references = pd.read_csv(biblio, sep=&#39;\\n&#39;, header=None,\\ names = [&#39;references&#39;, &#39;paper&#39;, &#39;weight&#39;]) df = pd.DataFrame(references) # Be sure to capitalize the paper or your data won&#39;t match # author 2020 and Author 2020 are different df[&#39;paper&#39;] = papernamewithyear.capitalize() df[&#39;weight&#39;] = 1 columns_titles = [&quot;paper&quot;,&quot;references&quot;, &quot;weight&quot;] df=df.reindex(columns=columns_titles) df.to_csv(papernamewithyear + &#39;.csv&#39;, index = False) print(&#39;Done&#39;) 8.1.7 Helper Functions Helper functions are there to make things easier for you and the users. Suppose you want to map a debate involving 10 papers and that you successfully obtained the data for all 10. You now have to join all these 10 CSV into a single file you are going to use in your visualization process. That’s perfect for a helper function like the following. Helper function joining CSVs def join_csv(): &quot;&quot;&quot; Helper function to join the results of various csv. &quot;&quot;&quot; # Initialize csv container csv = [] # Get all csv for item in os.listdir(): if item.endswith(&#39;.csv&#39;): csv.append(item) # Comprehension to come frame = pd.concat((pd.read_csv(item) for item in csv)) # We skipped the index of csv after the first frame.to_csv(&#39;joinedfiles.csv&#39;, index = False) print(&#39;Done!&#39;) In this helper function we are using Pandas to create a frame and then export the frame to CSV (frame.to_csv()). As we did before. The new function we called here is the pd.concat which allows us to concatenate the different CSVs of different papers into one. Also, a real-life usage of the tool calls to have a way to actually read, preprocess, and extract the bibliographic data. Like that. def textprocess(txt): &quot;&quot;&quot; (Helper function) Read, proprocess and extract references. &quot;&quot;&quot; filename = txt[:-4] read(txt) preprocess(filename + &#39;.txt&#39;) extractbiblio(filename + &#39;_prep.txt&#39;) 8.1.8 Tips for Graphing a Debate I can’t stress this enough, there are a lot of things that can go wrong while extracting the references and use them to produce a graph of a debate. This is a list of some of the things to watch out: different editions can give you two books when there’s only one (except cases in which the different edition is quite a different book you can consider as a different one); classics being quoted as modern (Aristotle 1923); co-authored papers: they need specific regexes; a, b, c, etc. (Author 2000a, Author 2000b and the fact that they may change across different papers); authors having the same surname; tricky surnames (van Der Torre, von Fintel, etc.). Some can be taken into account improving the program, others are harder. 8.2 Summary This chapter ends the HumanDemia training. We have a program and project that fits into a variety of different academic enterprises. We can (improve it and) use it to strengthen our research. Have fun! 8.2.1 More Resources Here are two projects that do similar things to the one we tried: https://www.rletters.net/ (this is in Ruby); https://www.bibliometrix.org/. NLTK has a free book documenting the library. Academics should feel at ease there: http://www.nltk.org/book/. (Format is suboptimal and the printed version uses Python 2) If you are interested in Natural Language Processing, Text Analytics with Python A Practitioner’s Guide to Natural Language Processing by Dipanjan Sarkar has a lot to offer to you. 8.2.2 Further Work Pdfminer is no longer maintained but there’s pdfminer.six that is. It offers an extract text function: simplify the workflow by using it. https://pdfminersix.readthedocs.io/en/latest/api/highlevel.html#api-extract-text Instead of Gephi we can visualize our graph with Python, for example using NetworkX (https://networkx.github.io/). If you are not satisfied with this extraction routine you can try building one based on PyPDF2, here’s an overview of the module https://realpython.com/pdf-python/ then use the docs, and… ok, know you know it.↩ "]
]
